<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Danping&#39;s blog </title>
    <link>https://maodanp.github.io/</link>
    <language>en-us</language>
    <author></author>
    <rights>(C) 2019</rights>
    <updated>2019-05-26 00:00:00 &#43;0000 UTC</updated>

    
      
        <item>
          <title>Linux的系统调用</title>
          <link>https://maodanp.github.io/2019/05/26/linux-syscall/</link>
          <pubDate>Sun, 26 May 2019 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2019/05/26/linux-syscall/</guid>
          <description>&lt;p&gt;系统调用是应用程序与操作系统内核之间的接口。本篇主要剖析 Linux 中系统调用的原理，详述系统调用从用户态到内核态的流程。&lt;/p&gt;

&lt;h3 id=&#34;系统调用介绍&#34;&gt;系统调用介绍&lt;/h3&gt;

&lt;p&gt;系统调用是操作系统为应用程序提供的一套接口，不仅包含应用程序运行所必需的支持，例如创建/退出进程，进程内存管理，也有对系统资源的访问，如文件、网络、进程通信、硬件设备访问等。&lt;/p&gt;

&lt;p&gt;系统调用作为接口，首先必需要有明确的定义，这样应用程序才能正确使用它，其次是需要保持向后兼容，以保证系统升级后原来的应用程序也能够正常的使用。&lt;/p&gt;

&lt;h4 id=&#34;系统调用与运行库&#34;&gt;系统调用与运行库&lt;/h4&gt;

&lt;p&gt;由于系统调用是各个操作系统提供的，所以会导致不同的操作系统的系统调用不能兼容，而且系统调用的接口相对比较原始，没有经过很好的封装。&lt;/p&gt;

&lt;p&gt;运行库就是为了实现不同系统的兼容性，在系统调用与程序之间做了一层抽象层。作为语言级别的抽象库一般都封装的比较好，并且对于标准库，能够实现不同操作系统之间的兼容。&lt;/p&gt;

&lt;p&gt;例如 Linux 下的 &lt;code&gt;read/write&lt;/code&gt; 系统调用在 C 语言中是 &lt;code&gt;fread/fwrite&lt;/code&gt; 标准库, 在 C++ 中是&lt;code&gt;iofstream&lt;/code&gt; 标准库。但是运行库为了各个操作系统之间的兼容性，只能取各平台的交集，但是一些系统独有的系统调用就不同通过标准库调用了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-26-linux-syscall-01.png&#34; alt=&#34;pic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;系统调用与内核架构图&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;中断&#34;&gt;中断&lt;/h4&gt;

&lt;p&gt;操作系统一般是通过中断来完成从用户态切换到内核态的。即通过硬件或者软件向操作系统发送一个请求，要求 CPU 暂停当前的工作转而去处理更加重要的事。&lt;/p&gt;

&lt;p&gt;中断一般具有两个属性，&lt;strong&gt;中断号&lt;/strong&gt;以及&lt;strong&gt;中断处理程序(Interrupt Service Routine, ISR)&lt;/strong&gt;。在内核中，有一个数组称为&lt;strong&gt;中断向量表(Interrupt Vector Table)&lt;/strong&gt;，能够通过中断号找到对应的中断处理程序，并且中断处理程序执行完成之后，CPU 会返回继续执行用户态代码。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-26-linux-syscall-02.png&#34; alt=&#34;pic&#34; /&gt;
&lt;em&gt;内核中断处理&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Linux 使用 &lt;code&gt;int 0x80&lt;/code&gt; 来触发所有的系统调用，并且系统调用号用 &lt;code&gt;eax&lt;/code&gt; 存储，这样中断服务程序就可以从 &lt;code&gt;eax&lt;/code&gt; 里取得系统调用号，进而调用对应的函数。&lt;/p&gt;

&lt;h3 id=&#34;系统调用的实现原理&#34;&gt;系统调用的实现原理&lt;/h3&gt;

&lt;p&gt;用户程序调用所有的系统调用的流程都是类似的，包含三部分:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;用户程序需要设置系统调用的参数，传递给内核态。这里不同架构，以及不同系统的参数是不同的；&lt;/li&gt;
&lt;li&gt;对于 x86，系统调用最终会调用 &lt;code&gt;glibc&lt;/code&gt; 的 &lt;code&gt;DO_CALL&lt;/code&gt;，这也就是程序将工作交给内核的切入点；&lt;/li&gt;
&lt;li&gt;陷入内核态处理，并最终返回用户态，返回值也是内核完成对应任务后返回的值。如果内核执行该系统调用遇到错误，也会通过一个全局的错误号来存储错误信息。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;系统调用参数传递&#34;&gt;系统调用参数传递&lt;/h4&gt;

&lt;p&gt;在 i386 系统中，系统调用由 &lt;code&gt;int 0x80&lt;/code&gt; 中断完成，各个通用寄存器用于传递参数，&lt;code&gt;eax&lt;/code&gt; 寄存器用于系统调用的接口号。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;arch&lt;/th&gt;
&lt;th&gt;arg1&lt;/th&gt;
&lt;th&gt;arg2&lt;/th&gt;
&lt;th&gt;arg3&lt;/th&gt;
&lt;th&gt;arg4&lt;/th&gt;
&lt;th&gt;arg5&lt;/th&gt;
&lt;th&gt;arg6&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;i386&lt;/td&gt;
&lt;td&gt;ebx&lt;/td&gt;
&lt;td&gt;ecx&lt;/td&gt;
&lt;td&gt;edx&lt;/td&gt;
&lt;td&gt;esi&lt;/td&gt;
&lt;td&gt;edi&lt;/td&gt;
&lt;td&gt;ebp&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;x86_64&lt;/td&gt;
&lt;td&gt;rdi&lt;/td&gt;
&lt;td&gt;rsi&lt;/td&gt;
&lt;td&gt;rdx&lt;/td&gt;
&lt;td&gt;r10&lt;/td&gt;
&lt;td&gt;r8&lt;/td&gt;
&lt;td&gt;r9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;x86 架构通用寄存器参数对照表&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;参数都是通过寄存器传递的，并且如上图所示，32 位和 64 位的寄存器也不一样。&lt;/li&gt;
&lt;li&gt;系统调用的参数限制在 6 个&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;系统调用在-glibc-中的实现&#34;&gt;系统调用在 glibc 中的实现&lt;/h4&gt;

&lt;p&gt;这里以常见的系统调用 open 为例，分析系统调用怎么实现的。glibc 的 open 函数定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int open(const char *pathname, int flags, mode_t mode);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 glibc 的源码中，有个文件 &lt;code&gt;syscalls.list&lt;/code&gt;, 里面罗列了所有 glibc 的函数对应的系统调用，如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# File name	Caller	Syscall name	Args	Strong name	Weak names

accept		-	accept		Ci:iBN	__libc_accept	accept
access		-	access		i:si	__access	access
...
open		-	open		Ci:siv	__libc_open __open open
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们来看 glibc 中的文件 &lt;code&gt;open.c&lt;/code&gt; 的实现函数 &lt;code&gt;__libc_open&lt;/code&gt; :&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int
__libc_open (const char *file, int oflag, ...)
{
  int mode = 0;

  if (__OPEN_NEEDS_MODE (oflag))
    {
      va_list arg;
      va_start (arg, oflag);
      mode = va_arg (arg, int);
      va_end (arg);
    }

  return SYSCALL_CANCEL (openat, AT_FDCWD, file, oflag, mode);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终，&lt;code&gt;SYSCALL_CANCEL&lt;/code&gt; 在 &lt;code&gt;sysdep.h&lt;/code&gt; 中的展开为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#define __INLINE_SYSCALL3(name, a1, a2, a3) \
INLINE_SYSCALL (name, 3, a1, a2, a3)
  
#ifndef INLINE_SYSCALL
#define INLINE_SYSCALL(name, nr, args...) __syscall_##name (args)
#endif
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;__syscall_##name&lt;/code&gt; 在代码中完全找不到, 应该是 makefile 中有调用 &lt;code&gt;make-syscalls.sh&lt;/code&gt; 来生成嵌套代码, 其使用模板是 &lt;code&gt;syscall-template.S&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;在 &lt;code&gt;syscall-template.S&lt;/code&gt; 中，定义了这个系统调用的调用方式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;T_PSEUDO (SYSCALL_SYMBOL, SYSCALL_NAME, SYSCALL_NARGS)
    ret
T_PSEUDO_END (SYSCALL_SYMBOL)

#define T_PSEUDO(SYMBOL, NAME, N)		PSEUDO (SYMBOL, NAME, N)


#define PSEUDO(name, syscall_name, args)           \
  .text;                                        \
  ENTRY (name)                                    \
    DO_CALL (syscall_name, args);                  \
    cmpl $-4095, %eax;                               \
    jae SYSCALL_ERROR_LABEL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于任何一个系统调用，会调用 &lt;code&gt;DO_CALL&lt;/code&gt;。对于 &lt;strong&gt;32 位系统&lt;/strong&gt;而言，该实现（&lt;code&gt;i386/sysdep.h&lt;/code&gt;）如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#define DO_CALL(syscall_name, args)			          \
    PUSHARGS_##args							  \
    DOARGS_##args							  \
    movl $SYS_ify (syscall_name), %eax;	      \
    ENTER_KERNEL							  \
    POPARGS_##args
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;code&gt;movl $SYS_ify (syscall_name), %eax;&lt;/code&gt; 表示将前面所讲的系统调用的调用号 &lt;code&gt;__NR_open&lt;/code&gt; 赋给 &lt;code&gt;eax&lt;/code&gt;。&lt;code&gt;ENTER_KERNEL&lt;/code&gt; 宏展开就是 &lt;code&gt;int $0x80&lt;/code&gt; 中断。&lt;/p&gt;

&lt;p&gt;其中，&lt;code&gt;__NR_open&lt;/code&gt; 是一个宏，表示 open 系统调用的调用号。32 位系统，该宏的定义可以在 Linux 系统中 &lt;code&gt;/usr/include/asm/unistd_32.h&lt;/code&gt; 中找到，64 位系统可以在 &lt;code&gt;/usr/include/asm/unistd_64.h&lt;/code&gt; 中找到。以下是 32 位系统的调用号的宏定义：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#define __NR_restart_syscall      0
#define __NR_exit         1
#define __NR_fork         2
#define __NR_read         3
#define __NR_write        4
#define __NR_open         5
#define __NR_close        6
......
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于 64 位系统而言，&lt;code&gt;DO_CALL&lt;/code&gt;实现（&lt;code&gt;x86_64/sysdep.h&lt;/code&gt;）的定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#define DO_CALL(syscall_name, args)					      \
  lea SYS_ify (syscall_name), %rax;					      \
  syscall
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里 64 位系统还是将系统调用名称转换为系统调用号，放在寄存器 &lt;code&gt;rax&lt;/code&gt; 中。但是不是通过中断，而是通过 &lt;code&gt;syscall&lt;/code&gt; 指令进行真正的内核调用。&lt;code&gt;syscall&lt;/code&gt; 指令使用了一种特殊的寄存器，&lt;strong&gt;特殊模块寄存器（Model Specific Registers, MSR）&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&#34;内核对调用函数的处理&#34;&gt;内核对调用函数的处理&lt;/h4&gt;

&lt;p&gt;(以下内核代码都是基于 &lt;code&gt;4.10.1&lt;/code&gt; 版本)&lt;/p&gt;

&lt;h5 id=&#34;触发中断与堆栈切换&#34;&gt;触发中断与堆栈切换&lt;/h5&gt;

&lt;p&gt;在内核启动时调用 &lt;code&gt;start_kernel&lt;/code&gt; 作为内核启动的函数入口， 其中有一个函数 &lt;code&gt;trap_init&lt;/code&gt; 用于初始化中断的，里面有一句对于 &lt;code&gt;int $0x80&lt;/code&gt; 的中断入口:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;set_system_intr_gate(IA32_SYSCALL_VECTOR, entry_INT80_32);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下是 &lt;code&gt;entry_INT80_32&lt;/code&gt; 的实现：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ENTRY(entry_INT80_32)
        ASM_CLAC
        pushl   %eax                    /* pt_regs-&amp;gt;orig_ax */
        SAVE_ALL pt_regs_ax=$-ENOSYS    /* save rest */
        movl    %esp, %eax
        call    do_syscall_32_irqs_on
.Lsyscall_32_done:
......
.Lirq_return:
	INTERRUPT_RETURN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过 &lt;code&gt;push&lt;/code&gt; 和 &lt;code&gt;SAVE_ALL&lt;/code&gt; 将当前用户态的寄存器，保存在 &lt;code&gt;pt_regs&lt;/code&gt; 结构里，然后调用&lt;code&gt;do_syscall_32_irqs_on&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;static __always_inline void do_syscall_32_irqs_on(struct pt_regs *regs)
{
	struct thread_info *ti = current_thread_info();
	unsigned int nr = (unsigned int)regs-&amp;gt;orig_ax;
......
	if (likely(nr &amp;lt; IA32_NR_syscalls)) {
		regs-&amp;gt;ax = ia32_sys_call_table[nr](
			(unsigned int)regs-&amp;gt;bx, (unsigned int)regs-&amp;gt;cx,
			(unsigned int)regs-&amp;gt;dx, (unsigned int)regs-&amp;gt;si,
			(unsigned int)regs-&amp;gt;di, (unsigned int)regs-&amp;gt;bp);
	}
	syscall_return_slowpath(regs);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里将系统调用号从 eax 中取出，然后根据系统调用号，在系统调用表里找到对应函数进行带哦用，并将寄存器中保存的参数取出来作为函数参数传递。&lt;/p&gt;

&lt;p&gt;最终 &lt;code&gt;INTERRUPT_RETURN&lt;/code&gt; 宏展开后为 &lt;code&gt;iret&lt;/code&gt;，将原来用户态保存的线程恢复回来。包含代码段、指令指针寄存器等。&lt;/p&gt;

&lt;h5 id=&#34;内核对系统函数的处理&#34;&gt;内核对系统函数的处理&lt;/h5&gt;

&lt;p&gt;内核中会维护一个系统调用号与对应函数的系统调用表。这里以 32 位的系统调用表（&lt;code&gt;arch/x86/entry/syscalls/syscall_32.tbl&lt;/code&gt;）为例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# &amp;lt;number&amp;gt; &amp;lt;abi&amp;gt; &amp;lt;name&amp;gt; &amp;lt;entry point&amp;gt; &amp;lt;compat entry point&amp;gt;
5	i386	open			sys_open  compat_sys_open
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中第一列数字就是系统调用号，第四列是系统调用在内核的实现函数，都是以 &lt;code&gt;sys_&lt;/code&gt; 开头。&lt;/p&gt;

&lt;p&gt;系统调用在内核中的实现函数声明一般在 &lt;code&gt;include/linux/syscalls.h&lt;/code&gt; 文件中, 可以看到 &lt;code&gt;sys_open&lt;/code&gt; 的声明：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;asmlinkage long sys_open(const char __user *filename,
				int flags, umode_t mode);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;真正实现一般在对应的 &lt;code&gt;.c&lt;/code&gt; 文件中，例如 &lt;code&gt;sys_ope&lt;/code&gt;n 的实现在 &lt;code&gt;fs/open.c&lt;/code&gt; 文件中。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;SYSCALL_DEFINE3(open, const char __user *, filename, int, flags, umode_t, mode)
{
        if (force_o_largefile())
                flags |= O_LARGEFILE;
        return do_sys_open(AT_FDCWD, filename, flags, mode);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;code&gt;SYSCALL_DEFINE3&lt;/code&gt; 是一个表示带有三个参数的宏，将其展开后，实现如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;asmlinkage long sys_open(const char __user * filename, int flags, int mode)
{
 long ret;


 if (force_o_largefile())
  flags |= O_LARGEFILE;


 ret = do_sys_open(AT_FDCWD, filename, flags, mode);
 asmlinkage_protect(3, ret, filename, flags, mode);
 return ret;
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结合以上分析，这里总结下 32 位的系统调用从用户态到内核态是如何执行的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-26-linux-syscall-03.png&#34; alt=&#34;pic&#34; /&gt;
&lt;em&gt;32 位的系统调用 图片来源：趣谈Linux操作系统&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;系统调用实例&#34;&gt;系统调用实例&lt;/h3&gt;

&lt;p&gt;通过以上的分析，相信大家已经了解了系统调用的整个流程。下面通过三种不同的方式，实现对终端的输出。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通过 &lt;code&gt;write()&lt;/code&gt; 系统调用实现&lt;/li&gt;
&lt;li&gt;通过 &lt;code&gt;syscall()&lt;/code&gt; 系统调用实现&lt;/li&gt;
&lt;li&gt;通过汇编，调用 &lt;code&gt;syscall&lt;/code&gt; 指令&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;write-系统调用&#34;&gt;write() 系统调用&lt;/h4&gt;

&lt;p&gt;这里我们没有使用 &lt;code&gt;printf&lt;/code&gt; 这个标准库，而是使用 Linux 的系统调用 &lt;code&gt;write&lt;/code&gt; 。参数 &lt;code&gt;1&lt;/code&gt; 表示标准输出文件描述符。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;fcntl.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
int main () 
{
    write (1, &amp;quot;Hello World&amp;quot;, 11);
return 0; 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;syscall-系统调用&#34;&gt;syscall() 系统调用&lt;/h4&gt;

&lt;p&gt;现在，我们使用 glibc 提供的 &lt;code&gt;syscall&lt;/code&gt; 接口，实现同样的逻辑。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;sys/syscall.h&amp;gt;
int main () 
{
    syscall (1, 1, &amp;quot;Hello World&amp;quot;, 11);
return 0; 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里第一个参数表示系统调用的调用号，我是在 64 位系统上运行的，所以 &lt;code&gt;write&lt;/code&gt; 对应的调用号为 &lt;code&gt;1&lt;/code&gt; ，如果是 32 位系统，则调用号为 &lt;code&gt;4&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;也就是说 &lt;code&gt;syscall&lt;/code&gt; 也是一个系统调用，而且接口更加原始，其他的系统调用都可以看作是通过 &lt;code&gt;syscall&lt;/code&gt; 实现的一种封装。&lt;/p&gt;

&lt;h4 id=&#34;syscall-指令&#34;&gt;syscall 指令&lt;/h4&gt;

&lt;p&gt;下面是通过汇编代码，实现同样的逻辑。这里的方法是将值放到对应的寄存器中，然后调用 &lt;code&gt;syscall&lt;/code&gt; 指令。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-s&#34;&gt;section .text global _start
_start: ; ELF entry point ; 1 is the number for syscall write ().
mov rax, 1
; 1 is the STDOUT file descriptor.
mov rdi, 1
    ; buffer to be printed.
    mov rsi, message
    ; length of buffer
    mov rdx, [messageLen]
    ; call the syscall instruction
syscall
; sys_exit
mov rax, 60
; return value is 0
mov rdi, 0
; call the assembly instruction
syscall
section .data
messageLen: dq message.end-message message: db &#39;Hello World&#39;, 10
.end:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对应汇编代码的 makefile 如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;all:
    nasm -felf64 write.asm
    ld write.o -o elf.write
clean:
    rm -rf *.o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，这里将系统调用号 &lt;code&gt;1&lt;/code&gt; 放入了 &lt;code&gt;eax&lt;/code&gt;，后面的几个参数分别放入了寄存器 &lt;code&gt;rdi&lt;/code&gt;, &lt;code&gt;rsi&lt;/code&gt;, &lt;code&gt;rdx&lt;/code&gt;, 顺序是与之前的 64 位系统通用寄存器传递参数的顺序是一致的。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>美国之行</title>
          <link>https://maodanp.github.io/2019/05/20/us-travel/</link>
          <pubDate>Mon, 20 May 2019 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2019/05/20/us-travel/</guid>
          <description>&lt;p&gt;去年11月份因公出差去了趟美国的丹佛市，在美国的一周时间里，亲身经历了这个发达国家人民的生活、工作状态，有一些感悟在这里分享给大家。&lt;/p&gt;

&lt;p&gt;由于飞机购票原因，跟另外一位同事分开了行程，我晚了一天去，所以是一个人的旅程。办签证很是顺利，材料准备好后，因为是会议旅游类型的签证，加上有公司出具的邀请函，所以不到两周就拿到了签证。&lt;/p&gt;

&lt;p&gt;到达美国后第一映像是天空如此的蓝，在飞机上就能看到地面的轮廓，如此的清晰。还有就是美国人民的谦和与笑容。&lt;/p&gt;

&lt;p&gt;乘坐航班由于需要先到西雅图，再转机到丹佛，落地后的感觉就是这两个机场的硬件设施都比较落后，远不能跟中国的一二线城市机场相提并论。虽然美国的基础建设还停留在上世纪七八十年代，但是设施都非常完善和人性化，特别是针对残障人士的设施。&lt;/p&gt;

&lt;h3 id=&#34;美国人的性格&#34;&gt;美国人的性格&lt;/h3&gt;

&lt;p&gt;因为美国本身就是一个由不同种族、不同文化的移民组成的国家。这个国家内部各种元素都是相互融合的。所以美国人大多是持开放的心态，对到访者也是非常的友善。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-21-us-travel-1.png&#34; alt=&#34;pic&#34; /&gt;
&lt;em&gt;丹佛小火车站&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-21-us-travel-2.jpeg&#34; alt=&#34;pic&#34; /&gt;
&lt;em&gt;丹佛火车站候车大厅，像是咖啡厅, 再比比国内的&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;在丹佛下飞机到市区需要做小火车，但是我兑换的都是100美元的面值，火车的自动售票机不支持这么大面额的纸币，又没有找到人工售票窗口，看到旁边有个小哥背着徒步背包过来买票，我只能硬着头皮上去跟人家兑换了。小哥非常的热心肠，给我兑换，还帮我买好票一起上了车。在半小时的旅程中聊的很欢，聊路过的风景，城市的历史，聊他周末都是怎么度过&amp;hellip;&amp;hellip; 临别时还不忘告诉我怎么座免费巴士去宾馆。&lt;/p&gt;

&lt;p&gt;总体感觉美国人非常的热情，友善。对家庭的观念也非常强，小哥说常开车去美国东部找他妹妹，充满着亲情与友情的味道。&lt;/p&gt;

&lt;h3 id=&#34;工作状态环境&#34;&gt;工作状态环境&lt;/h3&gt;

&lt;p&gt;美国的工作氛围比国内轻松不少，早上九点基本没看到几个人到office，十点多才差不多到齐，到晚上四五点基本就没几个人了。有个leader三点准时下班，去接娃放学；有位华人同事说 「慢慢来，这叫细水长流&amp;hellip;&amp;hellip;」， 想想也是，对于不考虑清楚需求就加班蛮干的，那才是真正的消耗员工时间。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-21-us-travel-3.png&#34; alt=&#34;pic&#34; /&gt;
&lt;em&gt;公司娱乐室的一角&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;还有就是办公室条件好，每人都是升降桌，茶水间每天都是新鲜水果，娱乐区有桌游，还看到游戏手柄和碟片，真是比国内的环境好不少。&lt;/p&gt;

&lt;h3 id=&#34;服务业&#34;&gt;服务业&lt;/h3&gt;

&lt;p&gt;在美国的消费都是用信用卡，而且都不用输密码，如果有盗刷情况，银行会有相应的赔付。看到一个有趣的现象，在餐厅就餐发展有些黑人用现金支付，同事说很可能是信用有问题，不能刷卡消费了，可见信用是多么的重要。美国服务行业的从业人员，大叔大妈级挺多，特别是空乘人员，人家重在服务质量和人员素质，所以不在意颜值，不过餐厅服务人员倒偏年轻化。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-21-us-travel-4.png&#34; alt=&#34;pic&#34; /&gt;
&lt;em&gt;Costco，到了大超市就是买买买，感觉衣服挺便宜，虽然很多made in China&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;美国是一个小费制的国家，只要涉及有人服务的消费，都是需要给消费的，但是快餐连锁式餐厅倒不用，因为都是流水线话的，没有专人为你服务。比如宾馆每天起床要在床头放几美元，到餐厅吃饭基本都是需要给服务员10%～20%不等的小费，有意思的一点是，为你服务的人须是同一个，因为最后的小费就是给那个服务员，所以用餐中途最好别看见服务员就喊。&lt;/p&gt;

&lt;p&gt;期间还特意去看了丹佛掘金队的场馆，虽然自己曾经是火箭队的球迷，但是也佩服掘金队在今年的崛起，能打到西部第一，实力绝非一般，虽然最终没能挺近总决赛，但依然值得尊敬。&lt;/p&gt;

&lt;h3 id=&#34;民主与宗教&#34;&gt;民主与宗教&lt;/h3&gt;

&lt;p&gt;因为丹佛是科罗拉多州的首府，所以我们还去看了科罗拉多州的州会议大厦，顶上是金的。果然是民主的国家，市民、观光客都是随便进，只要通过安检就行，最令我惊叹的是还能看到州议员们在办公室开会，这在我国真的是无法想象的事。很多小朋友在里面玩耍，还有一些老师带着学生来参观，从小接受民主教育。
&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-21-us-travel-6.png&#34; alt=&#34;pic&#34; /&gt;
&lt;em&gt;市政厅大门，前面是纪念南北战争的纪念碑&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;民主制度有其很大的优越性，首先法律就是保障大多数的利益，能够使人们有很强的平等、权利意识，几十是很穷的人也无法容忍别人侵犯和践踏自己的权利。并且也极其尊重法律，将其等同于尊重自己的选择和自己的意志。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-21-us-travel-5.png&#34; alt=&#34;pic&#34; /&gt;
&lt;em&gt;议会厅，很多小学生多来这里听老师讲授自由民主，讲述如何选举&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;此外，丹佛市的教堂非常非常多，有古老的三一联合卫理公会教堂，也有新式的教堂。民主与宗教是互相影响的，宗教在美国人心中的地位与自由共和精神同等的重要。美国人也很清楚如果没有宗教的精神，也就没有美国现在的自由，人人生而自由平等的观念就是来自于宗教。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-21-us-travel-7.png&#34; alt=&#34;pic&#34; /&gt;
&lt;em&gt;古老的三一联合卫理公会教堂&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;总之，有很多值得学习的地方，寄希望于自己的儿子以后能够去学习深造了。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>目标文件的那些事</title>
          <link>https://maodanp.github.io/2019/05/19/linux-elf/</link>
          <pubDate>Sun, 19 May 2019 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2019/05/19/linux-elf/</guid>
          <description>&lt;p&gt;本篇主要探讨目标文件（Linux中的ELF）的内部结构，并对神秘目标文件一探究竟。&lt;/p&gt;

&lt;h3 id=&#34;elf-文件结构概述&#34;&gt;ELF 文件结构概述&lt;/h3&gt;

&lt;p&gt;我们知道可执行文件的形成需要经过&lt;code&gt;预编译&lt;/code&gt;、&lt;code&gt;编译&lt;/code&gt;、&lt;code&gt;汇编&lt;/code&gt;、&lt;code&gt;链接&lt;/code&gt;，最终形成可执行文件。&lt;/p&gt;

&lt;p&gt;目标文件即为编译后生成的文件，它从文件结构上而言跟最终可执行文件是类似的，可能有些符号或者地址还需要调整。&lt;/p&gt;

&lt;p&gt;Linux中ELF（Executable linkable Format）文件包括以下4类：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ELF文件类型&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;可重定位文件（Relocatable File）&lt;/td&gt;
&lt;td&gt;其中包含数据与代码段，被用来链接生成可执行文件，静态链接库也归为这一类&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;可执行文件（Executable File）&lt;/td&gt;
&lt;td&gt;最终可执行程序&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;共享目标文件（Shared object File）&lt;/td&gt;
&lt;td&gt;包含数据和代码&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;核心转储文件（Core dump File）&lt;/td&gt;
&lt;td&gt;由于进程意外终止形成的文件，包括进程地址空间及终止时的一些其他信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;解析目标文件&#34;&gt;解析目标文件&lt;/h4&gt;

&lt;p&gt;通过以下的一个实例来解析下目标文件中包括哪些内容。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;/*
 * example.c
 * gcc -c example.c
 */
int printf(const char* format, ...);

int global_int_var = 84; 
int global_unint_var;

void fun1(int i)
{
    printf(&amp;quot;%d\n&amp;quot;, i); 
}

int main(void)
{
    static int static_var = 85; 
    static int static_var2;

    int a = 1;
    int b;

    func1(static_var + static_var2 + a + b); 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;global_int_var&lt;/code&gt;与&lt;code&gt;global_unint_var&lt;/code&gt;分别表示已初始化和未被初始化的全局静态变量。
&lt;code&gt;static_var&lt;/code&gt;与&lt;code&gt;static_var2&lt;/code&gt;分别表示已初始化和未被初始化的局部静态变量。
&lt;code&gt;a&lt;/code&gt;和&lt;code&gt;b&lt;/code&gt;分别表示已初始化和未被初始化的局部变量。&lt;/p&gt;

&lt;p&gt;我们可以观察上面几个变量在目标文件中是怎么存储的。通过&lt;code&gt;objdump -h example.o&lt;/code&gt; 可以查看该ELF的结构和内容。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .text         0000004c  00000000  00000000  00000034  2**2
                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE
  1 .data         00000008  00000000  00000000  00000080  2**2
                  CONTENTS, ALLOC, LOAD, DATA
  2 .bss          00000004  00000000  00000000  00000088  2**2
                  ALLOC
  3 .rodata       00000004  00000000  00000000  00000088  2**0
                  CONTENTS, ALLOC, LOAD, READONLY, DATA
  4 .comment      0000002e  00000000  00000000  0000008c  2**0
                  CONTENTS, READONLY
  5 .note.GNU-stack 00000000  00000000  00000000  000000ba  2**0
                  CONTENTS, READONLY
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我用了32位的系统测试，所以对于64位，ELF的段结构会有差异。对照段长度（Size）和偏移位置（File Offset）可以得出如下结构图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-19-elf-1.png&#34; alt=&#34;pic&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;段结构&#34;&gt;段结构&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ELF头文件（ELF header）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;描述整个文件的属性，包括文件是否可执行，是静态链接还是动态链接，目标硬件、目标操作系统。从上图可以看出，头文件的大小是固定的，为0x34个字节，后面一小节会有专门介绍。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;段表（Section Table）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;描述文件中各个段的一个数组。描述各段在文件中偏移量、读写权限及段属性。后面一小节再专门介绍。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;代码段（.text）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;保存执行语句编译后生成的机器代码&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据段（.data）与只读数据段（.rodata）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;保存已经初始化的全局变量和局部静态变量。只读数据段则保存程序里的只读变量。&lt;/p&gt;

&lt;p&gt;通过命令：&lt;code&gt;objdump -x -s -d exmpale.o&lt;/code&gt;， 可以查看到数据段：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;......
Contents of section .data:
 0000 54000000 55000000                    T...U...
Contents of section .rodata:
 0000 25640a00                             %d..
......
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到 &lt;code&gt;.data&lt;/code&gt; 的前4个字节，从低到高分别为 0x54, 0x00, 0x00, 0x00，刚好是 &lt;code&gt;global_int_var&lt;/code&gt; , 十进制 84。后面4个字节则刚好是 &lt;code&gt;static_var&lt;/code&gt; 的值 85。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;现代PC的CUP中都是Little-Endian。Little-endian 规定MSB在存储是放在高地址，传输时放在流的末尾；LSB存储时放在低地址，传输时放在流的开始。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;.rodata&lt;/code&gt; 段则是一个常量字符串 &lt;code&gt;%d\n&lt;/code&gt; 外加结束符。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;.bss段&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;保存未初始化的全局变量和局部静态变量。理论上应该存储 &lt;code&gt;global_uninit_var&lt;/code&gt; 和 &lt;code&gt;static_var2&lt;/code&gt; 的总大小8字节，但是这里确只有4个字节。&lt;/p&gt;

&lt;p&gt;这里编译器将 &lt;code&gt;global_uninit_var&lt;/code&gt; 看作了一个未定义的全局变量符号，等到最终链接成可执行文件时才会再在 &lt;code&gt;.bss&lt;/code&gt; 段中分配空间。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;编译器默认的函数和初始化了的全局变量作为强符号，未初始化的全局变量作为弱符号。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;Idx Name          Size      VMA       LMA       File off  Algn
......
  2 .bss          00000004  00000000  00000000  00000088  2**2
......
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;elf-文件结构详述&#34;&gt;ELF 文件结构详述&lt;/h3&gt;

&lt;p&gt;这里我先将这个ELF的文件中所有的段位置、长度都画出来，中间的 &lt;code&gt;Section Table&lt;/code&gt; 以及 &lt;code&gt;.real.text&lt;/code&gt; 都由于对齐原因与前面的段之间分别有一个字节的间隔。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-19-elf-2.png&#34; alt=&#34;pic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;最后 &lt;code&gt;.real.text&lt;/code&gt; 结束后长度为 0x450, 恰好是 &lt;code&gt;example.o&lt;/code&gt; 的文件大小。下面分别描述这些不同的段结构信息。&lt;/p&gt;

&lt;h4 id=&#34;elf头文件-elf-header&#34;&gt;ELF头文件 （ELF Header）&lt;/h4&gt;

&lt;p&gt;通过 &lt;code&gt;readelf -h example.o&lt;/code&gt; 命令可以查看ELF头文件的具体信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ELF Header:
  Magic:   7f 45 4c 46 01 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF32
  Data:                              2&#39;s complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              REL (Relocatable file)
  Machine:                           Intel 80386
  Version:                           0x1
  Entry point address:               0x0
  Start of program headers:          0 (bytes into file)
  Start of section headers:          268 (bytes into file)
  Flags:                             0x0
  Size of this header:               52 (bytes)
  Size of program headers:           0 (bytes)
  Number of program headers:         0
  Size of section headers:           40 (bytes)
  Number of section headers:         11
  Section header string table index: 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;分别对应了 &lt;code&gt;/usr/include/elf.h&lt;/code&gt; 中的头文件结构。分别定义了&lt;strong&gt;ELF魔数&lt;/strong&gt;、&lt;strong&gt;文件机器字节长度&lt;/strong&gt;、&lt;strong&gt;数据存储方式&lt;/strong&gt;、&lt;strong&gt;版本&lt;/strong&gt;、&lt;strong&gt;运行平台&lt;/strong&gt;、&lt;strong&gt;ABI版本&lt;/strong&gt;、&lt;strong&gt;ELF重定位类型&lt;/strong&gt;、&lt;strong&gt;硬件平台&lt;/strong&gt;、&lt;strong&gt;硬件平台版本&lt;/strong&gt;、&lt;strong&gt;入口地址&lt;/strong&gt;、&lt;strong&gt;程序头入口和长度&lt;/strong&gt;、&lt;strong&gt;段表的位置和长度&lt;/strong&gt;及&lt;strong&gt;段数量&lt;/strong&gt;等 。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;typedef struct
{
  unsigned char e_ident[EI_NIDENT]; /* Magic number and other info */
  Elf32_Half    e_type;         /* Object file type */
  Elf32_Half    e_machine;      /* Architecture */
  Elf32_Word    e_version;      /* Object file version */
  Elf32_Addr    e_entry;        /* Entry point virtual address */
  Elf32_Off e_phoff;        /* Program header table file offset */
  Elf32_Off e_shoff;        /* Section header table file offset */
  Elf32_Word    e_flags;        /* Processor-specific flags */
  Elf32_Half    e_ehsize;       /* ELF header size in bytes */
  Elf32_Half    e_phentsize;        /* Program header table entry size */
  Elf32_Half    e_phnum;        /* Program header table entry count */
  Elf32_Half    e_shentsize;        /* Section header table entry size */
  Elf32_Half    e_shnum;        /* Section header table entry count */
  Elf32_Half    e_shstrndx;     /* Section header string table index */
} Elf32_Ehdr;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，&lt;code&gt;e_ident[EI_NIDENT]&lt;/code&gt; 即为ELF的魔数。各个字节含义见下表：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字节&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;7f&lt;/td&gt;
&lt;td&gt;ASCII中DEL控制字符&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;45 4c 46&lt;/td&gt;
&lt;td&gt;对应ELF三个字符的ASCII&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;01&lt;/td&gt;
&lt;td&gt;32位系统， 02则表示64位&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;01&lt;/td&gt;
&lt;td&gt;字节序&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;01&lt;/td&gt;
&lt;td&gt;ELF主版本号&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;段表-section-header-table&#34;&gt;段表（Section Header Table）&lt;/h4&gt;

&lt;p&gt;前面介绍过 &lt;code&gt;.text&lt;/code&gt;, &lt;code&gt;.data&lt;/code&gt; 等基本的段，这个段表就是用来保存这些段的基本属性。如每个段的段名、段长度、在文件中的偏移、读写权限以及段的其他属性。&lt;/p&gt;

&lt;p&gt;通过 &lt;code&gt;readelf -S example.o&lt;/code&gt;可以看到所有的段表结构：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;There are 11 section headers, starting at offset 0x10c:

Section Headers:
  [Nr] Name              Type            Addr     Off    Size   ES Flg Lk Inf Al
  [ 0]                   NULL            00000000 000000 000000 00      0   0  0
  [ 1] .text             PROGBITS        00000000 000034 00004c 00  AX  0   0  4
  [ 2] .rel.text         REL             00000000 000428 000028 08      9   1  4
  [ 3] .data             PROGBITS        00000000 000080 000008 00  WA  0   0  4
  [ 4] .bss              NOBITS          00000000 000088 000004 00  WA  0   0  4
  [ 5] .rodata           PROGBITS        00000000 000088 000004 00   A  0   0  1
  [ 6] .comment          PROGBITS        00000000 00008c 00002e 01  MS  0   0  1
  [ 7] .note.GNU-stack   PROGBITS        00000000 0000ba 000000 00      0   0  1
  [ 8] .shstrtab         STRTAB          00000000 0000ba 000051 00      0   0  1
  [ 9] .symtab           SYMTAB          00000000 0002c4 000100 10     10  10  4
  [10] .strtab           STRTAB          00000000 0003c4 000063 00      0   0  1
Key to Flags:
  W (write), A (alloc), X (execute), M (merge), S (strings)
  I (info), L (link order), G (group), x (unknown)
  O (extra OS processing required) o (OS specific), p (processor specific)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上输出分别对应了 &lt;code&gt;/usr/include/elf.h&lt;/code&gt; 中的段表文件结构。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;typedef struct
{
  Elf32_Word    sh_name;        /* Section name (string tbl index) */
  Elf32_Word    sh_type;        /* Section type */
  Elf32_Word    sh_flags;       /* Section flags */
  Elf32_Addr    sh_addr;        /* Section virtual addr at execution */
  Elf32_Off sh_offset;      /* Section file offset */
  Elf32_Word    sh_size;        /* Section size in bytes */
  Elf32_Word    sh_link;        /* Link to another section */
  Elf32_Word    sh_info;        /* Additional section information */
  Elf32_Word    sh_addralign;       /* Section alignment */
  Elf32_Word    sh_entsize;     /* Entry size if section holds table */
} Elf32_Shdr;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;重定位表-relocatable-table&#34;&gt;重定位表（Relocatable Table）&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;.rel.text&lt;/code&gt; 为重定位表，即表示代码段中与一个需要重定位的代码段。&lt;code&gt;.rel.text&lt;/code&gt; 就是对 &lt;code&gt;.text&lt;/code&gt; 的重定位表，因为 &lt;code&gt;.text&lt;/code&gt; 中有对 &lt;code&gt;printf&lt;/code&gt; 外部函数的调用，需要在链接阶段重定位其实际函数地址。&lt;/p&gt;

&lt;h4 id=&#34;字符串表-string-table&#34;&gt;字符串表（String Table）&lt;/h4&gt;

&lt;p&gt;常见有 &lt;code&gt;.strtab&lt;/code&gt; 和 &lt;code&gt;.shstrtab&lt;/code&gt; 两种字符串表，分别表示为字符串表（string table）和段表字符串表（section header string table）。&lt;/p&gt;

&lt;p&gt;字符串表存放普通字符串的，段表字符串表则是用来保存段表中用到的字符串名的。&lt;/p&gt;

&lt;h4 id=&#34;符号表-symbol-table&#34;&gt;符号表（Symbol Table）&lt;/h4&gt;

&lt;p&gt;整个链接过程正是基于符号才能正确完成，每一个目标文件都会有一个相应的符号表，这个表里记录了目标文件中所用到的所有符号。
每个定义的符号有一个对应的值，对于函数和变量来说，这个符号值就是它们的地址。 &lt;code&gt;.symtab&lt;/code&gt; 中进行存储。&lt;/p&gt;

&lt;p&gt;通过 &lt;code&gt;readelf -s example.o&lt;/code&gt; 命令可以查看ELF头文件的具体信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Symbol table &#39;.symtab&#39; contains 16 entries:
   Num:    Value  Size Type    Bind   Vis      Ndx Name
     0: 00000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 00000000     0 FILE    LOCAL  DEFAULT  ABS exmpale.c
     2: 00000000     0 SECTION LOCAL  DEFAULT    1
     3: 00000000     0 SECTION LOCAL  DEFAULT    3
     4: 00000000     0 SECTION LOCAL  DEFAULT    4
     5: 00000000     0 SECTION LOCAL  DEFAULT    5
     6: 00000004     4 OBJECT  LOCAL  DEFAULT    3 static_var.1243
     7: 00000000     4 OBJECT  LOCAL  DEFAULT    4 static_var2.1244
     8: 00000000     0 SECTION LOCAL  DEFAULT    7
     9: 00000000     0 SECTION LOCAL  DEFAULT    6
    10: 00000000     4 OBJECT  GLOBAL DEFAULT    3 global_int_var
    11: 00000004     4 OBJECT  GLOBAL DEFAULT  COM global_unint_var
    12: 00000000    27 FUNC    GLOBAL DEFAULT    1 fun1
    13: 00000000     0 NOTYPE  GLOBAL DEFAULT  UND printf
    14: 0000001b    49 FUNC    GLOBAL DEFAULT    1 main
    15: 00000000     0 NOTYPE  GLOBAL DEFAULT  UND func1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上输出分别对应了 &lt;code&gt;/usr/include/elf.h&lt;/code&gt; 中的符号表文件结构。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;typedef struct
{
  Elf32_Word    sh_name;        /* Section name (string tbl index) */
  Elf32_Word    sh_type;        /* Section type */
  Elf32_Word    sh_flags;       /* Section flags */
  Elf32_Addr    sh_addr;        /* Section virtual addr at execution */
  Elf32_Off sh_offset;      /* Section file offset */
  Elf32_Word    sh_size;        /* Section size in bytes */
  Elf32_Word    sh_link;        /* Link to another section */
  Elf32_Word    sh_info;        /* Additional section information */
  Elf32_Word    sh_addralign;       /* Section alignment */
  Elf32_Word    sh_entsize;     /* Entry size if section holds table */
} Elf32_Shdr;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中 &lt;code&gt;sh_info&lt;/code&gt; 为符号类型和绑定信息。其中低4位为符号类型，高4位位符号绑定信息。对应输出中的 &lt;code&gt;Type&lt;/code&gt; 与 &lt;code&gt;Bind&lt;/code&gt; 两项。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type 类型&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;NOTYPE&lt;/td&gt;
&lt;td&gt;未知类型符号&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;OBJECT&lt;/td&gt;
&lt;td&gt;数据对象，如变量、数组&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;FUNC&lt;/td&gt;
&lt;td&gt;函数或其他可执行代码&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;SECTION&lt;/td&gt;
&lt;td&gt;表示一个段&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;FILE&lt;/td&gt;
&lt;td&gt;表示文件名&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Bind 类型&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;LOCAL&lt;/td&gt;
&lt;td&gt;局部符号，目标文件外部不可见&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;GLOBAL&lt;/td&gt;
&lt;td&gt;全局符号，外部课件&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description>
        </item>
      
    
      
        <item>
          <title>笔记法总结</title>
          <link>https://maodanp.github.io/2019/05/18/notes-summary/</link>
          <pubDate>Sat, 18 May 2019 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2019/05/18/notes-summary/</guid>
          <description>&lt;p&gt;职场五六年，对如何做笔记也有自己的一点心得体会，这里总结对自己有帮忙的方法。&lt;/p&gt;

&lt;h3 id=&#34;笔记的结构体系&#34;&gt;笔记的结构体系&lt;/h3&gt;

&lt;p&gt;笔记记录的越多，就感觉越庞杂，为笔记建立一个简单，有效的整理体系是非常必要的。该体系的大概运作流程为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;收集&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;将获得的数据、知识放入笔记的的「inbox」组中。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;整理与完善&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;将「inbox」中的笔记进行编辑、整理、完善（如笔记总结，内容标题修改，添加标签等）。 将编辑好之后的笔记放置到对应类别的笔记本中。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;应用&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;定时翻看，记忆笔记。特别是对自己重要的或者自己专业的笔记，需要转化为实践，通过实践应用，与他人分享或者写技术文章等等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;归档&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于已经内化为自己的知识，可以放在归档的目录中，或者删除，为后续学习腾出空间。&lt;/p&gt;

&lt;p&gt;对笔记的分类可以参考&lt;a href=&#34;https://zh.wikipedia.org/wiki/杜威十进制图书分类法&#34;&gt;十进制图书分类法&lt;/a&gt;为笔记分层级。对于文件夹而言，层级有三位数，表示三个层级。&lt;/p&gt;

&lt;p&gt;第一层级用100、200、300&amp;hellip;&amp;hellip;表示最大分类；到第二层级，表示第一层级下面的子分类，比如100下面有110、120、130&amp;hellip;&amp;hellip;；到第三层表示第二层的子分类，也是最小的一层分类，在该目录下就可以放相关笔记了。&lt;/p&gt;

&lt;h3 id=&#34;康奈尔笔记法&#34;&gt;康奈尔笔记法&lt;/h3&gt;

&lt;p&gt;康奈尔学习笔记法适合学生或者职场充电者，能够有效的提升学习能力。&lt;/p&gt;

&lt;p&gt;该笔记法包括记录（Record）、简化（Reduce）、背诵（Recite）、思考（Reflect）、复习（Review）, 所以该笔记法又称为&lt;code&gt;5R&lt;/code&gt;笔记法&lt;/p&gt;

&lt;p&gt;印象笔记模板中有现成的康奈尔笔记法模板，可以直接拿来就用，但是模板只是形式，关键还是看怎么利用。&lt;/p&gt;

&lt;p&gt;下面是我的我学习一个技术点的康奈尔笔记总结：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://maodanp.github.io/pic/2019/2019-05-18-notes-summary.png&#34; alt=&#34;康奈尔笔记&#34; /&gt;&lt;/p&gt;

&lt;p&gt;文稿中的图，第一部分叫做提示栏，第二部分为笔记栏，第三部分为总结栏。&lt;/p&gt;

&lt;p&gt;第一步：记录（Record）&lt;/p&gt;

&lt;p&gt;将你听到的或者看到的记在右边的笔记栏，当然不是照搬全文，而是在理解的基础上记录觉得对自己有用的，或者跟主题相关的。&lt;/p&gt;

&lt;p&gt;第二步：简化（Reduce）&lt;/p&gt;

&lt;p&gt;这一步考察了我们的提炼和概括的能力。简化可以从两方面入手：
第一是寻找主题词，即根据主题中各个小的主题概括；第二是以问题为导向进行概括、简化。&lt;/p&gt;

&lt;p&gt;第三步：背诵（Recite）&lt;/p&gt;

&lt;p&gt;写完两栏笔记之后，第三步需要做的是背诵，背诵的目的就是为了记忆，以便内化成自己的知识，在记忆过程中，遮住右侧的笔记栏，用提示栏中的概要提示，尽量完整的复述右侧的内容。&lt;/p&gt;

&lt;p&gt;第四步：思考（Reflect）&lt;/p&gt;

&lt;p&gt;背诵完后，就可以写总结栏了，这一步写下的东西应该是笔记内容的浓缩和升华，如果有能给力还可以加上自己对笔记内容的思考，提炼出自己的原创观点。&lt;/p&gt;

&lt;p&gt;第五步：复习（Review）&lt;/p&gt;

&lt;p&gt;复习是必不可少的一步，可以按照时间与需求进行复习。&lt;/p&gt;

&lt;p&gt;按时间复习建议分别在记完笔记的当天、第二天、一周后、一个月后进行复习，进行不断的重复与强化记忆将更加牢固。一个月后，可以按需求复习，如果笔记上的内容在工作中用到了，在需要时可以将笔记拿出来复习。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>宝宝出生记</title>
          <link>https://maodanp.github.io/2019/05/15/baby-born/</link>
          <pubDate>Wed, 15 May 2019 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2019/05/15/baby-born/</guid>
          <description>&lt;p&gt;宝宝出生也将近一周岁了，我也在适应着作为父亲的这个角色。老婆也早已经做完月子，开始了正常的上班生活，还跟我调侃说早就忘记了生娃时所受的痛苦了。&lt;/p&gt;

&lt;p&gt;这么重要的人生阶段我想很有必要记录一段，以后也能时常回忆。&lt;/p&gt;

&lt;h3 id=&#34;入院&#34;&gt;入院&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;忐忑，等待宝宝的自然降临&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;由于预产期过了一周了，老婆肚子一直没有产前的征兆，按照医生的指导，预产期过一周没反应直接就可以住院了，这一周也是我很忐忑的时间，一方面工作上有些要忙，另一方面在焦急的等着宝宝的随时发动。&lt;/p&gt;

&lt;p&gt;最终还是等了一周，工作上也阶段性完工。7月13号当天，和老婆，拖着一个大行李箱，还拎着几个大包开开心心的打车去医院，做好了顺产的准备。&lt;/p&gt;

&lt;h3 id=&#34;住院&#34;&gt;住院&lt;/h3&gt;

&lt;p&gt;住院的一周是对老婆也许是最痛苦的，对我也是如此，焦急的等待。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2018-07-11&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;满以为当天可以拎包住院的，结果还得挂专家号，做完各种检查后开了住院证明。跑去住院部结果护士说没病房了，难道还得让我们回去等病房空出来不成？结果又回去找了专家，给安排了病房，看来这年头挂专家号花大钱还是有必要的，不然连病房都没有。&lt;/p&gt;

&lt;p&gt;下午终于能入住了，B座17号床位。四个床位，病房却很小。床位间距非常的窄，想想这点不算啥，毕竟住不了两天就能回去了。&lt;/p&gt;

&lt;p&gt;晚上医生给老婆用了宫颈扩张手段，果然见效，逐渐疼痛感增强，我在一旁只能在病床上安慰她。到凌晨两三点老婆宫缩的感觉比较剧烈，急忙喊了护士，问护士这个怎么办，护士淡定的将老婆推进了产房，顺带了待产的产褥垫、宝宝出生的衣物等等，由于产房外人不能进入，我也只能在外面干等着。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2018-07-12 等待&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;焦急的等待，与产房里面的老婆也只能通过微信沟通，上午人工破水了，然后还打了催产针，老婆说自己极其疼痛，我唯一能够做的也只有安慰。同时买了便盆，零食，水果之类的委托产房里的阿姨送进去。不停的在产房外面踱步打转。&lt;/p&gt;

&lt;p&gt;晚上在病房里租了个躺椅，安慰老婆要坚持，能睡就多睡睡，估计那种疼痛也很难入眠。同一个病房里有两位产妇的宝宝已经出生了，所以晚上时不时会听到宝宝们的啼哭声。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2018-07-13 降生&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;熬到了13号了，老婆早上发信息给我说已经开了二指，又打了催产针，我心里顿时也安定了些，离宝宝出来更进一步了。结果没过多久，老婆说羊水有些浑浊，有待继续观察，如果三级浑浊就需要剖宫产了。那是的我也是无比的紧张，如果最终还是是做手术那这两天的罪是白受了。&lt;/p&gt;

&lt;p&gt;下午老婆发微信来了，说羊水极度浑浊，如果做完胎监不稳定的话就得剖宫产了。作为病人家属，我们也无法左右，只能听医生的，老婆的意思是剖了，想想已经坚持了一天两夜了，如果要剖也没有任何办法。胎监不稳，产房医生出来，拿了手术风险知情书，简单描述了目前老婆所处状况，如果再等宝宝会有风险；但是如果手术可能会有手术的不确定风险，我大概看了下就签了。&lt;/p&gt;

&lt;p&gt;下午两点左右，老婆被推出了产房，要推到二楼的手术室，我看着老婆憔悴哭泣的面庞不停的说着我本来想顺产的，都坚持这么久了……看到老婆这样的自责与无奈，我心都快碎了，没事的，咱没事的……被推进了手术室，此时我妈赶到了。&lt;/p&gt;

&lt;p&gt;之前老婆让我回家拿吸奶器，宝宝生了要催奶，我想利用手术的这段时间我就回去拿一下吧，于是赶紧打车往家里奔。还没来得及赶回医院，我妈打电话过了，说已经生了，是个男宝，7.8斤此时大概是14:30分。我长舒了一口气，母子平安就好。于是宝宝被推进产房了清理，老婆在手术室继续观察。&lt;/p&gt;

&lt;p&gt;过了一个小时左右，老婆被推出了手术室，第一句话是宝宝呢，在手术室呢，你别担心。由于怕混浊的羊水的感染，医院对宝宝打了抗生素，等推到我们病房前的时候，看着那么小的手里插着几根针管，心真疼。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2019/2019-05-15-baby-born-1.png&#34; alt=&#34;&#34; /&gt;
宝宝睡得如此安然，仔细打量了起来，头相比整个身子显得尤其大，估计长大后头型像你爹呀。咪咪的小妖精，再看旁边病床上的老婆，不对呀，难道又继承了我的优良传统？两个脸颊圆嘟嘟的，鼻子，小嘴，感觉有些你妈妈的样子了，综合来看，以后只能培养你走实力派路线了。&lt;/p&gt;

&lt;p&gt;晚上丈母娘，老婆的舅舅、舅妈、弟弟也从老家专程赶来，一下子气氛也热闹了很多，看老婆的精神也恢复的很快，也就安心了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2018-07-14 ~ 2018-07-16 带娃&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;剖宫产后需要几天恢复，老婆每天挂着盐水，抗生素啥，镇痛棒等等，宝宝每天也需要推一针抗生素，每天除了吃就是睡。&lt;/p&gt;

&lt;p&gt;由于前期没有做足功课，宝宝躺在婴儿床里我尽无所适从。一大堆问题冒上来了，抱姿是啥样的？怎么哄睡？一次多少毫升水兑多少奶？遇到不懂的只能厚着脸皮，问隔壁床上的产妇。同事之前还提醒有必要在医院请个护工照顾宝宝，能够学些经验，看来这个经验也很有必要。经过一两天的摸索，带娃也算是顺手了。&lt;/p&gt;

&lt;h3 id=&#34;出院&#34;&gt;出院&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;2018-07-17&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;出院的心情是美好的，从医院拿了各种证件，宝宝医学出生证明，老婆的生育证明，医院的住院小结等等，开开心心的回家了。&lt;/p&gt;

&lt;h3 id=&#34;坐月子&#34;&gt;坐月子&lt;/h3&gt;

&lt;p&gt;老婆这一个月非常的辛苦，前期母乳不怎么够，想着如何催乳，也是每天鱼汤，猪蹄汤炖着。每天晚上都不能睡个完整觉了，隔两三个小时就的起来喂一次奶。伴随着腰痛，老寒腿，伤口痛。&lt;/p&gt;

&lt;p&gt;宝宝每天苦恼，我们俩也是干着急，感觉永远没吃饱，后来网上查阅才发现可能是腹绞痛。脸上新生儿痤疮比较多，屁股上由于之前用尿不湿被捂出了红屁股。&lt;/p&gt;

&lt;p&gt;过一个月去社区医院体检发现宝宝长了一斤都不到，一般都会长两斤，难道这一月之前没有给他吃饱？我们俩满是内疚……&lt;/p&gt;

&lt;h3 id=&#34;后续&#34;&gt;后续&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2019/2019-05-15-baby-born-2.png&#34; alt=&#34;&#34; /&gt;
宝宝每个月都在成长，在接触新的东西。 从能够抱着挺直腰背，到能够坐，能够扶着走； 从打哈哈，到咿咿呀呀的叫，到现在能够说出爸爸妈妈；从手指触碰东西，到能够正常抓握。每天都在成长，每天都在变化。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>基于redis的分布式锁的实现方案</title>
          <link>https://maodanp.github.io/2016/09/16/redis-lock/</link>
          <pubDate>Fri, 16 Sep 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/09/16/redis-lock/</guid>
          <description>&lt;p&gt;在不同进程需要互斥的访问共享资源时，分布式锁是一种常用的技术手段。目前主要有几种解决方法，一种是借助于DB的事务来实现，另一种是借助于分布式键值存储系统(例如etcd, zookeeper等)实现。本篇主要介绍如何通过redis实现分布式锁。&lt;/p&gt;

&lt;p&gt;使用redis实现分布式锁也是常用的方案，因为本身redis在互联网产品应用中基本都会使用到，而且不用再依赖额外的etcd、zookeeper，另外相对于数据库事务实现的分布式锁，redis实现的性能相对来说会更高。&lt;/p&gt;

&lt;h3 id=&#34;分布式锁的基本属性&#34;&gt;分布式锁的基本属性&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;互斥性：对于分布式锁来说，最基本的就是互斥性了，即不管在何时，只能有一个节点获得该锁&lt;/li&gt;
&lt;li&gt;无死锁：拿到锁的节点挂掉了，没有释放锁，不会导致其它节点永远无法继续&lt;/li&gt;
&lt;li&gt;高性能：分布式锁不能成为影响系统性能的瓶颈&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;redis单例实现分布式锁&#34;&gt;Redis单例实现分布式锁&lt;/h3&gt;

&lt;p&gt;我们可以通过单个Redis实例实现分布式锁机制，这也是后续Redis集群实现的基础。我们可以利用Redis的不同API实现锁，但大致思想都是类似的：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;获取当前时间，这里为更高的提供精度，可以设置为毫秒&lt;/li&gt;
&lt;li&gt;请求锁，实际就是向Redis中写入key(包括锁的&lt;strong&gt;过期时间&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;如果锁获取成功了，则返回成功&lt;/li&gt;
&lt;li&gt;如果锁获取失败了，则等待一定的时间(&lt;strong&gt;重试时间&lt;/strong&gt;)，重新竞争锁资源&lt;/li&gt;
&lt;li&gt;如果超过一定的时间(&lt;strong&gt;超时时间&lt;/strong&gt;) 还没有竞争到锁，则返回失败，后续是否继续获取锁由调用者决定。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上述步骤中引入这些时间是必要的，能够避免死锁问题。但是时间设定一般需要遵循以下的规则：&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;code&gt;重试时间&lt;/code&gt; &amp;lt; &lt;code&gt;过期时间&lt;/code&gt; &amp;lt; &lt;code&gt;超时时间&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;set实现方案&#34;&gt;SET实现方案&lt;/h4&gt;

&lt;p&gt;要获得锁，可以用下面这个命令：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SET key random_value NX PX 300
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该命令的作用是在只有这个&lt;code&gt;key&lt;/code&gt;不存在的时候才会设置这个&lt;code&gt;key&lt;/code&gt;的值(&lt;code&gt;NX&lt;/code&gt;选项的作用)，如果存在则不做任何动作直接返回；超时时间设为300毫秒(&lt;code&gt;PX&lt;/code&gt;选项的作用).&lt;/p&gt;

&lt;p&gt;这里&lt;code&gt;key&lt;/code&gt;的值是&lt;code&gt;random_value&lt;/code&gt;，这个值必须在所有获取锁请求的客户端里保持唯一。 基本上这个随机值就是用来保证能安全地释放锁，因为每个锁只能被获得锁的节点删除，如果被其他节点删除，而获得锁的节点任务还没完成，其他节点会再次获得该锁，这样就违背了锁的互斥性。&lt;/p&gt;

&lt;p&gt;我们可以用下面的Lua脚本来实现锁的释放，保证获取锁与释放锁的节点是同一个。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;if redis.call(&amp;quot;get&amp;quot;,KEYS[1]) == ARGV[1] then
        return redis.call(&amp;quot;del&amp;quot;,KEYS[1])
    else
        return 0
    end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Lock()&lt;/code&gt;方法的代码大致如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (r *RedisLock) Lock() (lock bool, err error) {
	until := time.Now().Add(r.TimeOut)
	for {
		// 大于超时时间，则返回超时
		if time.Now().Before(until) == false {
			return false, fmt.Errorf(&amp;quot;timeout&amp;quot;)
		}

		curTime := time.Now().UnixNano() / int64(time.Millisecond)
		conn := r.RedisPool.Get()
		// 过期时间
		reply, err := redis.String(conn.Do(&amp;quot;SET&amp;quot;, m.Name, curTime, &amp;quot;NX&amp;quot;, &amp;quot;PX&amp;quot;, int(r.Expiry/time.Millisecond)))
		conn.Close()
		if err != nil {
			goto LOCK_RETRY
		}
		if reply != &amp;quot;OK&amp;quot; {
			goto LOCK_RETRY
		}
		return true, nil
		
	LOCK_RETRY:
		//重试时间
		time.Sleep(r.Delay)
	}
	return
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上&lt;code&gt;Lock()&lt;/code&gt;方法的实现还是相对简单的，其中&lt;code&gt;r.TimeOut&lt;/code&gt;为该方法的超时时间，&lt;code&gt;r.Expiry&lt;/code&gt;为该锁在Redis存储的过期时间，&lt;code&gt;r.Delay&lt;/code&gt;为尝试获取锁的重试间隔。&lt;/p&gt;

&lt;h4 id=&#34;lua脚本实现方案&#34;&gt;LUA脚本实现方案&lt;/h4&gt;

&lt;p&gt;SET方案相当于将&lt;code&gt;SET&lt;/code&gt;，&lt;code&gt;NX&lt;/code&gt;，&lt;code&gt;PX&lt;/code&gt;合成了一个步骤，并由Redis保证它们的原子性。当然，我们也可以采用&lt;code&gt;lua&lt;/code&gt;脚本方式，保证三者的原子性。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;var setScript = redis.NewScript(1, `
if redis.call(&amp;quot;SET&amp;quot;, KEYS[1], ARGV[1], &amp;quot;NX&amp;quot;) == ARGV[1] then
	return redis.call(&amp;quot;EXPIRE&amp;quot;, KEYS[1], ARGV[2])
else
	return &amp;quot;ERR&amp;quot;
end`)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样我们就可以使用如下代码代替上述的SET实现方案：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;reply, err := setScript.Do(conn, m.Name, curTime, int(r.Expiry/time.Millisecond))
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;setnx-get-getset-实现方案&#34;&gt;SETNX+GET+GETSET 实现方案&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;SET val NX PX expire&lt;/code&gt;方式是&lt;strong&gt;Redis2.6&lt;/strong&gt;之后的版本引入的。如果生产环境不支持该用法，或者没有意识到可以利用&lt;code&gt;LUA&lt;/code&gt;脚本保证其原子性，那么是否还有其他的实现方式？&lt;/p&gt;

&lt;p&gt;我们可以通过&lt;code&gt;SETNX&lt;/code&gt;+&lt;code&gt;GET&lt;/code&gt;+&lt;code&gt;GETSET&lt;/code&gt;命令方式实现。主要步骤如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;调用&lt;code&gt;SETNX&lt;/code&gt;命令，是否返回设置成功则表示获取了锁，未成功则进行后续操作&lt;/li&gt;
&lt;li&gt;调用&lt;code&gt;GET&lt;/code&gt;命令，返回&lt;code&gt;valGet&lt;/code&gt;. 将&lt;code&gt;当前时间&lt;/code&gt;与&lt;code&gt;valGet&lt;/code&gt;之差与&lt;code&gt;过期时间&lt;/code&gt;比较，如果未达到过期时间，则sleep后重新尝试获取锁；如果大于过期时间了，则继续后续操作&lt;/li&gt;
&lt;li&gt;调用&lt;code&gt;GETSET&lt;/code&gt;命令，设置新的当前时间，并且返回Redis中的值&lt;code&gt;valGetSet&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;比较&lt;code&gt;valGet&lt;/code&gt;与&lt;code&gt;valGetSet&lt;/code&gt;，如果一致，则说明该节点获取了锁，如果不一致，则说明在该节点&lt;code&gt;GETSET&lt;/code&gt;之前，已经被其他节点&lt;code&gt;GETSET&lt;/code&gt;成功了(即表示其他节点获得了该锁)，则sleep后重新尝试获取锁&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;Lock()&lt;/code&gt;方法的代码大致如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (r *RedisLock) Lock() (lock bool, err error) {
	until := time.Now().Add(r.TimeOut)
	for {
		// timeOut
		if time.Now().Before(until) == false {
			return false, fmt.Errorf(&amp;quot;timeout&amp;quot;)
		}
		curTime := time.Now().UnixNano() / int64(time.Millisecond)
		succ, _ := r.cmdSetnx(r.Name, curTime)
		if succ {
			r.Value = curTime
			return true, nil
		}

		var valGet, valGetSet int64
		valGet, err = r.cmdGet(r.Name)
		// the lock is deleted when cmd GET returs err(nil returned)
		// so sleep and retry to run cmd SETNX
		// 锁已经被释放，则重新竞争
		if err != nil {
			goto LOCK_RETRY
		} else {
			// the lock is captured now
			// 锁还被占用着，如果锁未达到超时时间，则重新竞争
			if int64(r.Expiry/time.Millisecond) &amp;gt; curTime-valGet {
				goto LOCK_RETRY
			}
		}

		// the lock is timeout, so involve the race
		// 存储新的，返回旧的值
		valGetSet, err = r.cmdGetSet(r.Name, curTime)
		// the lock is deleted when cmd GETSET returs err(nil returned)
		// so sleep and retry to run cmd SETNX
		// 可能到这一步锁正好已经释放了，则重新竞争
		if err != nil {
			goto LOCK_RETRY
		}

		// haha, I get the lock!!
		// 如果GET的值与GETSET的值相等，则该协程获得了锁
		if valGet == valGetSet {
			r.Value = valGet
			return true, nil
		}

	LOCK_RETRY:
		time.Sleep(r.Delay)
	}
	return
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上为&lt;code&gt;SETNX&lt;/code&gt;+&lt;code&gt;GET&lt;/code&gt;+&lt;code&gt;GETSET&lt;/code&gt;命令方式实现的&lt;code&gt;Lock()&lt;/code&gt;方法，可以看到，相比于之前两种实现就稍微有些复杂了，需要考虑的地方较多。该方案的整体实现可以在我的&lt;a href=&#34;https://github.com/maodanp/redis-lock&#34;&gt;redislock&lt;/a&gt;中看到。&lt;/p&gt;

&lt;h3 id=&#34;redis集群实现分布式锁&#34;&gt;Redis集群实现分布式锁&lt;/h3&gt;

&lt;p&gt;基于Redis单例的实现方式是一种理想的环境，对于一个非分布式的、单点的，保证永不宕机的环境而言，是没有任何问题的。但是在分布式环境中，如果假设有N个Redis master节点，又该如何实现分布式锁？&lt;/p&gt;

&lt;p&gt;在Redis的官方文档中提供了官方的实现方案：&lt;a href=&#34;https://github.com/antirez/redis-doc/blob/master/topics/distlock.md&#34;&gt;Redlock算法&lt;/a&gt;。大体实现步骤如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;获取当前时间（单位是毫秒）&lt;/li&gt;
&lt;li&gt;轮流用相同的key和随机值在N个节点上请求锁，这一步相当于回归到了单节点获取锁的方式。如果一个master节点不可用了，我们应该尽快尝试下一个master节点。&lt;/li&gt;
&lt;li&gt;客户端计算第二步中获取锁所花的时间，只有当客户端在大多数master节点上成功获取了锁(N/2+1)，而且总共消耗的时间不超过锁释放时间，这个锁就认为是获取成功了&lt;/li&gt;
&lt;li&gt;如果锁获取成功了，那现在锁自动释放时间就是最初的锁释放时间减去之前获取锁所消耗的时间&lt;/li&gt;
&lt;li&gt;如果锁获取失败了，不管是因为获取成功的锁不超过一半(N/2+1)还是因为总消耗时间超过了锁释放时间，客户端都会到每个master节点上释放锁，即便是那些他认为没有获取成功的锁&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;关于Redis集群的实现方案可以参考Go语言&lt;a href=&#34;https://github.com/hjr265/redsync.go&#34;&gt;Redsync.go&lt;/a&gt;。官方文档也对安全性、可用性等做了论述，总体来说相对于DB的分布式锁实现应该还是具有很大的性能优势的，但是与etcd，zk的性能比较，这个还有待验证。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/antirez/redis-doc/blob/master/topics/distlock.md&#34;&gt;dist-lock&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ifeve.com/redis-lock/&#34;&gt;dist-lock译文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/ugg/article/details/41894947&#34;&gt;基于Redis实现分布式锁&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>创建基于proxy的HTTP(s)连接</title>
          <link>https://maodanp.github.io/2016/09/11/golang-https-proxy/</link>
          <pubDate>Sun, 11 Sep 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/09/11/golang-https-proxy/</guid>
          <description>&lt;p&gt;最近遇到了几次HTTP(s)如何通过代理访问内网的问题，本篇讲述基于proxy发送/接收HTTP(s)请求的客户端实现方法。&lt;/p&gt;

&lt;p&gt;开发者可能比较熟悉如何编写&lt;code&gt;http/https&lt;/code&gt;的网络编程(包含客户端/服务端)。在&lt;code&gt;net/http&lt;/code&gt;的标准库中也有相关很多示例。但是如何基于&lt;code&gt;proxy&lt;/code&gt;创建HTTP(s)的连接，这个并不一定熟悉。&lt;/p&gt;

&lt;p&gt;下面依次介绍两种方法，都能够实现HTTP(s)的代理转发:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;第一种是直接通过对&lt;code&gt;http.Transport&lt;/code&gt;的&lt;code&gt;proxy&lt;/code&gt;字段设置代理，然后按照的客户端访问方式编写；&lt;/li&gt;
&lt;li&gt;第二种是根据代理协议，与&lt;code&gt;proxy&lt;/code&gt;先建立连接(传输层)，然后基于该连接再发送HTTP(s)数据(应用层)。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;http-client-创建代理连接&#34;&gt;&lt;code&gt;http.Client&lt;/code&gt;创建代理连接&lt;/h3&gt;

&lt;h4 id=&#34;基本方法&#34;&gt;基本方法&lt;/h4&gt;

&lt;p&gt;以下为客户端的常用方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (c *Client) Get(url string) (r *Response, err error)
func (c *Client) Post(url string, bodyType string, body io.Reader) (r *Response, err error)
func (c *Client) PostForm(url string, data url.Values) (r *Response, err error) func (c *Client) Head(url string) (r *Response, err error)
func (c *Client) Do(req *Request) (resp *Response, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常前三个基本能够满足条件，如果我们发起的HTTP请求需要更多的定制信息(增加HTTP头信息，传递Cookie等)，可以使用&lt;code&gt;Client.Do()&lt;/code&gt;方法来实现：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;req, err := http.NewRequest(&amp;quot;GET&amp;quot;, &amp;quot;http://example.com&amp;quot;, nil) // ...
req.Header.Add(&amp;quot;User-Agent&amp;quot;, &amp;quot;Gobook Custom User-Agent&amp;quot;)
// ...
client := &amp;amp;http.Client{ //... }
resp, err := client.Do(req)
// ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;高级封装&#34;&gt;高级封装&lt;/h4&gt;

&lt;p&gt;Go暴露了比较底层的HTTP相关库，让开发者灵活定制和使用HTTP服务。&lt;/p&gt;

&lt;h5 id=&#34;自定义http-transport&#34;&gt;自定义http.Transport&lt;/h5&gt;

&lt;p&gt;HTTP Client的Request结构主要操作是了HTTP Method, 目标URL，请求参数，请求内容等信息。而具体的HTTP的细节，都需要通过http.Transport去处理。比如：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HTTP底层传输细节&lt;/li&gt;
&lt;li&gt;HTTP代理&lt;/li&gt;
&lt;li&gt;gzip压缩&lt;/li&gt;
&lt;li&gt;连接池及管理&lt;/li&gt;
&lt;li&gt;认证（SSL或其他认证方式）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;http.Transport类型的具体结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Transport struct {
// Proxy指定用于针对特定请求返回代理的函数。
// 如果该函数返回一个非空的错误,请求将终止并返回该错误。
// 如果Proxy为空或者返回一个空的URL指针,将不使用代理
Proxy func(*Request) (*url.URL, error)
// Dial指定用于创建TCP连接的dail()函数。
// 如果Dial为空,将默认使用net.Dial()函数
Dial func(net, addr string) (c net.Conn, err error)
// TLSClientConfig指定用于tls.Client的TLS配置。
// 如果为空则使用默认配置
TLSClientConfig *tls.Config
DisableKeepAlives bool
DisableCompression bool
// 如果MaxIdleConnsPerHost为非零值,它用于控制每个host所需要
// 保持的最大空闲连接数。如果该值为空,则使用DefaultMaxIdleConnsPerHost 
MaxIdleConnsPerHost int
// ... 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中&lt;code&gt;Proxy&lt;/code&gt;指定了一个代理方法。如果 Proxy 未指定或者返回的 *URL 为零值,将不会有代理被启用；&lt;code&gt;TLSClientConfig&lt;/code&gt;指定 tls.Client 所用的 TLS 配置信息,如果不指定, 也会使用默认的配置；&lt;code&gt;DisableKeepAlives&lt;/code&gt;是否取消长连接,默认值为 false,即启用长连接；&lt;code&gt;DisableCompression&lt;/code&gt;是否取消压缩(GZip),默认值为 false,即启用压缩。&lt;/p&gt;

&lt;h4 id=&#34;通过proxy创建client示例&#34;&gt;通过proxy创建client示例&lt;/h4&gt;

&lt;p&gt;下面为客户端的代码，其中我们对http.Transport指定了&lt;code&gt;Proxy&lt;/code&gt;及&lt;code&gt;TLSClientConfig&lt;/code&gt;, 相当于封装了具体的HTTP实现细节，最后通过&lt;code&gt;http.Client.Get&lt;/code&gt;方法实现基于proxy的HTTP(s)代理。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
        &amp;quot;crypto/tls&amp;quot;
        &amp;quot;flag&amp;quot;
        &amp;quot;fmt&amp;quot;
        &amp;quot;net/http&amp;quot;
        &amp;quot;net/url&amp;quot;
        &amp;quot;time&amp;quot;
)

const timeout time.Duration = 10

func main() {
        // Parse cmdline arguments using flag package
        server := flag.String(&amp;quot;server&amp;quot;, &amp;quot;abhijeetr.com&amp;quot;, &amp;quot;Server to ping&amp;quot;)
        port := flag.Uint(&amp;quot;port&amp;quot;, 443, &amp;quot;Port that has TLS&amp;quot;)
        proxy := flag.String(&amp;quot;proxyURL&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;Proxy to use for TLS connection&amp;quot;)
        flag.Parse()

        // Prepare the client
        var client http.Client
        if *proxy != &amp;quot;&amp;quot; {
                proxyURL, err := url.Parse(*proxy)
                if err != nil {
                        panic(&amp;quot;Error parsing proxy URL&amp;quot;)
                }
                transport := http.Transport{
                        Proxy:           http.ProxyURL(proxyURL),
                        TLSClientConfig: &amp;amp;tls.Config{InsecureSkipVerify: true},
                }
                client = http.Client{
                        Transport: &amp;amp;transport,
                        Timeout:   time.Duration(time.Millisecond * timeout),
                }

        } else {
                client = http.Client{}
        }
        // Now we&#39;ve proper client, with or without proxy

        resp, err := client.Get(fmt.Sprintf(&amp;quot;https://%v:%v&amp;quot;, *server, *port))
        if err != nil {
                panic(&amp;quot;failed to connect: &amp;quot; + err.Error())
        }

        fmt.Printf(&amp;quot;Time to expiry for the certificate: %v\n&amp;quot;, resp.TLS.PeerCertificates[0].NotAfter.Sub(time.Now()))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;tls-client-创建代理连接&#34;&gt;&lt;code&gt;tls.Client&lt;/code&gt;创建代理连接&lt;/h3&gt;

&lt;p&gt;上述http.Client能够实现代理连接的创建，但是如果我们需要通过代理传输原始数据，即TCP层的数据传输，而不是应用层的HTTP数据传输，那么我们可以直接与&lt;code&gt;proxy&lt;/code&gt;先建立连接，然后基于该连接再发送HTTP(s)数据。&lt;/p&gt;

&lt;p&gt;分两个步骤完成：
1. 与&lt;code&gt;proxy&lt;/code&gt;建立连接，发送&lt;code&gt;CONNECT&lt;/code&gt;方法的HTTP请求
2. 复用步骤1中的connection，发送原始数据(HTTP/HTTPS需要通过接口写入该connection)&lt;/p&gt;

&lt;p&gt;下面分别通过描述&lt;/p&gt;

&lt;h4 id=&#34;建立连接&#34;&gt;建立连接&lt;/h4&gt;

&lt;p&gt;如下代码段所示，首先与&lt;code&gt;proxy&lt;/code&gt;建立connecton, 发送&lt;code&gt;CONNECT&lt;/code&gt;方法的HTTP请求。 如果&lt;code&gt;proxy&lt;/code&gt;返回了200，则后面就能够复用该连接了，否则与&lt;code&gt;proxy&lt;/code&gt;的连接就失败了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;if conn, err = net.Dial(&amp;quot;tcp&amp;quot;, proxyURL.Host); err != nil {
                panic(&amp;quot;Error net.Dial&amp;quot;)
                return
        }

// send an HTTP proxy CONNECT message
req, err := http.NewRequest(&amp;quot;CONNECT&amp;quot;, &amp;quot;https://&amp;quot;+server, nil)
if err != nil {
        panic(&amp;quot;Error http.NewRequest&amp;quot;)
        return
}
//组织http协议，写入该connection
req.Write(conn)

// 读取proxy的返回
resp, err := http.ReadResponse(bufio.NewReader(conn), req)
if err != nil {
        panic(&amp;quot;Error http.ReadResponse&amp;quot;)
        return
}
resp.Body.Close()

if resp.StatusCode != 200 {
        err = fmt.Errorf(&amp;quot;Non-200 response from proxy server: %s&amp;quot;, resp.Status)
        return
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;发送数据&#34;&gt;发送数据&lt;/h4&gt;

&lt;p&gt;有了该连接后，对于HTTP的请求就好办了，按照发送CONNECT方法的HTTP请求一样，我们可以通过&lt;code&gt;NewRequest&lt;/code&gt;创建&lt;code&gt;GET&lt;/code&gt;/&lt;code&gt;POST&lt;/code&gt;方法，然后写入&lt;code&gt;connection&lt;/code&gt;, 处理回应消息。完成整个请求流程。&lt;/p&gt;

&lt;p&gt;但是对于HTTPS的请求, 因为需要TLS协议的加密，所以不能简单的传递明文，需要传递加密后的数据，这个过程在Go的&lt;code&gt;crypto/tls&lt;/code&gt;包中已经实现了。我们需要对之前的connection再次封装一层，得到新的基于TLS协议的connection。&lt;/p&gt;

&lt;p&gt;代码段如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// 创建request结构
req, err = http.NewRequest(&amp;quot;GET&amp;quot;, &amp;quot;https://&amp;quot;+server, nil)
if err != nil {
        panic(&amp;quot;Error http.NewRequest&amp;quot;)
        return
}

//这里基于原先的conn创建了一个TLS的newConn
newConn := tls.Client(conn, proxyTlsConfig)

// 将request的相关信息写入到newConn中
// 后续将基于该newConn进行数据的读写操作
err = req.Write(newConn)
if err != nil {
        panic(&amp;quot;Error req.Write&amp;quot;)
        return
}
resp, err = http.ReadResponse(bufio.NewReader(newConn), req)
if err != nil {
        panic(&amp;quot;Error http.ReadResponse&amp;quot;)
        return
}
if respBody, err := ioutil.ReadAll(resp.Body); err != nil {
        panic(&amp;quot;Error http.ReadResponse&amp;quot;)
        return
} else {
        fmt.Printf(&amp;quot;resp: %s&amp;quot;, string(respBody))

}
resp.Body.Close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过以上方式，我们也能够传递其他原始数据，经过代理，并且经过加密传输。那基于该传输层的数据传输，对应的server端如何接收呢？&lt;/p&gt;

&lt;p&gt;我们可以创建密钥，证书。然后通过&lt;code&gt;tls.Listen&lt;/code&gt;方法监听指定端口。大致代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func main() {
    cer, err := tls.LoadX509KeyPair(&amp;quot;../cert_server/server.crt&amp;quot;, &amp;quot;../cert_server/server.key&amp;quot;)
    if err != nil {
        fmt.Println(err.Error())
    }
    config := &amp;amp;tls.Config{Certificates: []tls.Certificate{cer}}
    listener, erl := tls.Listen(&amp;quot;tcp&amp;quot;, &amp;quot;:8888&amp;quot;, config)
    if erl != nil {
        fmt.Println(erl.Error())
        return
    }
    for {
        conn, err := listener.Accept()
        checkErr(err)
        go Handle(conn)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;以上两种方式都能够实现通过proxy发送/接收HTTP(s)的请求。第一种方式相对来说简单，直接通过&lt;code&gt;http.Transport&lt;/code&gt;的&lt;code&gt;proxy&lt;/code&gt;字段设置就能通过代理发送请求，而第二种方式相对较为复杂，但是方法二更加的灵活，通过代理我们不仅能够收发HTTP(s)信息，同样也能对我们的原始数据进行加密传输。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.tuicool.com/articles/uIbUnmE&#34;&gt;Golang: Creating HTTPS connection via proxy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://golang.org/pkg/crypto/tls/&#34;&gt;https://golang.org/pkg/crypto/tls/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Go语言编程 Ch5 网络编程&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Liunx性能检测常用命令(二)</title>
          <link>https://maodanp.github.io/2016/09/04/linux-performace-cmd-two/</link>
          <pubDate>Sun, 04 Sep 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/09/04/linux-performace-cmd-two/</guid>
          <description>&lt;p&gt;&lt;a href=&#34;https://maodanp.github.io/2016/09/03/linux-performace-cmd-one&#34;&gt;前一篇&lt;/a&gt;讲述了Linux分析常用的一些命令，本篇继续分析其他常用命令。&lt;/p&gt;

&lt;h3 id=&#34;iostat&#34;&gt;iostat&lt;/h3&gt;

&lt;p&gt;iostat主要用于监控系统设备的IO负载情况。 主要用法如下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iostat -xz 1

Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await  svctm  %util
sda               0.00    51.00    0.00   22.00     0.00   648.00    29.45     0.00    0.05   0.05   0.10

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.88    0.00    0.38    0.04    0.00   98.70

Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await  svctm  %util
sda               0.00    20.00    0.00   16.00     0.00   288.00    18.00     0.01    0.75   0.06   0.10

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           3.69    0.00    0.88    0.00    0.00   95.43
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，&lt;code&gt;-x&lt;/code&gt;将用于显示和io相关的扩展数据; &lt;code&gt;-z&lt;/code&gt;将取消显示在该间隔统计数据中无io活动的设备。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;r/s, w/s, rkB/s, wkB/s&lt;/code&gt; 分别表示每秒读写次数和每秒读写数据量（千字节）。读写量过大，可能会引起性能问题。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;await&lt;/code&gt; IO操作的平均等待时间，单位是毫秒。这是应用程序在和磁盘交互时，需要消耗的时间，包括IO等待和实际操作的耗时。如果这个数值过大，可能是硬件设备遇到了瓶颈或者出现故障。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;avgqu-sz&lt;/code&gt; 向设备发出的请求平均数量。如果这个数值大于1，可能是硬件设备已经饱和（部分前端硬件设备支持并行写入）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;%util&lt;/code&gt; 设备利用率。这个数值表示设备的繁忙程度，经验值是如果超过60，可能会影响IO性能（可以参照IO操作平均等待时间）。如果到达100%，说明硬件设备已经饱和。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;free&#34;&gt;free&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;free -m

              total       used       free      shared     buffers   cached
Mem:           1002        769        232        0           62       421
-/+ buffers/cache:         286        715
Swap: 1153 0 1153
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一部分Mem行。该行是针对OS而言的，它认为buffers/cached都是属于被使用,所以它认为free只有232M。存在如下关系：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;total(1002M) = used(769M) + free(232M)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第二部分(-/+ buffers/cache)从应用程序的角度而言的，Mem行的buffers/cached 是等同可用的，因为buffer/cached是为了提高程序执行的性能，当程序使用内存时，buffer/cached会很快地被使用。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* (-buffers/cache) used内存数：286M (Mem行中的used – buffers – cached)
* (+buffers/cache) free内存数: 715M (Mem行中的free + buffers + cached)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;从应用的角度看，可用内存就是-/+ buffers/cache行的free&lt;/strong&gt;，如果可用内存非常少，系统可能会动用交换交换分区（如果配置了的话），这样会增加IO开销（可以在iostat命令中提现），降低系统性能。&lt;/p&gt;

&lt;h3 id=&#34;sar&#34;&gt;sar&lt;/h3&gt;

&lt;h4 id=&#34;网络设备的吞吐率&#34;&gt;网络设备的吞吐率&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;sar -n DEV 1&lt;/code&gt; 可以用于查看各个网络设备的吞吐量，判断网络设备的饱和度。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sar -n DEV 1

11时58分49秒     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s
11时58分50秒        lo    174.75    174.75     99.00     99.00      0.00      0.00      0.00
11时58分50秒       em1     27.27     19.19     13.53      3.12      0.00      0.00      1.01
11时58分50秒       em2      6.06      0.00      0.38      0.00      0.00      0.00      1.01
11时58分50秒       em3     98.99     94.95     37.58      7.10      0.00      0.00      0.00
11时58分50秒       em4      0.00      0.00      0.00      0.00      0.00      0.00      0.00
11时58分50秒   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00
11时58分50秒    virbr0      0.00      0.00      0.00      0.00      0.00      0.00      0.00
11时58分50秒 virbr0-nic     0.00      0.00      0.00      0.00      0.00      0.00      0.00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，&lt;code&gt;rxkB/s&lt;/code&gt;，&lt;code&gt;txkB/s&lt;/code&gt;分别表示网卡的单位时间的进出口流量。在排查性能问题时，可以通过网络设备的吞吐量，判断网络设备是否已经饱和。&lt;/p&gt;

&lt;h4 id=&#34;tcp连接状态&#34;&gt;TCP连接状态&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;sar -n TCP,ETCP 1&lt;/code&gt;可以用于查看TCP连接状态。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sar -n TCP,ETCP 1

12时03分21秒  active/s passive/s    iseg/s    oseg/s
12时03分22秒     13.13     11.11    277.78    283.84
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中参数含义：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;active/s：每秒本地发起的TCP连接数，既通过connect调用创建的TCP连接&lt;/li&gt;
&lt;li&gt;passive/s：每秒远程发起的TCP连接数，即通过accept调用创建的TCP连接&lt;/li&gt;
&lt;li&gt;retrans/s：每秒TCP重传数量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;TCP连接数可以用来判断性能问题是否由于建立了过多的连接，进一步可以判断是主动发起的连接，还是被动接受的连接。TCP重传可能是因为网络环境恶劣，或者服务器压力过大导致丢包。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.tuicool.com/articles/mAFjaq&#34;&gt;centos 下安装监控工具&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/zhaoyl/p/4325811.html&#34;&gt;正确解读free -m&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.chinaz.com/server/2013/0401/297942.shtml&#34;&gt;linux sar 命令详解&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>golang中context包</title>
          <link>https://maodanp.github.io/2016/09/04/go/</link>
          <pubDate>Sun, 04 Sep 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/09/04/go/</guid>
          <description>&lt;p&gt;在阅读一些标准库(net、net/http、os/exec)时，经常会遇到context包，大致知道是当做关闭事件触发用的。阅读完GoTeam的文章&lt;a href=&#34;https://blog.golang.org/context&#34;&gt;Go Concurrency Patterns: Context&lt;/a&gt;，才更深刻的了解了其设计意图。&lt;/p&gt;

&lt;p&gt;一般我们会通过&lt;code&gt;select + channel&lt;/code&gt;的方式去终止一个协程，这也是最简单的情况。我们可以考虑些稍微复杂的情形，比如在写Go的Server服务，context包能够使得传递某些信息给相关的处理协程变得很简单，这些传递信息包括：&lt;strong&gt;请求域的值(request-scoped values)&lt;/strong&gt;、&lt;strong&gt;中断信号(cancelation signals)&lt;/strong&gt;、&lt;strong&gt;过期时间&lt;/strong&gt;等。或者想中止某个goroutine创建的goroutines，使用context也很方便。&lt;/p&gt;

&lt;p&gt;目前Go1.7将原来的&lt;code&gt;golang.org/x/net/context&lt;/code&gt;包挪入了标准库中，放在&lt;code&gt;$GOROOT/src/context&lt;/code&gt;，可见context模式用途广泛。&lt;/p&gt;

&lt;h3 id=&#34;context接口&#34;&gt;Context接口&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;context&lt;/strong&gt;包的核心是一个&lt;strong&gt;Context&lt;/strong&gt;类型：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Context包 携带信息包括过期时间、中止信号，参数值等
// context 包里的方法是线程安全的，可以被多个 goroutine 使用
type Context interface {

    // 当Context被canceled或times out的时候，Done返回一个被close的channel 
    Done() &amp;lt;-chan struct{}

    // 在Done的channel被closed后， Err代表被关闭的原因   
    Err() error

    // 如果存在，Deadline返回Context将要关闭的时间 
    Deadline() (deadline time.Time, ok bool)

    // 如果存在，Value返回与key相关了的值，不存在返回nil  
    Value(key interface{}) interface{}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的Done方法返回了一个通道，代表了Context的一个中止信号：当这个通道关闭，函数将中止并且立即返回。Err方法也将返回为何被终止的错误。&lt;/p&gt;

&lt;p&gt;Done方法返回的通道是只读的，所以Context并没有提供Cancel方法来关闭通道。这个也比较好理解，比如当一个协程创建了很多的子协程，这些子协程不能够中止父协程的。而父协程则可以通过WithCancel函数(后面描述)提供的一种方式来中止子协程。&lt;/p&gt;

&lt;h3 id=&#34;派生的结构&#34;&gt;派生的结构&lt;/h3&gt;

&lt;p&gt;context包为我们提供了两个Context包的实现，Background()与TODO()。只是返回的这两个实例都是空 Context。它们没有过期时间，没有任何值，一般在&lt;code&gt;main&lt;/code&gt;,&lt;code&gt;init&lt;/code&gt;,&lt;code&gt;tests&lt;/code&gt;等函数中，当做对上层的Context使用，其他Context往往派生于它们(一般嵌入到其他Context中)。&lt;/p&gt;

&lt;h4 id=&#34;cancelctx&#34;&gt;cancelCtx&lt;/h4&gt;

&lt;p&gt;cancelCtx结构体继承了Context ，实现了canceler方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;//*cancelCtx 和 *timerCtx 都实现了canceler接口，实现该接口的类型都可以被直接canceled
type canceler interface {
    cancel(removeFromParent bool, err error)
    Done() &amp;lt;-chan struct{}
}        

type cancelCtx struct {
    Context
    done chan struct{} // closed by the first cancel call.
    mu       sync.Mutex
    children map[canceler]bool // set to nil by the first cancel call
    err      error             
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，核心方法是&lt;code&gt;cancel&lt;/code&gt;。该方法会依次遍历c.children，每个child分别cancel；如果设置了removeFromParent，则将c从其parent的children中删除&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (c *cancelCtx) cancel(removeFromParent bool, err error) {
      //...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以通过WithCancel函数来创建一个cancelCtx。返回一个 cancelCtx的结构，同时也会返回一个CancelFunc自定义函数，调用该函数，将会关闭对应的c.done，也就是让他的后代goroutine退出。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func WithCancel(parent Context) (ctx Context, cancel CancelFunc) {
    //...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;timerctx&#34;&gt;timerCtx&lt;/h4&gt;

&lt;p&gt;timerCtx 结构继承 cancelCtx。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type timerCtx struct {
    cancelCtx //此处的封装为了继承来自于cancelCtx的方法，cancelCtx.Context才是父亲节点的指针
    timer *time.Timer // 计时器
    deadline time.Time
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以通过下面两个函数来创建timerCtx：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)
func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;WithDeadline 和 WithTimeout 是相似的，WithDeadline 是设置具体的deadline时间，到达deadline的时候，派生goroutine退出；WithTimeout设置的是时间间隔。&lt;/p&gt;

&lt;h4 id=&#34;valuectx&#34;&gt;valueCtx&lt;/h4&gt;

&lt;p&gt;valueCtx 结构实现了Cancel接口。该结构多了一对key,val的值。其派生goroutine通过Context以及key都能得到响应的val。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type valueCtx struct {
    Context
    key, val interface{}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;示例&#34;&gt;示例&lt;/h3&gt;

&lt;p&gt;下面模拟了一个累加器，通过context传递累加的上限。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
        &amp;quot;context&amp;quot;   //go1.7以上版本直接使用标准库中的context
        &amp;quot;fmt&amp;quot;
        &amp;quot;time&amp;quot;
)

// 模拟累加器
func accumulator(ctx context.Context) (res int) {
        loop, ok := ctx.Value(userKey).(int)
        if !ok {
                return 0
        }

        // 直到累加结束或者收到closed channel
        for i := 0; i &amp;lt; loop; i++ {
                res += i
                select {
                case &amp;lt;-ctx.Done():
                        fmt.Println(&amp;quot;need to done&amp;quot;)
                        return res
                default:
                }
        }
        fmt.Println(&amp;quot;finish calculate&amp;quot;)
        return res
}

type key int

const userKey key = 0

func main() {
        // cancelCtx
        ctx, cancel := context.WithCancel(context.Background())
        // valueCtx
        newCtx := context.WithValue(ctx, userKey, 10000000)

        go func() {
                time.Sleep(1 * time.Millisecond)
                cancel() // 在调用处主动取消
        }()
        res := accumulator(newCtx)
        fmt.Printf(&amp;quot;accumulato result: %d\n&amp;quot;, res)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;在请求的输入输出函数中，一般讲context作为首个参数传递。它能够非常简便的控制超时、中止等操作，并且也能够确保信息在goroutine中的安全传输。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.golang.org/context&#34;&gt;Go Concurrency Patterns: Context&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Liunx性能检测常用命令(一)</title>
          <link>https://maodanp.github.io/2016/09/03/linux-performace-cmd-one/</link>
          <pubDate>Sat, 03 Sep 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/09/03/linux-performace-cmd-one/</guid>
          <description>&lt;p&gt;作为后端研发人员，了解Linux服务器的性能状态是非常必要的，Linux设计的性能检测命令也很多，如何在最短时间内定位到影响服务器性能的瓶颈，这也是每个研发人员的必备的技能之一。&lt;/p&gt;

&lt;h3 id=&#34;uptime&#34;&gt;uptime&lt;/h3&gt;

&lt;p&gt;以下是&lt;code&gt;uptime&lt;/code&gt;的输出信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;04:03:58 up 10 days, 13:19, 1 user, load average: 0.54, 0.40, 0.20
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，0.54, 0.40, 0.20，最近1分钟、5分钟、15分钟系统的负载。&lt;/p&gt;

&lt;p&gt;通过这三个数据，可以了解服务器负载是在趋于紧张还是趋于缓解。如果1分钟平均负载很高，而15分钟平均负载很低，说明服务器正在命令高负载情况，需要进一步排查CPU资源都消耗在了哪里；反之，如果15分钟平均负载很高，1分钟平均负载较低，则有可能是CPU资源紧张时刻已经过去。&lt;/p&gt;

&lt;h4 id=&#34;系统负载&#34;&gt;系统负载&lt;/h4&gt;

&lt;p&gt;系统平均负载被定义为在特定时间间隔内运行队列中的平均进程数。如果一个进程满足以下条件就会认为位于运行队列中：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;它没有在等待I/O操作的结果&lt;/li&gt;
&lt;li&gt;它没有主动进入等待状态&lt;/li&gt;
&lt;li&gt;没有被停止&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;负载高-or-低&#34;&gt;负载高 or 低&lt;/h4&gt;

&lt;p&gt;一般来说，每个CPU内核当前活动进程数不大于3，则系统运行表现良好。也就是如果你的主机是四核cpu的话，那么只要uptime最后输出的一串字符数值小于12即表示系统负载不是很严重。&lt;/p&gt;

&lt;h3 id=&#34;dmesg&#34;&gt;dmesg&lt;/h3&gt;

&lt;p&gt;dmesg命令显示linux内核的环形缓冲区信息，我们可以从中获得诸如系统架构、cpu、挂载的硬件，内存等多个层次的系统信息。这也有助于我们排查性能问题。&lt;/p&gt;

&lt;p&gt;一般我们会将&lt;code&gt;dmesg&lt;/code&gt;结合命令&lt;code&gt;more&lt;/code&gt;、&lt;code&gt;less&lt;/code&gt;、&lt;code&gt;head&lt;/code&gt;、&lt;code&gt;tail&lt;/code&gt;、&lt;code&gt;grep&lt;/code&gt;等使用，打印出我们需要的信息，或者过滤掉我们不需要的信息。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dmesg | head -20&lt;/code&gt; 显示前20行的内核信息&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dmesg | tail -20&lt;/code&gt; 显示后20行的内核信息&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dmesg | grep sda&lt;/code&gt; 搜索包含sda关键字的信息&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tail -f /var/log/dmesg&lt;/code&gt; 或者 &lt;code&gt;watch &amp;quot;dmesg | tail&amp;quot;&lt;/code&gt; 实时监控dmesg的日志输出&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;vmstat&#34;&gt;vmstat&lt;/h3&gt;

&lt;p&gt;vmstat命令每行会输出一些系统核心指标，这些指标可以让我们更详细的了解系统状态。可以展现给定时间间隔的服务器的状态值,包括服务器的CPU使用率，内存使用，虚拟内存交换情况,IO读写情况。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vmstat 1

procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0 2593888 45303876 18504760 37989512    0    0     2   700    0    0  7  2 89  2  0
 0  0 2593888 45303964 18504760 37989644    0    0     0   764 11204 21249  3  1 96  0  0
 1  0 2593888 45302544 18504760 37989668    0    0     0   184 8455 16237  2  1 97  0  0
 3  0 2593888 45303872 18504760 37989692    0    0     0   200 13497 27806  5  1 94  0  0
 1  0 2593888 45302944 18504760 37989744    0    0     0   300 26437 53148 12  4 85  0  0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，和性能调优相关的信息包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;r&lt;/code&gt; 表示运行和等待CPU时间片的进程数。如果这个数值长期大于机器CPU核数，那么机器的CPU资源已经饱和。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;free&lt;/code&gt; 系统可用内存数（KB为单位），如果剩余内存不足，也会导致系统性能问题。（具体可以看free命令）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;si, so&lt;/code&gt; 交换区写入和读取的数量。如果这个数据不为0，说明系统已经在使用交换区（swap），机器物理内存已经不足，或者存在内存泄漏了。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;us, sy, id&lt;/code&gt; 这些都代表了CPU时间的消耗，它们分别表示用户时间（user）、系统（内核）时间（sys）、空闲时间（idle）。一般来说，id+us+sy=100，如果us长期大于50%，那就要考虑程序优化了；如果us+sy超过80%，就说明CPU的资源存在不足。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wa&lt;/code&gt; 表示IO等待所占的CPU时间百分比。wa值越高，说明IO等待越严重。如果wa值超过20%，说明IO等待严重。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;mpstat&#34;&gt;mpstat&lt;/h3&gt;

&lt;p&gt;mpstat（Multiprocessor Statistics）最大的特点是可以查看多核心cpu中每个计算核心的统计数据；而上述的vmstat只能查看系统整体cpu情况。以下命令是每2秒更新一次，查看多核CPU核心的当前运行状况信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mpstat  -P ALL 2

19:43:58     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest   %idle
19:43:59     all    0.00    0.00    0.04    0.00    0.00    0.00    0.00    0.00   99.96
19:43:59       0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
19:43:59       1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
.......
19:43:59      13    0.99    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.01
19:43:59      14    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
19:43:59      15    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果有一个CPU占用率特别高，那么我们可以推断有可能是一个单线程应用程序引起的。&lt;/p&gt;

&lt;h3 id=&#34;pidstat&#34;&gt;pidstat&lt;/h3&gt;

&lt;p&gt;pidstat主要用于监控全部或指定进程占用系统资源的情况，如CPU，内存、设备IO、任务切换、线程等。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pidstat 1
Linux 2.6.32.12-0.7-default (linux)             06/18/12        _x86_64_

11:37:19          PID    %usr %system  %guest    %CPU   CPU  Command
……
11:37:19        11452    0.00    0.00    0.00    0.00     2  bash
11:37:19        11509    0.00    0.00    0.00    0.00     3  dd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行&lt;code&gt;pidstat 1&lt;/code&gt;，将以采样间隔1s，输出系统启动后*所有活动进程*的cpu统计信息，等同于&lt;code&gt;pidstat -u 1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;常用命令如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pidstat -u 1&lt;/code&gt; 采样周期1s, 输出所有活动进程的CPU统计信息&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pidstat -u -p 2938 1&lt;/code&gt; 采样周期1s, 输出进程号为2938的CPU统计信息(通过-p指定进程，下述的内存、磁盘IO统计类似)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pidstat -r 1&lt;/code&gt; 采样周期1s, 输出所有活动进程的内存统计信息&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pidstat -d 1&lt;/code&gt; 采样周期1s, 输出所有活动进程的磁盘IO统计信息&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.chinaunix.net/uid-24020646-id-1992032.html&#34;&gt;linux系统性能调优第一步——性能分析(vmstat)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/ggjucheng/archive/2012/01/05/2312625.html&#34;&gt;Linux vmstat命令实战详解&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/ggjucheng/archive/2013/01/13/2858874.html&#34;&gt;Linux 运行进程实时监控pidstat命令详解&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>分布式存储之Raft协议应用详解</title>
          <link>https://maodanp.github.io/2016/08/13/bigdata-raft-state/</link>
          <pubDate>Sat, 13 Aug 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/08/13/bigdata-raft-state/</guid>
          <description>&lt;p&gt;最近研究Raft协议，也阅读了&lt;a href=&#34;https://github.com/goraft/raft&#34;&gt;go-raft&lt;/a&gt;的实现代码，虽然已经不维护了，但&lt;strong&gt;etcd&lt;/strong&gt;, &lt;strong&gt;InfluxDB&lt;/strong&gt;等项目前期都是使用的该库，还是很有工程上的参考价值。本篇针对&lt;a href=&#34;http://files.catwell.info/misc/mirror/raft/raft.pdf&#34;&gt;论文&lt;/a&gt;与实现过程作简要的分析, 并分析了Raft的容错处理。&lt;/p&gt;

&lt;h3 id=&#34;raft节点状态数据&#34;&gt;Raft节点状态数据&lt;/h3&gt;

&lt;p&gt;下图为每个Raft节点保存的一些状态信息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-08-13-bigdata-raft-state-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;大致解释为：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;状态&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;所有节点&lt;/strong&gt;保存的持久化数据&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;currentTerm&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;最新任期数，第一次启动时为0，单调递增的&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;voteFor&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;当前任期内，本节点投票目标节点&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;log[]&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;日志项：每一项包含状态机命令，以及从&lt;strong&gt;Leader&lt;/strong&gt;接收到的该日志项的任期&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;状态&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;所有节点&lt;/strong&gt;非持久化数据&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;commitIndex&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;已经提交的最高日志项的编号（默认从0开始，单调递增）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;lastApplied&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;log中最高的日志项的编号（默认从0开始，单调递增）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;状态&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Leader节点&lt;/strong&gt;的可变状态(选举后会重置)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;nextIndex[]&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;对于每一个服务器，需要发送给他的下一个日志项的索引值（初始化为领导人最后索引值加一）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;matchIndex[]&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;对于每一个服务器，已经复制给它的日志的最高索引值&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;在定义节点的状态信息时，在&lt;strong&gt;goraft&lt;/strong&gt;的状态信息与论文中的有些差异，&lt;strong&gt;goraft&lt;/strong&gt;中状态信息总结如下：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;状态&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;所有节点&lt;/strong&gt;保存的持久化数据&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;commitIndex&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;最新任期数，第一次启动时为0，单调递增的&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Peer[]&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;集群中其他节点信息&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;log[]&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;日志项(同上)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;状态&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;所有节点&lt;/strong&gt;非持久化数据&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;currentTerm&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;最新任期数，第一次启动时为0，单调递增的&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;voteFor&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;当前任期内，本节点投票目标节点&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;状态&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Leader节点&lt;/strong&gt;的可变状态(选举后会重置)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;prevLogIndex&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Leader节点&lt;/strong&gt;会维护一个&lt;strong&gt;Peer[]&lt;/strong&gt;，存储集群中其他节点信息。其中每个节点信息中&lt;strong&gt;prevLogIndex&lt;/strong&gt;表示上一次&lt;strong&gt;leader&lt;/strong&gt;复制给它的最高索引编号&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;goraft&lt;/strong&gt;中并没有将&lt;strong&gt;currentTerm&lt;/strong&gt;作为持久化数据保存，因为已经保存了&lt;strong&gt;log[]&lt;/strong&gt;, 而每个&lt;strong&gt;log entry&lt;/strong&gt;中都包含term信息，每次server重启是，都会获取最后一个&lt;strong&gt;log entry&lt;/strong&gt;中的term作为当前term，所以&lt;strong&gt;currentTerm&lt;/strong&gt;不需要存储。&lt;/p&gt;

&lt;h3 id=&#34;raft的rpc&#34;&gt;Raft的RPC&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Raft&lt;/strong&gt;的核心部分使用两个RPC进行节点间通信： &lt;strong&gt;RequestVote&lt;/strong&gt;和&lt;strong&gt;AppendEntries&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RequestVote&lt;/strong&gt; RPC: 由candidate发送给其他节点，请求其他节点为自己投票，如果一个candidate获得了多数节点的投票，则该candidate转变为Leader&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AppendEntries&lt;/strong&gt; RPC: 由Leader节点发送给其他节点，有两个作用，当其entries域为空时，该RPC作为Leader的心跳，当entries域不为空时，请求其他节点将其中的log添加到自己的log中&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;appendentries-rpc&#34;&gt;AppendEntries RPC&lt;/h4&gt;

&lt;p&gt;以下为&lt;strong&gt;AppendEntries RPC&lt;/strong&gt;的格式和说明:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-08-13-bigdata-raft-state-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从以上&lt;strong&gt;AEs(AppendEntries RPC)&lt;/strong&gt;的请求、响应格式说明可以看到，Raft对于实现细节有非常清晰的界定与描述。对于RPC接受者的实现主要有以下几种情况：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果 term &amp;lt; currentTerm 就返回 false&lt;/li&gt;
&lt;li&gt;如果日志在 prevLogIndex 位置处的日志项的任期号和 prevLogTerm 不匹配，则返回 false&lt;/li&gt;
&lt;li&gt;如果已经已经存在的日志项和新的产生冲突（相同Index但是term不同），删除这一条和之后所有的&lt;/li&gt;
&lt;li&gt;附加任何在已有的日志中不存在的项&lt;/li&gt;
&lt;li&gt;如果 leaderCommit &amp;gt; commitIndex，令 commitIndex 等于 leaderCommit 和 最新日志项索引值中较小的一个&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;goraft&lt;/strong&gt;中的&lt;strong&gt;AEs RPC&lt;/strong&gt;处理过程基本遵循上述处理流程，对应中的主要代码段如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt; func (s *server) processAppendEntriesRequest(req *AppendEntriesRequest){

      //如果AppendEntries请求的term小于该server当前term
      //返回失败
      if req.Term &amp;lt; s.currentTerm {
          s.debugln(&amp;quot;server.ae.error: stale term&amp;quot;)
          return false
      }

      if req.Term == s.currentTerm {

          // 当server处于candidate状态，则降为follower
          if s.state == Candidate {
              s.setState(Follower)
          }

      } else {
     
          // term 比 目前的大，则有新的leader产生
          // 更新 term 以及 leader
          s.updateCurrentTerm(req.Term, req.LeaderName)
      }

      // 将req.PrevLogIndex 编号后的log entry都删除了
      if err := s.log.truncate(req.PrevLogIndex, req.PrevLogTerm); err != nil {
          return false
      }

     // 加入该server节点的 log entries
      if err := s.log.appendEntries(req.Entries); err != nil {
          return false
      }

      // 提交至req.CommitIndex
      if err := s.log.setCommitIndex(req.CommitIndex); err != nil {
          s.debugln(&amp;quot;server.ae.commit.error: &amp;quot;, err)
          return true
      }
      return true;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Leader&lt;/strong&gt;对于 &lt;strong&gt;AppendEntries RPC Response&lt;/strong&gt;的处理流程:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果在response中，有term大于当前leader的term，则当前leader角色转变为follower&lt;/li&gt;
&lt;li&gt;如果收到大多数节点的&lt;strong&gt;AEs&lt;/strong&gt;成功回应，后续会判断下次的提交编号，否则返回&lt;/li&gt;
&lt;li&gt;Leader根据大多数节点返回的上次log的索引编号，来决定这次提交的编号， 该提交编号将在下次随&lt;strong&gt;AEs RPC&lt;/strong&gt;传给follower&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (s *server) processAppendEntriesResponse(resp *AppendEntriesResponse) {
 
      // 如果发现AppendEntries的返回中term较大，则角色变为follower
      // 这个判断非常重要，能够保证网络分区恢复后的一致性
      if resp.Term() &amp;gt; s.Term() {
          s.updateCurrentTerm(resp.Term(), &amp;quot;&amp;quot;)
          return
      }

      // 对于回应返回成功的，更新map表
      if resp.append == true {
          s.syncedPeer[resp.peer] = true
      }

      if len(s.syncedPeer) &amp;lt; s.QuorumSize() {
          return
      }

      // 计算此次需要提交的编号
      var indices []uint64
      indices = append(indices, s.log.currentIndex())
      for _, peer := range s.peers {
          indices = append(indices, peer.getPrevLogIndex())
      }
      sort.Sort(sort.Reverse(uint64Slice(indices)))

      commitIndex := indices[s.QuorumSize()-1]
      committedIndex := s.log.commitIndex

      if commitIndex &amp;gt; committedIndex {
          s.log.sync()
          s.log.setCommitIndex(commitIndex)
      }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;requestvote-rpc&#34;&gt;RequestVote RPC&lt;/h4&gt;

&lt;p&gt;以下为&lt;strong&gt;RequestVote RPC&lt;/strong&gt;的格式和说明:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-08-13-bigdata-raft-state-3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;对于&lt;strong&gt;RequestVote RPC&lt;/strong&gt;接受者的处理流程：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果term &amp;lt; currentTerm返回 false&lt;/li&gt;
&lt;li&gt;如果votedFor为空或者就是candidateId，并且候选人的日志也自己一样新，那么就投票给它&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;goraft&lt;/strong&gt;中的&lt;strong&gt;RequestVote RPC&lt;/strong&gt;处理过程主要代码段如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;
func (s *server) processRequestVoteRequest(req *RequestVoteRequest){

      // term小于当前的，则返回false
      if req.Term &amp;lt; s.Term() {
          s.debugln(&amp;quot;server.rv.deny.vote: cause stale term&amp;quot;)
		  return false
      }

      // 如果请求的term大于该节点的term，则更新该节点的term
      // 如果term相等，且我们已经投给了其他候选节点(votedFor参数),则不投给该候选节点candidate
      // 即一个任期内只投给一个候选节点，但是可以投多次（可能存在网络异常，候选节点再次发出投票请求）
      if req.Term &amp;gt; s.Term() {
          s.updateCurrentTerm(req.Term, &amp;quot;&amp;quot;)
      } else if s.votedFor != &amp;quot;&amp;quot; &amp;amp;&amp;amp; s.votedFor != req.CandidateName {
          return false
      }

      // 如果candidate中最新日志项编号小于 当前server的最新日志项编号，则不投票
      // 这里满足了Raft的安全性：必须要比大部分其它候选者的log新，才有机会成为leader
      lastIndex, lastTerm := s.log.lastInfo()
      if lastIndex &amp;gt; req.LastLogIndex || lastTerm &amp;gt; req.LastLogTerm {
          return false
      }

      s.votedFor = req.CandidateName

      return true
  }

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Candidate&lt;/strong&gt;对于&lt;strong&gt;RequestVote RPC Response&lt;/strong&gt;的处理流程:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;
 func (s *server) candidateLoop() {
	  //处于 Candidate 状态，直到状态改变为leader或者follower
	  //否则超时后再次发起投票请求     
      for s.State() == Candidate {

          if doVote {
              //自增term
              s.currentTerm++
              s.votedFor = s.name

              // 向每个servers发送 RequestVote RPCs
              respChan = make(chan *RequestVoteResponse, len(s.peers))
              for _, peer := range s.peers {
                  s.routineGroup.Add(1)
                  go func(peer *Peer) {
                      defer s.routineGroup.Done()
                      peer.sendVoteRequest(newRequestVoteRequest(s.currentTerm, s.name, lastLogIndex, lastLogTerm), respChan)
                  }(peer)
              }

              //发起请求后的变量初始化
              votesGranted = 1
              timeoutChan = afterBetween(s.ElectionTimeout(), s.ElectionTimeout()*2)
              doVote = false
           }

           //如果收到超过半数以上的投票支持，则状态变为leader
           if votesGranted == s.QuorumSize() {
              s.setState(Leader)
              return
           }

          select {
          //处理收到RequestVote RPC回应
          case resp := &amp;lt;-respChan:
              if success := s.processVoteResponse(resp); success {
                  s.debugln(&amp;quot;server.candidate.vote.granted: &amp;quot;, votesGranted)
                  votesGranted++
              }
          //如果选举超时，则继续选举    	
          case &amp;lt;-timeoutChan:
              doVote = true
       }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;raft的failure处理&#34;&gt;Raft的failure处理&lt;/h3&gt;

&lt;p&gt;Raft关于容错的处理是需要考虑的方面。主要的异常包括&lt;strong&gt;Leader crash&lt;/strong&gt;、&lt;strong&gt;Follower crash&lt;/strong&gt;、&lt;strong&gt;Network Partition&lt;/strong&gt;等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Leader crash&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Leader crash&lt;/strong&gt;需要考虑&lt;strong&gt;crash&lt;/strong&gt;后，log中未被提交的数据是否属于&lt;strong&gt;脏数据&lt;/strong&gt;。 这个需要分多种情况考虑。(a) 客户端将某条&lt;strong&gt;log entry&lt;/strong&gt;发送给&lt;strong&gt;Leader&lt;/strong&gt;后&lt;strong&gt;crash&lt;/strong&gt;；(b) &lt;strong&gt;Leader&lt;/strong&gt;将&lt;strong&gt;log entry&lt;/strong&gt;发送给&lt;strong&gt;Follower&lt;/strong&gt;后&lt;strong&gt;crash&lt;/strong&gt;，(3)&lt;strong&gt;Leader&lt;/strong&gt;提交了该&lt;strong&gt;entry&lt;/strong&gt;后&lt;strong&gt;crash&lt;/strong&gt;等等。&lt;/p&gt;

&lt;p&gt;对于情况(1)而言，该命令是未添加成功的(该命令在原leader中当做&lt;strong&gt;脏数据&lt;/strong&gt;，将等待新&lt;strong&gt;Leader&lt;/strong&gt;的覆盖)，客户端将超时后采取重试机制重新发送该命令，将会被新选举出的&lt;strong&gt;Leader&lt;/strong&gt;处理。&lt;/p&gt;

&lt;p&gt;对于情况(2)而言，该命令算添加成功么？这个有需要分情况了：&lt;/p&gt;

&lt;p&gt;（a）如果大多数节点多收到了，添加到了各自的&lt;strong&gt;log entries&lt;/strong&gt;中，那么此次添加算成功的。根据Raft的安全性原则，新选举出来的leader一定是包最新log的，并且新选出来的&lt;strong&gt;leader&lt;/strong&gt;，term号一定大于上一轮的term。那么当新的日志提交以后，之前的commit就被间接地提交了；&lt;/p&gt;

&lt;p&gt;(b) 如果只有少部分&lt;strong&gt;Follower&lt;/strong&gt;添加到了各自的&lt;strong&gt;log entries&lt;/strong&gt;中，那就存在该日志被覆盖的情况，要看新选出的&lt;strong&gt;Leader&lt;/strong&gt;是否包含这条日志了。&lt;/p&gt;

&lt;p&gt;下图为情况(2)中(a)的情形，即大多数节点都&lt;strong&gt;AppendEntries&lt;/strong&gt;了，根据Raft安全性原则，后续的&lt;strong&gt;Leader&lt;/strong&gt;在*F_1*或者&lt;em&gt;F_2&lt;/em&gt; 中产生，那么 “Hello”命令也间接被提交了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-08-13-bigdata-raft-state-4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;对于情况(3)，类似于情况(2)中的(a)。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Follower crash&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Follower crash&lt;/strong&gt;比较简单，主要是&lt;strong&gt;crash&lt;/strong&gt;恢复后怎么保持log与&lt;strong&gt;Leader&lt;/strong&gt;的一致性。具体如图示，*F_4*恢复后，怎么保持数据一致？&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-08-13-bigdata-raft-state-5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在之前&lt;strong&gt;节点状态数据&lt;/strong&gt;中我们看到，每个&lt;strong&gt;节点&lt;/strong&gt;中会维护一个&lt;strong&gt;Peer[]&lt;/strong&gt;, 存放集群中的节点信息。其中就有一个&lt;strong&gt;prevLogIndex&lt;/strong&gt;，用于维护上一次该&lt;strong&gt;Follower&lt;/strong&gt;最新添加的log的索引号。如果 &lt;em&gt;F_4&lt;/em&gt; 恢复了，&lt;strong&gt;Leader&lt;/strong&gt;中维护的&lt;strong&gt;prevLogIndex=1&lt;/strong&gt;，后续将从索引2开始的所有&lt;strong&gt;log entries&lt;/strong&gt;发送给 &lt;em&gt;F_4&lt;/em&gt; 。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Network Partition&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Network Partition&lt;/strong&gt;网络分区会导致&lt;strong&gt;脑裂问题&lt;/strong&gt;，即每个分区都会出现一个&lt;strong&gt;Leader&lt;/strong&gt;。这种情况随着分区的恢复，Raft很快能够恢复集群的一致性。&lt;/p&gt;

&lt;p&gt;下图为网络分区的一种情形，其中&lt;em&gt;le_1&lt;/em&gt; 为原来的&lt;strong&gt;Leader&lt;/strong&gt;， *le_2*为分区二新选举出的&lt;strong&gt;Leader&lt;/strong&gt;（&lt;strong&gt;term&lt;/strong&gt;比分区一的大)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-08-13-bigdata-raft-state-6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;对于图中的&lt;strong&gt;分区一&lt;/strong&gt;，由于通信的节点不满足大多数节点（这里假设没有机制去变化整个集群总共的节点数量），所以向该分区中添加的日志都不能提交，客户端将一直收到超时的回复。而对于&lt;strong&gt;分区二&lt;/strong&gt;，满足提交的条件，该分区中的日志都能够被正常提交。&lt;/p&gt;

&lt;p&gt;待分区恢复，*le_1*由于term小于*le_2*，则自动转为Follower状态，如下图所示，最终能够实现一致性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-08-13-bigdata-raft-state-7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;下图为网络分区的另一种情形，&lt;em&gt;le_1&lt;/em&gt; 分区占有了大部分节点，能够正常的提交日志。但是&lt;strong&gt;分区二&lt;/strong&gt;中的两个&lt;strong&gt;Follower&lt;/strong&gt;节点，由于选票个数未过半，将持续处于&lt;strong&gt;Candidate&lt;/strong&gt;状态，直到网络恢复。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-08-13-bigdata-raft-state-8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;由于&lt;strong&gt;分区二&lt;/strong&gt;的竞选，导致term不停增加，网络分区恢复后，集群中的term号会随着&lt;strong&gt;leader&lt;/strong&gt;的&lt;strong&gt;AppendEntries RPC&lt;/strong&gt;（参见&lt;strong&gt;processAppendEntriesResponse&lt;/strong&gt;函数），将term一起同步到最新。&lt;/p&gt;

&lt;p&gt;虽然Raft易于理解，但是工程实践还是需要考虑到各种异常情况。通过代码的阅读，也能够更加理解其背后的原理。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://files.catwell.info/misc/mirror/raft/raft.pdf&#34;&gt;In Search of an Understandable Consensus Algorithm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/goraft/raft&#34;&gt;https://github.com/goraft/raft&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.tuicool.com/articles/aERnm2U&#34;&gt;从raft看failure的处理&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>sublime text常用快捷键</title>
          <link>https://maodanp.github.io/2016/08/06/sublime-shortcut/</link>
          <pubDate>Sat, 06 Aug 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/08/06/sublime-shortcut/</guid>
          <description>&lt;p&gt;本篇总结在sublime text的使用过程中常用的快捷键。&lt;/p&gt;

&lt;h3 id=&#34;快速查找-command-p&#34;&gt;快速查找(Command+P)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;输入@+函数名可以快速找到函数&lt;/li&gt;
&lt;li&gt;输入#+文本可以快速进行文件内文本匹配&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;命令行模式-shift-command-p&#34;&gt;命令行模式(Shift+Command+P)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;set syntax: go&lt;/code&gt; 设置go语法高亮 (对于新建的plain text，没有语法高亮)&lt;/li&gt;
&lt;li&gt;minimap 隐藏或显示右边的minimap缩影&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;其他快捷键&#34;&gt;其他快捷键&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Ctrl + X:            删除当前行&lt;/li&gt;
&lt;li&gt;Ctrl + Shift + M:    选中花括号里面的全部内容不包括{}&lt;/li&gt;
&lt;li&gt;Shift + Command + T: 重新打开关闭了的某个标签页&lt;/li&gt;
&lt;li&gt;Shift + Command + V:    完整拷贝，避免格式错乱&lt;/li&gt;
&lt;li&gt;Ctrl + Enter:        可以在当前行下新建一行；Ctrl + Shift + Enter 可以在当前行上面添加一行&lt;/li&gt;
&lt;li&gt;Command + K + B:     开关侧栏&lt;/li&gt;
&lt;li&gt;Command + Shift + F: 查找并替换&lt;/li&gt;
&lt;li&gt;Ctrl + Command + F:  全屏/退出全屏&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/lanxuezaipiao/p/4151095.html&#34;&gt;sublime Text 3实用功能和常用快捷键收集&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://segmentfault.com/a/1190000002570753&#34;&gt;Sublime Text 3 快捷键精华版&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.lupaworld.com/article-248738-1.html&#34;&gt;我常用的16个Sublime Text快捷键&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>分布式存储之Raft协议</title>
          <link>https://maodanp.github.io/2016/08/05/bigdata-raft/</link>
          <pubDate>Fri, 05 Aug 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/08/05/bigdata-raft/</guid>
          <description>&lt;p&gt;随着&lt;a href=&#34;http://files.catwell.info/misc/mirror/raft/raft.pdf&#34;&gt;Raft一致性算法论文&lt;/a&gt;的发表，该协议在分布式领域的应用越来越广泛，大有取代Paxos协议之势。&lt;/p&gt;

&lt;h3 id=&#34;raft概述&#34;&gt;Raft概述&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Raft强调的是&lt;strong&gt;易懂（Understandability）&lt;/strong&gt;，在做技术决策和选型的时候，易于理解是非常重要的&lt;/li&gt;
&lt;li&gt;Raft算法能够给出实现系统的&lt;strong&gt;确定性&lt;/strong&gt;，能够给出每个技术细节的清晰界定与描述&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Raft使用了分而治之的思想把算法流程分为三个子问题：&lt;strong&gt;选举（Leader election）&lt;/strong&gt;、&lt;strong&gt;日志复制（Log replication）&lt;/strong&gt;、&lt;strong&gt;安全性（Safety）&lt;/strong&gt;三个子问题。&lt;/p&gt;

&lt;h3 id=&#34;raft流程&#34;&gt;Raft流程&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Raft开始时在集群中选举出&lt;strong&gt;Leader&lt;/strong&gt;负责日志复制的管理；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Leader&lt;/strong&gt;接受来自客户端的事务请求（日志），并将它们复制给集群的其他节点，然后负责通知集群中其他节点提交日志，&lt;strong&gt;Leader负&lt;/strong&gt;责保证其他节点与他的日志同步；&lt;/li&gt;
&lt;li&gt;当&lt;strong&gt;Leader&lt;/strong&gt;宕掉后集群其他节点会发起选举选出新的&lt;strong&gt;Leader&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可以看到&lt;strong&gt;Raft&lt;/strong&gt;采用的是&lt;strong&gt;Master-Slave&lt;/strong&gt;模式，这在一定程度上简化了一致性维护的问题，清晰的看到各个系统所处的状态。&lt;/p&gt;

&lt;h3 id=&#34;raft详解&#34;&gt;Raft详解&lt;/h3&gt;

&lt;h4 id=&#34;角色&#34;&gt;角色&lt;/h4&gt;

&lt;p&gt;Raft把集群中的节点分为三种状态：&lt;strong&gt;Leader&lt;/strong&gt;、&lt;strong&gt;Follower&lt;/strong&gt;、&lt;strong&gt;Candidate&lt;/strong&gt;。Raft运行时提供服务的时候只存在&lt;strong&gt;Leader&lt;/strong&gt;与&lt;strong&gt;Follower&lt;/strong&gt;两种状态；即&lt;strong&gt;Candidate&lt;/strong&gt;是转换的中间状态。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Leader（领导者）&lt;/strong&gt;：负责日志的同步管理，处理来自客户端的请求，与Follower保持这heartBeat的联系；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Follower（追随者）&lt;/strong&gt;：刚启动时所有节点为Follower状态，响应Leader的日志同步请求，响应Candidate的请求，把请求到Follower的事务转发给Leader；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Candidate（候选者）&lt;/strong&gt;：负责选举投票，Raft刚启动时由一个节点从Follower转为Candidate发起选举，选举出Leader后从Candidate转为Leader状态；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;三者的转换关系及转换条件如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-08-05-bigdata-raft-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;term&#34;&gt;Term&lt;/h4&gt;

&lt;p&gt;在Raft中使用了一个可以理解为周期（第几届、任期）的概念，用Term作为一个周期，每个Term都是一个连续递增的编号，每一轮选举都是一个Term周期，在一个Term中只能产生一个Leader；先简单描述下Term的变化流程：Raft开始时所有Follower的Term为1，其中一个Follower逻辑时钟到期后转换为Candidate，Term加1这是Term为2（任期），然后开始选举，这时候有几种情况会使Term发生改变：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果当前Term为2的任期内没有选举出Leader或出现异常，则Term递增，开始新一任期选举&lt;/li&gt;
&lt;li&gt;当这轮Term为2的周期选举出Leader后，过后Leader宕掉了，然后其他Follower转为Candidate，Term递增，开始新一任期选举&lt;/li&gt;
&lt;li&gt;当Leader或Candidate发现自己的Term比别的Follower小时Leader或Candidate将转为Follower，Term递增&lt;/li&gt;
&lt;li&gt;当Follower的Term比别的Term小时Follower也将更新Term保持与其他Follower一致；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;可以说每次Term的递增都将发生新一轮的选举，Raft保证一个Term只有一个Leader，在Raft正常运转中所有的节点的Term都是一致的，如果节点不发生故障一个Term（任期）会一直保持下去，当某节点收到的请求中Term比当前Term小时则拒绝该请求。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-08-05-bigdata-raft-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;选举&#34;&gt;选举&lt;/h4&gt;

&lt;p&gt;Raft的选举由定时器来触发，每个节点的选举定时器时间都是不一样的，开始时状态都为&lt;strong&gt;Follower&lt;/strong&gt;某个节点定时器触发选举后&lt;strong&gt;Term&lt;/strong&gt;递增，状态由&lt;strong&gt;Follower&lt;/strong&gt;转为&lt;strong&gt;Candidate&lt;/strong&gt;，向其他节点发起&lt;strong&gt;RequestVote RPC&lt;/strong&gt;请求，这时候有三种可能的情况发生：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;赢得本次选举&lt;/p&gt;

&lt;p&gt;如果接收到大都输其他节点的投票，则赢得选举成为领导者，然后定时向其他服务器发送RPC心跳维护其&lt;strong&gt;Leader&lt;/strong&gt;地位。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;另一个服务器S宣称并确认自己是新的领导者&lt;/p&gt;

&lt;p&gt;如果该&lt;strong&gt;Candidate&lt;/strong&gt;收到服务器S的RPC，且Term编号大于&lt;strong&gt;Candidate&lt;/strong&gt;自身编号，则自己转为&lt;strong&gt;Follower&lt;/strong&gt;，否则拒绝承认S为新领导者并继续维持自身的&lt;strong&gt;Candidate&lt;/strong&gt;状态。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;经过一定时间仍然没有新领导者产生&lt;/p&gt;

&lt;p&gt;由于同一时间有多个&lt;strong&gt;Follower&lt;/strong&gt;转为&lt;strong&gt;Candidate&lt;/strong&gt;状态，导致选票分流，所以没能得到多数选票。此时&lt;strong&gt;Candidate&lt;/strong&gt;增加自身&lt;strong&gt;Term&lt;/strong&gt;编号进入新一轮选举。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;日志复制&#34;&gt;日志复制&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;日志复制（Log Replication）&lt;/strong&gt;主要作用是用于保证节点的一致性，这阶段所做的操作也是为了保证一致性与高可用性；当Leader选举出来后便开始负责客户端的请求，所有事务（更新操作）请求都必须先经过Leader处理。&lt;/p&gt;

&lt;p&gt;要保证节点的一致性就要保证每个节点都按顺序执行相同的操作序列，日志复制（Log Replication）就是为了保证执行相同的操作序列所做的工作；&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在Raft中当接收到客户端的日志（事务请求）后先把该日志&lt;strong&gt;追加&lt;/strong&gt;到本地的Log中；&lt;/li&gt;
&lt;li&gt;然后通过&lt;strong&gt;heartbeat&lt;/strong&gt;把该&lt;strong&gt;Entry&lt;/strong&gt;同步给其他&lt;strong&gt;Follower&lt;/strong&gt;，&lt;strong&gt;Follower&lt;/strong&gt;接收到日志后记录日志然后向&lt;strong&gt;Leader&lt;/strong&gt;发送ACK；&lt;/li&gt;
&lt;li&gt;当&lt;strong&gt;Leader&lt;/strong&gt;收到大多数&lt;strong&gt;Follower&lt;/strong&gt;的&lt;strong&gt;ACK&lt;/strong&gt;信息后将该日志设置为&lt;strong&gt;已提交&lt;/strong&gt;并追加到本地磁盘中，通知客户端；&lt;/li&gt;
&lt;li&gt;并在下个&lt;strong&gt;heartbeat&lt;/strong&gt;中&lt;strong&gt;Leader&lt;/strong&gt;将通知所有的&lt;strong&gt;Follower&lt;/strong&gt;将该日志存储在自己的本地磁盘中;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-08-05-bigdata-raft-3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上图展示了每个&lt;strong&gt;Logs&lt;/strong&gt;的组织结构。这些&lt;strong&gt;log entry&lt;/strong&gt;都是从&lt;strong&gt;Leader&lt;/strong&gt;中获取，其中每个&lt;strong&gt;log entry&lt;/strong&gt;存储了一个&lt;strong&gt;状态机命令&lt;/strong&gt;和任期号，且每个&lt;strong&gt;log entry&lt;/strong&gt;包含整型的索引来确定在log中的位置。&lt;/p&gt;

&lt;h4 id=&#34;安全性&#34;&gt;安全性&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;安全性&lt;/strong&gt;是用于保证每个节点都执行相同序列的安全机制，如当某个&lt;strong&gt;Follower&lt;/strong&gt;在当前&lt;strong&gt;Leader commit Log&lt;/strong&gt;时变得不可用了，稍后可能该&lt;strong&gt;Follower&lt;/strong&gt;又会被选举为&lt;strong&gt;Leader&lt;/strong&gt;，这时新&lt;strong&gt;Leader&lt;/strong&gt;可能会用新的Log覆盖先前已&lt;strong&gt;committed&lt;/strong&gt;的Log，这就是导致不同的节点执行不同序列。&lt;strong&gt;Safety&lt;/strong&gt;就是用于保证选举出来的&lt;strong&gt;Leader&lt;/strong&gt;一定包含先前&lt;strong&gt;commited Log&lt;/strong&gt;的机制。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;必须要比大部分其它候选者的log新，才有机会成为leader&lt;/strong&gt;, 这个是&lt;strong&gt;只有拥有所有commit日志，才有可能被选为leader&lt;/strong&gt;的充分非必要条件。在实现的时候，保证选举&lt;strong&gt;Leader&lt;/strong&gt;满足前者条件，即：当请求投票的该Candidate的Term较大或Term相同Index更大则投票，否则拒绝该请求。 （限制了哪些服务器可以被选举为Leader）&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Raft uses the voting process to prevent a candidate from winning an election unless its log contains all committed entries.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;对于新领导者而言，只有它自己已经提交过当前&lt;strong&gt;Term&lt;/strong&gt;的操作命令才被认为是真正的提交（限制了哪些操作命令的提交可被认为真正的提交）&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Only log entries from the leader’s current term are committed by counting replicas.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://files.catwell.info/misc/mirror/raft/raft.pdf&#34;&gt;In Search of an Understandable Consensus Algorithm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/cszhouwei/article/details/38374603&#34;&gt;Raft一致性算法&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/longxibendi/article/details/43340469&#34;&gt;etcd：从应用场景到实现原理的全方位解读&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.solinx.co/archives/415?utm_source=tuicool&amp;amp;utm_medium=referral&#34;&gt;一致性算法Raft详解&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/mindwind/p/5231986.html&#34;&gt;Raft 为什么是更易理解的分布式一致性算法&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/whycold/article/details/39157645&#34;&gt;Raft 一致性协议&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>《一个人的朝圣》- 思想的旅程</title>
          <link>https://maodanp.github.io/2016/07/20/pilgrimage/</link>
          <pubDate>Wed, 20 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/07/20/pilgrimage/</guid>
          <description>&lt;p&gt;最近用零零碎碎的时间看完了英国作家的小说《一个人的朝圣》，英文名称《The unlikely pilgrimage of Harold Fry》，英文翻译应该是哈罗德•弗莱不可能的朝圣之旅。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-07-20-pilgrimage.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;“朝圣”一词基本让我联想到“宗教、信仰、虔诚”，看完之后发现讲述的是一个普通的老人为了一个单纯的目的，徒步行走的故事，并没有与宗教信仰相关。中文如此的翻译也许是作为一种卖点，迎合大众的心理。当然不光是读者的心理，还包括但书中疯狂追随主人公哈罗德脚步的粉丝们的心理。这让我想到了《阿甘正传》，单纯的初衷被大众、媒体解读成了信仰之旅。&lt;/p&gt;

&lt;p&gt;书中的主角哈罗德是一个做了一辈子办公室，普普通通的老实人，到了花甲之年，也许可以和所有人一样坐着等待生命的临终。然而，因为一封信的到来，为了能够用精神力量来延续老友的生命，他选择了徒步出发。87天，627英里，对于一个普通人是一个不可思议的事，对于一个老年人更是一个奇迹。&lt;/p&gt;

&lt;p&gt;书中缓缓讲述着主人公的徒步旅程，旅途中有壮阔优美的景色，这些鲜花野草，在主人公的眼中代表了新的生命，是的，自然风景永远都在那里，变的确是我们自己。旅途中有不断出场、离去的陌生人，这些人都有自己生活的故事，这些故事都不断的触碰着哈罗德的内心深处那些不能释怀的过往。这不仅是单纯的徒步旅程，更是心灵的旅程，身体与心灵之旅的交替出现，构成了本书的主线。。作者在书中大量穿插着主人公对过去的回忆，和妻子的过去、和儿子的过去、和老友的过去。。。。内心是什么在折磨着他，才执着的走上这段漫长的旅程？&lt;/p&gt;

&lt;p&gt;越是看到中间，越是感觉旅程本身也是一种隐喻，仿佛就是我们整个人生。起初时双手空空，他的全副装备是：衬衫，领带，防水外套，帆船鞋。随着旅程的展开，随声携带的也在不断增加。他得到了关注，有了大批粉丝狂热的支持与追随。但最后，那些行装、那些追随者都变成了负担，他不得不选择了放下，就跟人的一生一样，赤裸裸的来，赤裸裸的离开人世。是的，我们都需要放弃那些承重的绑在身上的枷锁。&lt;/p&gt;

&lt;p&gt;最后，哈罗德和莫琳都释怀了，是对彼此的接纳和爱让他们放下了过去不可触碰的那些东西：彼此包裹的内心、对儿子自杀的自责与埋怨。最后，旅程改变了什么？改变了自己的心态，放下过去，去接受命运给予的一切，不再纠结于内心的痛苦，甚至让负罪感毁了自己和他人的生活，而是学会了珍视他人和卑微的自己。&lt;/p&gt;

&lt;p&gt;正如狄伦•托马斯的诗句：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;不要温顺地走入那个良夜，老年应当在日暮时燃烧咆哮；怒斥，怒斥光明的消逝&lt;/p&gt;
&lt;/blockquote&gt;</description>
        </item>
      
    
      
        <item>
          <title>分布式存储之2PC协议</title>
          <link>https://maodanp.github.io/2016/07/17/bigdata-2pc/</link>
          <pubDate>Sun, 17 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/07/17/bigdata-2pc/</guid>
          <description>&lt;p&gt;两阶段提交是很常用的解决分布式事务问题的方式，它可以保证分布式事务的原子性（要么所有参与进程都提交事务、要么都取消事务）。在数据一致性环境下，其代表的含义是：要么所有备份数据同时更改某个数值，要么都不更改，以此来达到数据的&lt;strong&gt;强一致性&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;2pc原则&#34;&gt;2PC原则&lt;/h3&gt;

&lt;p&gt;在实际应用中一般作为数据操作原子性的常用手段，利用该协议能够非常方便地完成所有分布式事务参与者的协调，统一决定事务的提交或回滚，从而能够有效地保证分布式数据一致性，因此二阶段提交协议被广泛地应用在许多分布式系统中。&lt;/p&gt;

&lt;h4 id=&#34;2pc说明&#34;&gt;2PC说明&lt;/h4&gt;

&lt;p&gt;在两阶段提交协议中，包含了两种角色：协调者与众多参与者。参与者就是实际处理事务的机器，而协调者就是其中一台单独的处理分布式事务的机器。&lt;/p&gt;

&lt;p&gt;该算法分为两个阶段：&lt;/p&gt;

&lt;p&gt;1.表决阶段(vote)&lt;/p&gt;

&lt;p&gt;【协调者视角】协调者向所有参与者发送一个&lt;code&gt;VOTE_REQUEST&lt;/code&gt;消息。&lt;/p&gt;

&lt;p&gt;【参与者视角】当参与者接受到&lt;code&gt;VOTE_REQUEST&lt;/code&gt;消息后，向协调者发送&lt;code&gt;VOTE_COMMIT&lt;/code&gt;消息作为回应，告知协调者自己已经做好准备；否则返回&lt;code&gt;VOTE_ABORT&lt;/code&gt;消息，告知协调者目前尚无提交事务可能。&lt;/p&gt;

&lt;p&gt;2.提交阶段(commit)&lt;/p&gt;

&lt;p&gt;【协调者视角】协调者收集来自各个参与者的表决信息。如果所有参与者一致认为可以提交事务，那么协调者决定事务最终可以提交，协调者会向所有参与者发送一个&lt;code&gt;GLOBAL_COMMIT&lt;/code&gt;通知参与者进行本地提交；如果所有参与者中有任意一个返回的消息是&lt;code&gt;VOTE_ABORT&lt;/code&gt;,协调者决定取消事务，则向所有参与者多播一条&lt;code&gt;GLOBAL_ABORT&lt;/code&gt;消息通知其取消事务。&lt;/p&gt;

&lt;p&gt;【参与者视角】参与者在接收到协调者发来的消息后将执行响应的操作。协调者如果发现有一个投票是&lt;code&gt;VOTE_ABORT&lt;/code&gt;，那么将创建一个&lt;code&gt;GLOBAL_ABORT&lt;/code&gt;通知所有的参与者终止该事务。如果都是&lt;code&gt;VOTE_COMMIT&lt;/code&gt;,那么协调者将发送一个&lt;code&gt;GLOBAL_COMMIT&lt;/code&gt;，告知所有的参与者执行该事务。&lt;/p&gt;

&lt;h4 id=&#34;2pc状态&#34;&gt;2PC状态&lt;/h4&gt;

&lt;p&gt;协调者、参与者的有限状态机如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-07-17-bigdata-2pc.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从上述有限状态机来看，有可能存在3种阻塞状态。3种状态都需要等待对方的反馈信息：
* 协调者： WAIT状态
* 参与者： INIT状态、READY状态&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;如果一个协议包含阻塞态，则明显是一个很脆弱的系统，因为很可能因为有进程陷入崩溃而导致处于阻塞态的对象进入长时间等待，系统无法继续向后运行&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;对于阻塞状态的应对机制有两种：&lt;strong&gt;超时判断机制&lt;/strong&gt;和&lt;strong&gt;参与者互询机制&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;超时判断机制存在的问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;但是对于处于&lt;code&gt;READY状态&lt;/code&gt;的参与者，仅仅引入超时判断机制是不行的。即使发生超时，参与者也不能简单的做出终止事务的决定，因为它不确定协调者到底发出的哪种表决消息(&lt;code&gt;GLOBAL_COMMIT&lt;/code&gt;或&lt;code&gt;GLOBAL_ABORT&lt;/code&gt;)。如果简单终止事务可能导致数据不一致。&lt;/p&gt;

&lt;p&gt;该情况有两种解决方案，第一种是协调者在最终的提交阶段(&lt;code&gt;ABORT&lt;/code&gt;或&lt;code&gt;COMMIT&lt;/code&gt;)也阻塞等待，并且设置超时时间。如果处在&lt;code&gt;READY&lt;/code&gt;状态的参与者超时不回应，则强制剔除该参与者，置为&lt;code&gt;offline&lt;/code&gt;下线状态(Codis的实现方案类似这种)。第二种是引入&lt;strong&gt;参与者互询机制&lt;/strong&gt;，让参与者之间相互通信，来决定自己该处于何种状态。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;参与者互询机制存在的问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;该方案能够让处于阻塞的参与者P询问另一个参与者Q来决定自己什么状态。如果有参与者处于INIT/ABORT/COMMIT的任一状态，则P就可以做出确定的决策。&lt;/p&gt;

&lt;p&gt;唯一一种不能使得P做出明确决策的状态是：所有其他参与者都处于READY状态。这种情况下，就必须长时间处于阻塞状态。这也是2PC所无法解决的问题，不过实际应用中该情况较少出现。&lt;/p&gt;

&lt;h4 id=&#34;2pc特点&#34;&gt;2PC特点&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;同步阻塞&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在2PC的提交阶段，所有参与该事务的逻辑都将处于阻塞状态，各个参与者都需要等待其他参与者响应。如果在提交过程中，参与者出现故障而导致协调者始终无法获取到所有参与者的响应信息的话，这时协调者只能依靠其自身的超时机制来判断是否需要中断事务，这样的策略显得比较保守。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;单点问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当协调者向所有的参与者发送Commit请求之后，发生了局部网络异常或者是协调者在尚未发送完Commit请求之前自身发生了崩溃，导致最终只有部分参与者收到了Commit请求。于是，这部分收到了Commit请求的参与者就会进行事务的提交，而其他没有收到Commit请求的参与者则无法进行事务提交，于是整个分布式系统便出现了数据不一致性现象。&lt;/p&gt;

&lt;h3 id=&#34;3pc&#34;&gt;3PC&lt;/h3&gt;

&lt;p&gt;三阶段提交协议是为了解决2PC协议存在长时间阻塞的办法，其核心是将2PC的提交阶段再次细分为两个阶段：预提交阶段和提交阶段。3PC在实际系统中很少使用，一方面由于2PC长时间阻塞的情况很少发生；另一方面是3PC效率过低。&lt;/p&gt;

&lt;h3 id=&#34;2pc在codis中的应用&#34;&gt;2PC在Codis中的应用&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;Codis&lt;/code&gt;是一种分布式 Redis 解决方案。该方案中redis纯碎是作为存储节点，不感知集群状态信息。&lt;strong&gt;集群状态信息是由zookeeper维护的&lt;/strong&gt;,这样实现的好处是简单，不用对redis太多修改。处理迁移期间一致性，可以看作是一个两阶段提交。&lt;/p&gt;

&lt;h4 id=&#34;迁移状态的2pc&#34;&gt;迁移状态的2PC&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;Codis&lt;/code&gt;支持不停机的数据迁移，它的&lt;code&gt;Proxy&lt;/code&gt;模块能够对原生的redis命令进行转发，并且&lt;code&gt;Proxy&lt;/code&gt;是无状态的，支持集群化部署。所以在数据迁移过程中必然需要针对&lt;code&gt;Proxy&lt;/code&gt;实现迁移数据的强一致性。Codis中使用&lt;code&gt;pre_migrate&lt;/code&gt;(待迁移状态), &lt;code&gt;migrate&lt;/code&gt;(迁移状态)表示2PC的两种状态, &lt;code&gt;Proxy&lt;/code&gt;相当于参与者，&lt;code&gt;zookeeper&lt;/code&gt;相当于协调者。&lt;/p&gt;

&lt;p&gt;第一阶段：将需要迁移的&lt;code&gt;Slot&lt;/code&gt;的&lt;code&gt;online&lt;/code&gt;(在线状态)状态更新为&lt;code&gt;pre_migrate&lt;/code&gt;状态，并通过&lt;code&gt;zookeeper&lt;/code&gt;通知给所有的在线&lt;code&gt;Proxy&lt;/code&gt;。迁移程序会等待所有&lt;code&gt;Proxy&lt;/code&gt;的回应，等待所有&lt;code&gt;Proxy&lt;/code&gt;都已经进入到待迁移状态的回应。&lt;/p&gt;

&lt;p&gt;第二阶段：如果迁移程序能够确认所有的&lt;code&gt;Proxy&lt;/code&gt;都回复了，即收到了所有&lt;code&gt;Proxy&lt;/code&gt;的回应，那么它就可以将该slot状态改为&lt;code&gt;migrate&lt;/code&gt;并再次通知所有的&lt;code&gt;Proxy&lt;/code&gt;这个slot状态的变更。对于&lt;code&gt;Proxy&lt;/code&gt;不响应的情况(通过超时机制)，可以将该无回应的&lt;code&gt;Proxy&lt;/code&gt;标记为&lt;code&gt;offline&lt;/code&gt;(下线状态)，通过&lt;code&gt;dashboard&lt;/code&gt;能够展示出各个&lt;code&gt;Proxy&lt;/code&gt;的状态，由管理员来处理异常。&lt;/p&gt;

&lt;p&gt;那将&lt;code&gt;Proxy&lt;/code&gt;的状态直接从&lt;code&gt;online&lt;/code&gt;更行为&lt;code&gt;migrate&lt;/code&gt;状态为何不行？如果直接这么做，那么可能有些&lt;code&gt;Proxy&lt;/code&gt;知道&lt;code&gt;Slot&lt;/code&gt;进入了迁移状态，有些&lt;code&gt;Proxy&lt;/code&gt;还不知道（认为是&lt;code&gt;online&lt;/code&gt;状态），此时就不能保证slot迁移中，key从一个节点迁移到另一个节点是原子性的了。&lt;/p&gt;

&lt;p&gt;为了保证一致性，在slot为&lt;code&gt;pre_migrate&lt;/code&gt;状态时是不能对该slot操作的，直到切换到&lt;code&gt;migrate&lt;/code&gt;才能再次写（&lt;code&gt;pre_migrate&lt;/code&gt;时间短暂，对性能影响较小），锁的粒度比较细。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;pre_migrate&lt;/code&gt;期间，不能写入处于迁移状态的&lt;code&gt;slot&lt;/code&gt;；在&lt;code&gt;migrate&lt;/code&gt;状态下，能够保证对该&lt;code&gt;slot&lt;/code&gt;中，每一个key操作是原子性的。&lt;/p&gt;

&lt;h4 id=&#34;2pc示例详解&#34;&gt;2PC示例详解&lt;/h4&gt;

&lt;p&gt;上述分析&lt;code&gt;Codis&lt;/code&gt;的2PC时涉及到的几个要素：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;迁移模块&lt;/code&gt;：负责迁移的发起、对&lt;code&gt;zookeeper&lt;/code&gt;的操作，相应&lt;code&gt;slot&lt;/code&gt;状态的更新等;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Proxy&lt;/code&gt;处理状态变更：在&lt;code&gt;Proxy&lt;/code&gt;接收到slot的状态变更（&lt;code&gt;pre_migrate&lt;/code&gt;、&lt;code&gt;migrate&lt;/code&gt;）时，作了哪些相关处理;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Proxy&lt;/code&gt;处理客户端请求：&lt;code&gt;Proxy&lt;/code&gt;如何响应客户端redis命令请求的（特别是&lt;code&gt;slot&lt;/code&gt;处在迁移状态中）;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;迁移任务&#34;&gt;迁移任务&lt;/h5&gt;

&lt;p&gt;该模块主要负责&lt;code&gt;迁移任务&lt;/code&gt;的发起，并将更新的状态写入&lt;code&gt;zookeeper&lt;/code&gt;以通知集群中的各个&lt;code&gt;Proxy&lt;/code&gt;节点。&lt;code&gt;Codis&lt;/code&gt;创建了协程定时从&lt;code&gt;zookeeper&lt;/code&gt;中读取迁移任务并执行。执行函数大体如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;//单个slot的迁移
func (t *MigrateTask) migrateSingleSlot(slotId int, to int) error {

    // .......

    /*
     * 完成状态转换：
     * ONLINE -&amp;gt; SLOT_STATUS_PRE_MIGRATE -&amp;gt; SLOT_STATUS_MIGRATE
     * 状态更新过程中，各个Proxy会收到slot状态变更通知，做相应处理
     */
    if err := s.SetMigrateStatus(t.zkConn, from, to); err != nil {
        log.ErrorErrorf(err, &amp;quot;set migrate status failed&amp;quot;)
        return err
    }

    /*
     * 执行迁移命令:
     * 将slot中的key逐个的迁移到新的group中
     * 在原生Redis中加入了 SLOTSMGRTTAGSLOT 迁移命令
     */
    t.Migrate(s, from, to, func(p SlotMigrateProgress) 

    // 迁移完成，将该slot状态改回 SLOT_STATUS_ONLINE 状态
    s.State.Status = models.SLOT_STATUS_ONLINE
    s.State.MigrateStatus.From = models.INVALID_ID
    s.State.MigrateStatus.To = models.INVALID_ID

    // 更新slot状态信息
    if err := s.Update(t.zkConn); err != nil {
        log.ErrorErrorf(err, &amp;quot;update zk status failed, should be: %+v&amp;quot;, s)
        return err
    }

}

&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;proxy处理状态迁移&#34;&gt;Proxy处理状态迁移&lt;/h5&gt;

&lt;p&gt;状态迁移中，会重新建立slot与groupId, redis-server的连接关系。并且如果状态为&lt;code&gt;pre_migrate&lt;/code&gt;， 会阻塞slot的所有操作，直到状态变为&lt;code&gt;migrate&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;//对于从zookeeper收到的状态变更处理函数
func (s *Server) checkAndDoTopoChange(seq int) bool {
   
    // ........

    switch act.Type {
    // slot状态变更，获取zookeeper中slot的信息
    case models.ACTION_TYPE_SLOT_MIGRATE, models.ACTION_TYPE_SLOT_CHANGED,
        models.ACTION_TYPE_SLOT_PREMIGRATE:
        slot := &amp;amp;models.Slot{}
        s.getActionObject(seq, slot)
        
        s.fillSlot(slot.Id)

    // .......
}

//更新slotId与groupId的映射关系，建立与redis-server的连接
func (s *Server) fillSlot(i int) {

    // ........
    /*
     * 如果slot变更为SLOT_STATUS_MIGRATE，其所属groupId也变更了
     * 需要获取原先的 groupId
     */
    var addr = groupMaster(*slotGroup)
    if slotInfo.State.Status == models.SLOT_STATUS_MIGRATE {
        fromGroup, err := s.topo.GetGroup(slotInfo.State.MigrateStatus.From)
        if err != nil {
            log.PanicErrorf(err, &amp;quot;get migrate from failed&amp;quot;)
        }
        from = groupMaster(*fromGroup)
        if from == addr {
            log.Panicf(&amp;quot;set slot %04d migrate from %s to %s&amp;quot;, i, from, addr)
        }
    }

    // 更新slot所属的groupId
    s.groups[i] = slotInfo.GroupId
    /*
     * s.router.FillSlot()函数主要完成与redis-server的连接
     * 同时判断当前状态，如果处于pre_migrate会阻塞客户端对该slot的所有操作
     */
    s.router.FillSlot(i, addr, from,
        slotInfo.State.Status == models.SLOT_STATUS_PRE_MIGRATE)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;proxy处理客户端请求&#34;&gt;Proxy处理客户端请求&lt;/h5&gt;

&lt;p&gt;&lt;code&gt;客户端&lt;/code&gt;的redis请求会通过&lt;code&gt;Proxy&lt;/code&gt;的路由规则，转发给指定的slot处理。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (s *Slot) forward(r *Request, key []byte) error {
	//这里对于pre_migrate状态会阻塞，该slot中key的所有命令将不执行
    s.lock.RLock()
    /*
     * 执行redis命令前的准备工作:
     * 1. 检查slot是否处于迁移状态中
     * 2. 强制迁移指定key到新的redis-server
     * 3. 检查和后端redis连接是否存在，检查slot是否处于迁移状态中，如果是，强制迁移指定key到新的redis-server
     */
    bc, err := s.prepare(r, key)

    //将redis命令发向新的redis-server
    bc.PushBack(r)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从示例代码中，我们能够看到，在&lt;code&gt;pre_migrate&lt;/code&gt;状态下，该slot的操作是阻塞的。在&lt;code&gt;migrate&lt;/code&gt;状态下，对slot的key操作是原子的：首先向旧的&lt;code&gt;groupId&lt;/code&gt;所在的&lt;code&gt;redis-server&lt;/code&gt;发送&lt;code&gt;SLOTSMGRTTAGONE&lt;/code&gt;命令，完成单个&lt;code&gt;key&lt;/code&gt;的迁移，然后向新的&lt;code&gt;groupId&lt;/code&gt;所在的&lt;code&gt;redis-server&lt;/code&gt;进行该&lt;code&gt;key&lt;/code&gt;的操作。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.tuicool.com/articles/FFb2Uvz&#34;&gt;一致性协议&amp;ndash;2PC与3PC&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.tuicool.com/articles/2qUnUfv&#34;&gt;codis 数据迁移期间的一致性&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;大数据日知录:架构与算法 Ch2-数据一致性协议&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>分布式存储之CAP原则</title>
          <link>https://maodanp.github.io/2016/07/02/bigdata-cap/</link>
          <pubDate>Sat, 02 Jul 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/07/02/bigdata-cap/</guid>
          <description>&lt;p&gt;深入理解分布式环境需要理解几个基本的概念CAP、BASE、ACID等。本篇以下记录了这几个基本概念及其关系。&lt;/p&gt;

&lt;h3 id=&#34;cap原则&#34;&gt;CAP原则&lt;/h3&gt;

&lt;p&gt;CAP(Consistency/Availavility/Partition Tolerance)分别代表强一致性、可用性、分区容忍性。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;强一致性&lt;/strong&gt; 在分布式系统中的同一份数据多副本情形下，对数据的更新操作体现出的效果与只有一份数据是一样的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;可用性&lt;/strong&gt;：客户端在任何时刻对大规模数据系统的读、写操作都应该保证在限定的时间内完成。一定时间指的是，在可以容忍的范围内返回结果，结果可以是成功或者失败。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;分区容忍性&lt;/strong&gt;：在大规模数据系统中，网络分区现象（分区间的机器无法进行网络通信的情况）必然会发生，系统需要能够在这种情况下继续工作。就分布式存储而言，分区相当于系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;cap权衡&#34;&gt;CAP权衡&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;It states, that though its desirable to have Consistency, High-Availability and Partition-tolerance in every system, unfortunately no system can achieve all three at the same time.&lt;/p&gt;

&lt;p&gt;在分布式系统的设计中，没有一种设计可以同时满足一致性，可用性，分区容错性 3个特性&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;一个数据存储系统不可能同时满足上述三个特性，只能同时满足其两个特性(CA,CP,AP)。当前所有的数据存储解决方案，都可以归类的上述三种类型。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CA&lt;/strong&gt; 满足数据的一致性和高可用，但是没有可扩展性。传统的关系型数据库基本都采用该原则（Oracle、Mysql等）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CP&lt;/strong&gt; 满足数据的一致性和分区性，但是会牺牲数据一致性。一旦遇到分区容错故障，那么受到影响的服务需要等待一定的时间，因此在等待期间系统无法对外提供服务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AP&lt;/strong&gt; 满足数据的可用性和分忍性，但在数据一致性方面会作牺牲(这里指的是强一致性)，但是能够保证数据的最终一致性。比如当前的NoSql大多都是这种。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-07-02-bigdata-cap-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C与A的抉择&lt;/strong&gt;： 在分布式存储系统中，网络必然会出现延迟丢包等问题，或者说集群中的节点必然动态加入与离开（也可以认为是集群内部的网络分区），所以分区容忍性是必须要遵守的原则。所以我们只能在一致性和可用性之间进行权衡。&lt;/p&gt;

&lt;h4 id=&#34;简单示例&#34;&gt;简单示例&lt;/h4&gt;

&lt;p&gt;一个DB服务搭建在两个机房，两个DB实例同时提供写入和读取&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-07-02-bigdata-cap-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;1.假设DB的更新操作是同时写DB都成功才返回成功，网络故障无法提供服务/提供降级的读取服务&lt;/p&gt;

&lt;p&gt;在没有出现网络故障的时候，满足CAP原则。如果网络出现故障，无法提供服务或者只能提供读取功能，所以返回失败，即&lt;code&gt;A&lt;/code&gt;条件无法满足，仅能满足&lt;code&gt;CP&lt;/code&gt;原则。&lt;/p&gt;

&lt;p&gt;2.假设DB的更新操作是只写本地机房成功就返回，通过&lt;code&gt;binlog/oplog&lt;/code&gt;回放方式同步至侧边机房&lt;/p&gt;

&lt;p&gt;这种操作保证了在出现网络故障时,双边机房都是可以提供服务的，读写操作都能成功，意味着满足了&lt;code&gt;AP&lt;/code&gt;，但是它不满足&lt;code&gt;C&lt;/code&gt;条件，因为更新操作返回成功后，双边机房的DB看到的数据会存在短暂不一致（仅能保证最终一致性）。&lt;/p&gt;

&lt;h4 id=&#34;cap-reolad&#34;&gt;CAP Reolad&lt;/h4&gt;

&lt;p&gt;Eric Brewer在2012年发表文章中指出：实践过程中应用CAP理论时不得不在三要素中选择两个而牺牲另外一个的做法具有误导性。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实际系统中，网络分区（P）出现概率很小，不应为了容忍这种小概率事件而在设计之初就选择放弃A或者C。&lt;/li&gt;
&lt;li&gt;即使必须在AC之间做出取舍，也不应该是粗粒度的在整个系统级别进行取舍，而是应该考虑系统中存在不同的子系统。&lt;/li&gt;
&lt;li&gt;CAP三者并非是绝对二元式的有或无，而是应该将其看作连续变量，即可以看作在一定程度上的有或没有。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对传统CAP的修正步骤：
&lt;strong&gt;首先&lt;/strong&gt;能够识别网络分区的发生，&lt;strong&gt;然后&lt;/strong&gt;在网络分区场景下进入明确的分区模式，此时会限制某些系统，&lt;strong&gt;最后&lt;/strong&gt;在网络分区解决后能够进行善后处理，即恢复数据的一致性或者弥补分区模式中产生的错误。&lt;/p&gt;

&lt;h3 id=&#34;acid原则&#34;&gt;ACID原则&lt;/h3&gt;

&lt;p&gt;ACID是关系型数据库采纳的原则，代表定义为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;原子性（Atomicity）&lt;/strong&gt;：一个事务要么全部执行，要么完全不执行，不允许一个事务只执行一半就停止&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;一致性（Consistency）&lt;/strong&gt;：事务在开始和结束时，应该始终满足一致性约束条件&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;事务独立（Isolation）&lt;/strong&gt;：如果有多个事务同时执行，彼此之间不需要知晓对方的存在，而且执行时互不影响，不允许出现两个事务交错、间隔执行部分任务的情形。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;持久性（Durability）&lt;/strong&gt;：事务的持久性是指事务运行成功以后，对系统状态的更新是永久的，不会无缘由的回滚撤销。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;base-原则&#34;&gt;BASE 原则&lt;/h3&gt;

&lt;p&gt;大多数环境下的云存储系统和NoSQL系统采纳了BASE原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;基本可用（Basically Available）&lt;/strong&gt;：在绝大多数时间内系统处于可用状态，允许偶尔失败，所以称为基本可用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;软状态/柔性状态（Soft State）&lt;/strong&gt;：数据状态不要求在任意时刻都完全保持同步，即处于有状态和无状态之前的中间状态。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最终一致性（Eventual Consistency）&lt;/strong&gt;：最终一致性是一种弱一致性，软状态不要求任意时刻数据保持一致同步，但最终一致性要求在给定时间窗口内数据会达到一致状态。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;cap-base-acid-三者关系&#34;&gt;CAP/BASE/ACID 三者关系&lt;/h3&gt;

&lt;p&gt;ACID更加强调的是数据一致性，为传统数据库设计的思路，类似于CAP中的CA原则；BASE强调的是可用性，弱化数据强一致性的概念，是对大规模分布式数据系统的一种需求，类似于CAP中的AP原则。&lt;/p&gt;

&lt;p&gt;ACID与CAP的兼顾：
1. ACID中的C指的是对操作的一致性约束，而CAP中的C指的是数据的强一致性（多副本对外表现类似于单副本），可以将CAP中的C看做ACID中C所涵盖语义的子集。
2. 当出现网络分区时，ACID中的事务只能在多个分区中的某个分区执行，事务的序列化要求通信，而网络分区出现无法做到这一定。
3. 当出现网络分区时，多个分区可以进行ACID中的D持久化操作，当网络分区解决后，则集群会根据这些记录发现违反ACID一致性约束的内容并予以纠正。&lt;/p&gt;

&lt;p&gt;总之，当CAP中的P出现时，如果每个分区都尽可能执行ACID，那么对于网络分区问题解决后数据一致性恢复将有很大帮助。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/Creator/p/3762315.html&#34;&gt;分布式系统设计权衡之CAP&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/hxsyl/p/4381980.html&#34;&gt;分布式系统之CAP理论&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>分布式存储之数据切片</title>
          <link>https://maodanp.github.io/2016/06/25/bigdata-data-slice/</link>
          <pubDate>Sat, 25 Jun 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/06/25/bigdata-data-slice/</guid>
          <description>&lt;p&gt;在大数据时代，稍大型企业的数据量已经达到TB甚至PB级别，显然单机无法存储于处理如此规模的数据量。分布式数据的存储必然涉及到数据的分片，本篇分析了几种常用的数据分片模型。&lt;/p&gt;

&lt;h3 id=&#34;1-数据分片概念&#34;&gt;1. 数据分片概念&lt;/h3&gt;

&lt;p&gt;目前主流的大数据存储于计算系统通常采用&lt;strong&gt;横向扩展&lt;/strong&gt;方式支持系统的可扩展性，即通过增加机器数据获得水平扩展能力。&lt;/p&gt;

&lt;p&gt;对于待存储的海量数据，需要通过&lt;strong&gt;数据分片(Shard/Partition)&lt;/strong&gt;来将数据进行切分、并通过&lt;strong&gt;数据路由(Route)&lt;/strong&gt;机制分配到各个机器中。&lt;/p&gt;

&lt;p&gt;这里需要区分数据分片与数据复制的概念。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;数据分片&lt;/em&gt;&lt;/strong&gt;: 实现的是系统的水平扩展，达到通过增加机器来提高容量的目的&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;数据复制&lt;/em&gt;&lt;/strong&gt;: 实现的是数据的高可用性，将数据复制多份来保障数据不会丢失（但是对数据更新时存在一致性问题）&lt;/p&gt;

&lt;h3 id=&#34;2-分片模型&#34;&gt;2. 分片模型&lt;/h3&gt;

&lt;p&gt;下图为数据分片与路由的通用模型。相当于经过了二级映射。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;第一级映射是&lt;strong&gt;key-partition&lt;/strong&gt;映射，多对一映射关系，即多条记录被映射到同一个数据分片中&lt;/li&gt;
&lt;li&gt;第二级映射是&lt;strong&gt;partition-machine&lt;/strong&gt;映射，多对一映射关系，即多个数据分片被映射到同一个物理机中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-06-25-bigdata-data-slice-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;哈希分片&lt;/strong&gt;和&lt;strong&gt;范围分片&lt;/strong&gt;都可以映射到这个抽象模型中。&lt;strong&gt;&lt;em&gt;哈希分片&lt;/em&gt;&lt;/strong&gt;，主要是通过哈希函数来建立&lt;strong&gt;key-partition&lt;/strong&gt;映射关系，只能根据某个记录的主键获得记录内容，但是哈希方法需要记录的元信息非常的简单，只需要知道哈希函数的计算方式就行。&lt;strong&gt;&lt;em&gt;范围/顺序分片&lt;/em&gt;&lt;/strong&gt;，该分片方式在分布式表格系统中比较常见，能够根据指定的主键范围一次性读取多条满足条件的记录。&lt;/p&gt;

&lt;h3 id=&#34;3-哈希分片&#34;&gt;3. 哈希分片&lt;/h3&gt;

&lt;p&gt;通过哈希函数进行数据分片是常用手段，常用的三种哈希分片是：Round Robin、虚拟桶、一致性哈希等方法。&lt;/p&gt;

&lt;h4 id=&#34;3-1-round-robin-哈希取模&#34;&gt;3.1 Round Robin/哈希取模&lt;/h4&gt;

&lt;p&gt;该方法是非常常用的数据分片方法。将哈希值与服务器个数作除法取模映射，假设有K台物理机，则通过以下哈希函数即可实现数据分片：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;H(Key) = hash(key)mod K
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;H(Key)&lt;/code&gt;的数值即为存储该数据的物理机的编号。但是当服务器上线或者下线时，K的值发生变化，数据映射完全被打乱，几乎所有的额数据都需要重新分布，这将带来大量的数据迁移工作。&lt;/p&gt;

&lt;h4 id=&#34;3-2-虚拟桶-内存表&#34;&gt;3.2 虚拟桶/内存表&lt;/h4&gt;

&lt;p&gt;该思路不再简单的将哈希值和服务器个数做除法取摸映射，而是将哈希值与服务器的对应关系作为元数据，交给专门的虚拟桶/内存表来管理。所有记录首先通过哈希函数映射到对应的虚拟桶（多对一映射），第二层映射是虚拟桶和物理机之间的映射关系（多对一映射），可以通过查内存表来管理。&lt;/p&gt;

&lt;p&gt;该方式相比于Round Roubin，由原先&lt;strong&gt;记录&lt;/strong&gt;直接到&lt;strong&gt;物理机&lt;/strong&gt;的单层映射解耦成两层映射，大大加强了系统的扩展灵活性。这样，集群扩容是，可以将部分哈希值分配给新加入的机器并迁移对应的数据。&lt;/p&gt;

&lt;h4 id=&#34;3-3-一致性哈希&#34;&gt;3.3 一致性哈希&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;分布式哈希（DHT）&lt;/strong&gt;是P2P(Peer-to-Peer)网络（对等网络）和分布式存储中常见的一项技术。即考虑在多机分布环境，每台机器负责承载部分数据的存储情形下，如何通过哈希方式对数据进行增/删/改/查等数据操作的方法。&lt;/p&gt;

&lt;p&gt;算法思想： 给系统中每个节点（物理机器）分配一个token（根据物理机器IP、端口映射到哈希空间），这些token构成一个哈希环。执行数据增加操作时，先计算数据Key的哈希值，然后存放到顺时针方向第一个大于等于该哈希值的token所在的节点。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一致性的优点在于节点加入、删除时只会影响在哈希环中相邻的节点，而对其他节点没有影响。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;假设哈希空间表示的长度为n, 则哈希空间所表达的数值范围是 \(0-2^n\) , 一致性哈希算法大致如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;首先求出每个服务器的hash值，将其配置到一个 \(0-2^n\) 圆环区间上；&lt;/li&gt;
&lt;li&gt;使用同样的方法求出待存储的主键hash值，也将其配置到这个圆环上；&lt;/li&gt;
&lt;li&gt;数据的路由，将数据存储到找到合适的服务器节点上（下面的路由问题）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-06-25-bigdata-data-slice-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;3-3-1-路由问题&#34;&gt;3.3.1 路由问题&lt;/h5&gt;

&lt;p&gt;上述方法能够将海量数据分布到集群中的不同机器集群, 实现数据分片功能。那对于接收到查询请求的节点（该服务器节点可以是hash环中的任意一个），如何根据数据记录的主键以及哈希函数来定位到记录的内容呢？&lt;/p&gt;

&lt;p&gt;下面列举了基于空间复杂度的几种路由方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;O(1)&lt;/code&gt; 顺序查找法&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这是一种最直观的查找方法。每台服务器只要记录它的前一个以及后一个节点的位置信息。接收到查询请求的节点计算出数据主键的Hash值，然后判断是否在自身范围内，不在则转交给后继节点继续查找，如此循环直到找到某个机器节点。&lt;/p&gt;

&lt;p&gt;该做法维护的节点位置信息的空间复杂度为&lt;code&gt;O(1)&lt;/code&gt;, 但是有可能遍历hash环中所有服务器，所以时间复杂度为&lt;code&gt;O(N)&lt;/code&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;O(N)&lt;/code&gt;路由表法&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了加速查询，可以在每个机器节点维护一个大小为&lt;code&gt;N&lt;/code&gt;的路由表（假设哈希空间为 \(0~2^n\)，这里n即为Hash空间二进制数值比特位长度）, 路由表中的第 i 个元素记录了编号为  \(p+2^{i-1}\), 其中p为服务器在Hash环中的编号。 通过维护  &lt;code&gt;O(N)&lt;/code&gt; 的位置信息，查找的时间复杂度可以改进为 &lt;code&gt;Olog(N)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;还有一种方式，就是在每个机器节点维护一个大小为&lt;code&gt;N&lt;/code&gt;的路由表，这里的&lt;code&gt;N&lt;/code&gt;不是Hash空间的长度，而是物理节点的个数。即在每个服务器维护整个集群中所有服务器的位置信息，查找服务器的时间复杂度为 &lt;code&gt;Olog(N)&lt;/code&gt;。工程上一般采用这种方法，一般需要一个带有总控节点的存储系统来统一维护这张表。&lt;/p&gt;

&lt;h5 id=&#34;3-3-2-节点的加入-离开&#34;&gt;3.3.2 节点的加入/离开&lt;/h5&gt;

&lt;p&gt;节点的加入根据“路由问题“可以找到后继节点，则改变相应位置的前驱、后继节点的位置关系，以体现新的网络结构。同时需要将对应的数据重新进行分片，进行数据的迁移。&lt;/p&gt;

&lt;p&gt;节点的离开需要考虑正常与异常离开。正常离开前需要做些准备工作，包括通知相应节点更新前驱后继节点以及将本身持有数据迁移到后继节点上。异常离开往往是机器故障导致，为避免故障机器中数据可能丢失，需要采用将同一份数据在多台机器上保留副本的方式。&lt;/p&gt;

&lt;h5 id=&#34;3-3-3-虚拟节点&#34;&gt;3.3.3 虚拟节点&lt;/h5&gt;

&lt;p&gt;引入”虚拟节点“的概念，主要为解决一致性哈希算法潜在的问题：机器节点映射到环状结构的位置是随机的，可能会导致机器负载不均衡；同时如果将所有机器平等看待会导致低配置机器高负载的情况。&lt;/p&gt;

&lt;p&gt;虚拟节点即将一个物理节点虚拟成若干的虚拟节点，分别映射到一致性哈希的环状结构的不同位置。一方面会有更佳的负载均衡，也可以兼顾到机器的异质性问题。&lt;/p&gt;

&lt;p&gt;下面简要展示Golang实现的&lt;a href=&#34;https://github.com/stathat/consistent&#34;&gt;一致性Hash算法&lt;/a&gt;的主要结构。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;//定义Hash环，切片中元素为有序的物理节点Hash值
type Circle []uint32


type Consistent struct {
	// Hash函数
    hash  Hash  		
    // 有序环
    circle   Circle 
    //虚拟节点个数
    virtualNodes int
    //点到主机的映射（多对一的关系）
    virtualMap   map[uint32]string
    //主机列表
    members      map[string]bool
    //同步锁
    sync.RWMutex
}

//向Hash环中加入节点
func (c *Consistent) Add(elt string) 

//从Hash环中删除节点
func (c *Consistent) Remove(elt string) 

//根据数据主键，获取存储的节点信息
func (c *Consistent) Get(key string) string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对照上面的结构，大致的结构图如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-06-25-bigdata-data-slice-3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当然，以上的实现是对于一致性Hash的基本操作，具体的业务还需要考虑数据的存储，迁移，备份等等操作。&lt;/p&gt;

&lt;h3 id=&#34;4-范围分片&#34;&gt;4. 范围分片&lt;/h3&gt;

&lt;p&gt;范围分片首先将所有记录的主键进行排序，然后在排序好的主键空间里将记录划分成连续的范围（每个范围称为一个&lt;code&gt;子表&lt;/code&gt;），每个字表存储有序的主键空间片段内的所有记录，通过范围分片能够避免哈希分布的数据散列问题。&lt;/p&gt;

&lt;p&gt;范围分片对应的key-partition映射表是通过记录主键排序切割获得的，而不同于哈希分片通过Hash函数获得。&lt;/p&gt;

&lt;p&gt;很多大规模存储系统都支持上述范围的分片模式，比如Google的BigTable也基本遵循上述模式。不同点在于其数据分片映射表不是单层结构，而是组织成类似B+树的层次结构，这样可容纳的数据分片个数获得极大的提升。&lt;/p&gt;

&lt;p&gt;B+树的层次结构中，每个字表相当于叶子节点，随着数据的插入和删除，某些字表可能变得很大或很小，数据分布不均匀。采用范围分片设计时就需要考虑子表的&lt;code&gt;分裂&lt;/code&gt;与&lt;code&gt;合并&lt;/code&gt;，这也将极大的增加系统的复杂度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;子表分裂&lt;/strong&gt;是指当一个子表太大超过一定的阈值时需要分裂为两个子表，从而有机会通过系统的负载均衡机制分散到多个存储节点&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;子表合并&lt;/strong&gt;一般由数据删除引起，当相邻的两个子表都很小时，可以合并为一个子表。合并的目的是为了防止系统中出现过多太小的子表，较少系统中的元数据。&lt;/p&gt;

&lt;h3 id=&#34;5-参考阅读&#34;&gt;5. 参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/haippy/archive/2011/12/10/2282943.html&#34;&gt;一致性Hash算法背景&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;大数据日知录:架构与算法 Ch1&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>浏览器缓存</title>
          <link>https://maodanp.github.io/2016/05/23/web-cache/</link>
          <pubDate>Mon, 23 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/05/23/web-cache/</guid>
          <description>&lt;p&gt;当我们通过浏览器打开一个web页面的时候，浏览器需要从web服务器下载各种资源（网页、脚本、样式表等）。但并不是每次请求都需要从web服务器中获取的，浏览器自身可以设置缓存。本篇将会介绍些浏览器的缓存技术。&lt;/p&gt;

&lt;p&gt;浏览器使用缓存的好处有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;较少服务器的计算开销，避免由于内容的重复传输带来的带宽浪费&lt;/li&gt;
&lt;li&gt;浏览器自身缓存，只需要从本地缓存取资源，响应速度比网络快&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;因为浏览器和服务器是通过HTTP协议沟通的，所以浏览器缓存本质是HTTP协议的缓存。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;不使用缓存&#34;&gt;不使用缓存&lt;/h3&gt;

&lt;p&gt;我们可以通过php动态网页来模拟设置一些缓存信息，通过添加必要的HTTP头信息（浏览器不区分内容是否是动态生成的）。响应头如果是POST模式递交数据，则返回的页面大部分不会被浏览器缓存，如果你发送内容通过URL和查询（通过GET模式），则返回的内容可以缓存下来供以后使用。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?php
echo time();
?&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;请求头如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Request URL:http://vmnet64.com/http_cache.php
Request Method:GET
Status Code:200 OK
Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
Accept-Encoding:gzip, deflate, sdch
Accept-Language:zh-CN,zh;q=0.8,en;q=0.6
Cache-Control:max-age=0
Connection:keep-alive
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;响应头如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;view source
Connection:keep-alive
Content-Type:text/html
Date:Wed, 27 Apr 2016 04:14:53 GMT
Server:nginx/1.6.3
Transfer-Encoding:chunked
X-Powered-By:PHP/5.4.16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于这里服务端未使用缓存，所以刷新每次都会从服务器获取响应结果(笔者MAC中的浏览器有 chrome/safari)。&lt;/p&gt;

&lt;h3 id=&#34;last-modified&#34;&gt;Last-Modified&lt;/h3&gt;

&lt;p&gt;一般web服务器会为静态文件的HTTP响应头自动生成&lt;code&gt;最后修改时间&lt;/code&gt;，而动态内容一般不存在传统意义上的最后修改时间。这里为演示方便，给演示脚本http_cache.php设置了。&lt;/p&gt;

&lt;h4 id=&#34;last-modified-设置&#34;&gt;Last-Modified 设置&lt;/h4&gt;

&lt;p&gt;修改代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?php
header(&amp;quot;Last-Modified: &amp;quot; . gmdate(&amp;quot;D, d M Y H:i:s&amp;quot;) . &amp;quot; GMT&amp;quot;);
echo time();
?&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;此时，Web服务器的HTTP响应头中增加了一个字段：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Last-ModifiedWed, 27 Apr 2016 04:47:52 GMT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;它代表了Web服务器对浏览器的暗示，告诉它当前请求内容的最后修改时间。此时，再次刷新浏览器，它发出的HTTP请求多了一行字段：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;If-Modified-Since:Wed, 27 Apr 2016 04:47:52 GMT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这意味着浏览器在询问Web服务器“请求的内容在这个时间之后是否有更新”。主要任务在Web服务器，它需要检查这个内容在该时间后是否有过更新，并反馈给浏览器结果。&lt;/p&gt;

&lt;h4 id=&#34;对if-modified-since-的处理&#34;&gt;对If-Modified-Since 的处理&lt;/h4&gt;

&lt;p&gt;下面在动态脚本中加入对浏览器的询问的接受处理过程，代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?php
$modified_time = $_SERVER[&#39;HTTP_IF_MODIFIED_SINCE&#39;]
if (strtotime($modified_time) + 60 &amp;gt; time()) {
    header(&amp;quot;HTTP/1.1 304&amp;quot;);
    exit(1);
}
header(&amp;quot;Last-Modified: &amp;quot; . gmdate(&amp;quot;D, d M Y H:i:s&amp;quot;) . &amp;quot; GMT&amp;quot;);
echo time();
?&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;此时，再次刷新浏览器，可以看到请求头：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Request URL:http://vmnet64.com/http_cache.php
Request Method:GET
Status Code:304 
Remote Address:192.168.126.130:80
Response Headers
view source
Connection:keep-alive
Date:Wed, 27 Apr 2016 05:03:54 GMT
Server:nginx/1.6.3
X-Powered-By:PHP/5.4.16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上PHP脚本，首先获取HTTP请求中的If-Modified-Since字段，然后将它将它和当前服务器时间比较，如果距离当前时间不到一分钟，就返回304状态码，此时浏览器收到304后，会取本地缓存的资源。但是对于静态网页来说，就不需要写脚本比较时间了，&lt;strong&gt;Web服务器只要将静态文件的最后修改时间与浏览器询问的时间进行对比即可&lt;/strong&gt; 。&lt;/p&gt;

&lt;h4 id=&#34;etag&#34;&gt;ETag&lt;/h4&gt;

&lt;p&gt;HTTP/1.1另一种协商方法，该方式不采用内容的最后修改时间，而是采用一串编码来标记内容，称之为ETag。该协商方式的原则是：&lt;strong&gt;如果一个内容的ETag没有变化，那么这个内容也一定没有更新&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;由于服务器控制了ETag如何生成，Web服务器可以通过If-None-Match来标识请求内容是否变化了。eTag的校验方式正越来越流行。&lt;/p&gt;

&lt;h4 id=&#34;对服务器性能的影响&#34;&gt;对服务器性能的影响&lt;/h4&gt;

&lt;p&gt;性能问题也需要分静态文件与动态文件。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;对静态类型的文件来说，服务器吞吐量的提升是非常相当明显，而且服务器的带宽使用率也大大降低&lt;/li&gt;
&lt;li&gt;对动态类型的文件来说，主要瓶颈是在Web服务器端的计算。所以，需要后端的优化&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;expires&#34;&gt;Expires&lt;/h3&gt;

&lt;p&gt;上述的Last-Modified缓存协商方式，每次都需要和Web服务器沟通，还有一种方式能够彻底消灭请求。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The goal of caching in HTTP/1.1 is t eliminate the need to send requests in mang cases&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;Expires&lt;/code&gt;这种标记，它通知浏览器该内容在何时过期，按时浏览器在内容过期之前不再询问服务器，而是直接通过本地缓存获得内容即可。Expires 字段接收以下格式的值：&lt;code&gt;“Expires: Sun, 08 Nov 2009 03:37:26 GMT”&lt;/code&gt;。如果查看内容时的日期在给定的日期之前，则认为该内容没有失效并从缓存中提取出来。反之，则认为该内容失效，缓存将采取一些措施。&lt;/p&gt;

&lt;p&gt;静态文件一般不开启Expires标记的支持，需要对Web服务器进行配置； 对于动态内容，则仍需要程序来添加。&lt;/p&gt;

&lt;h4 id=&#34;expires标记&#34;&gt;Expires标记&lt;/h4&gt;

&lt;p&gt;以下将Expires标记添加到它的响应HTTP头中，代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?php
$modified_time = $_SERVER[&#39;HTTP_IF_MODIFIED_SINCE&#39;]
if (strtotime($modified_time) + 60 &amp;gt; time()) {
    header(&amp;quot;HTTP/1.1 304&amp;quot;);
    exit(1);
}
header(&amp;quot;Last-Modified: &amp;quot; . gmdate(&amp;quot;D, d M Y H:i:s&amp;quot;) . &amp;quot; GMT&amp;quot;);
**header(&amp;quot;Expires: &amp;quot; . gmdate(&amp;quot;D, d M Y H:i:s&amp;quot;, time() + 60) . &amp;quot; GMT&amp;quot;);**
echo time();
?&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;HTTP响应中也会出现Expires的标记：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Expires:Wed, 27 Apr 2016 07:01:46 GMT
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;不同的请求方方式&#34;&gt;不同的请求方方式&lt;/h4&gt;

&lt;p&gt;对于浏览器的操作不同，浏览器的处理方式就不同了，这也是很有意思的。&lt;a href=&#34;http://blog.csdn.net/longxibendi/article/details/41630389&#34;&gt;浏览器缓存机制详解&lt;/a&gt;文章中专门罗列出了对不同浏览器的不同操作，浏览器的请求资源的方式。&lt;/p&gt;

&lt;h3 id=&#34;cache-control-适应本地的过期时间&#34;&gt;Cache-Control(适应本地的过期时间)&lt;/h3&gt;

&lt;p&gt;由于通过Expires制定的过期时间，是来自于Web服务器的系统时间，如果用户本地时间和服务器时间不一致，则会影响到本地缓存的有效期检查。HTTP/1.1中通过一个标记来弥补Expires的不足：Cache-Control。&lt;/p&gt;

&lt;p&gt;格式如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Cache-Control = “Cache-Control” “:” cache-directive
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下表展示了cache-directive常用的值：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Cache-directive&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;public&lt;/td&gt;
&lt;td&gt;所有内容都将被缓存(客户端和代理服务器都可缓存)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;private&lt;/td&gt;
&lt;td&gt;内容只缓存到私有缓存中(仅客户端可以缓存，代理服务器不可缓存)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;no-cache&lt;/td&gt;
&lt;td&gt;必须先与服务器确认返回的响应是否被更改，&lt;br&gt;然后才能使用该响应来满足后续对同一个网址的请求。&lt;br&gt;若存在合适的ETag，no-cache会发起往返通信来验证缓存的响应，&lt;br&gt;如果资源未被更改，可以避免下载。&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;no-store&lt;/td&gt;
&lt;td&gt;所有内容都不会被缓存到缓存或 Internet 临时文件中&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;must-revalidation/proxy-revalidation&lt;/td&gt;
&lt;td&gt;如果缓存的内容失效，请求必须发送到服务器/代理以进行重新验证&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;max-age=xxx (xxx is numeric)&lt;/td&gt;
&lt;td&gt;缓存的内容将在 xxx 秒后失效, 这个选项只在HTTP 1.1可用, &lt;br&gt;并如果和Last-Modified一起使用时, 优先级较高&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Cache-Control 是最重要的规则。这个字段用于指定所有缓存机制在整个请求/响应链中必须服从的指令。因此该字段也是浏览器&lt;strong&gt;优先考虑&lt;/strong&gt;的。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://baike.baidu.com/link?url=Eq3IppkwBmkE-jsHtYh0lX0T3krEEKrzqmopIZHgM1fDDqM8cT7-t8nLM6Sf3uQdoeUV8m4FdpzMVFzW5jdOka&#34;&gt;cache-cotrol&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/longxibendi/article/details/41630389&#34;&gt;浏览器缓存机制详解&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>服务器并发策略</title>
          <link>https://maodanp.github.io/2016/05/19/server-concurrent/</link>
          <pubDate>Thu, 19 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/05/19/server-concurrent/</guid>
          <description>&lt;p&gt;技术是随着需求的发展而不断前进的，正如服务器的并发量。对于单台服务器而言，资源是有限的，采用何种并发策略最大限度的利用服务器的性能，提高其吞吐量也是值得研究的，本篇将详述服务器的几种并发策略。&lt;/p&gt;

&lt;p&gt;随着互联网的发展，技术也是在不断的进步的。最初的服务器都是基于进程/线程模型的，新到来一个TCP连接，就需要分配1个进程（或者线程）。一台机器无法创建很多进程。如果是并发数为1万，那就要创建1万个进程，对于单台服务器而言显然是无法承受的。这就是C10K问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-05-19-server-concurrent-c10K.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;web服务器需要不断的读取连接请求，然后进行处理，并将结果发送给客户端。设计并发策略的目的就是让I/O操作和CPU计算尽量重叠进行。以下列举几种常见的并发策略：&lt;/p&gt;

&lt;h3 id=&#34;每个进程处理一个连接-process-per-connection&#34;&gt;每个进程处理一个连接(process-per-connection)&lt;/h3&gt;

&lt;p&gt;基本采用accept+fork系统调用方式，即由主进程负责accept()来自客户端的连接，收到客户端连接后立马fork()一个新的worker进程来处理，处理结束后进程被销毁。&lt;/p&gt;

&lt;p&gt;传统Unix并发网络编程方案，该方案适合并发连接数不大的情况。至今仍有一些网络服务器用这种方式：PostgreSQL和Perforce的服务端。该方案适合“&lt;strong&gt;计算响应时间的工作量远大于fork( )的开销&lt;/strong&gt;”这种情况。这种方案适合长连接，但不大适合短连接，因为fork()开销大于处理任务的用时。Python代码如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#ForkingTCPServer 会对每个客户连接新建一个子进程
from SocketServer import BaseRequestHandler, TCPServer
from SocketServer import ForkingTCPServer, ThreadingTCPServer

class EchoHandler(BaseRequestHandler):
    def handle(self):
        print &amp;quot;got connection from&amp;quot;, self.client_address
        while True:
            data = self.request.recv(4096)
            if data:
                sent = self.request.send(data)    # sendall?
            else:
                print &amp;quot;disconnect&amp;quot;, self.client_address
                self.request.close()
                break

if __name__ == &amp;quot;__main__&amp;quot;:
    listen_address = (&amp;quot;0.0.0.0&amp;quot;, 2007)
    server = ForkingTCPServer(listen_address, EchoHandler)
    server.serve_forever()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;thread-per-connection(每个线程处理一个连接)，该方式与 process-per-connection类似，初始化线程的开销稍微小一些，但连接数仍然线程数的限制，且连接数非常大，对系统将产生很大的负担。&lt;/p&gt;

&lt;h3 id=&#34;每个进程处理多个连接-prefork&#34;&gt;每个进程处理多个连接（prefork）&lt;/h3&gt;

&lt;p&gt;该方式是Apache httpd一直采用的方案，该方式由主进程预先创建一定数量的子进程，每个请求由一个子进程来处理，且每个子进程可以处理多个请求。父进程往往只负责子进程的管理，根据负载管理子进程的数量。&lt;/p&gt;

&lt;p&gt;Apache的所有子进程使用阻塞accept()来竞争接收连接。但是当一个请求连接到达，内核会激活所有阻塞在accept()的子进程，但只有一个能够成功获得连接并返回到用户空间，其余的子进程由于得不到连接而继续回到休眠状态，这种“惊群”也会造成一定的性能损耗。&lt;/p&gt;

&lt;p&gt;当然，一个子进程处理多个请求，有效方式基本都是I/O复用（复用的是进程/线程），可以使用select/poll/epoll等不同方案实现（见[I/O多路复用详解]()）。下面给出了单个进程的poll实现：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#事件的处理通过handlers转发到各个函数中，不再集中在一处
import socket
import select

server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
server_socket.bind((&#39;&#39;, 2007))
server_socket.listen(5)
# serversocket.setblocking(0)

poll = select.poll() # epoll() should work the same
connections = {}
handlers = {}

#普通客户连接的处理函数时handler_request，又将连接断开和数据到达两个事件分开
def handle_input(socket, data):
    socket.send(data) # sendall() partial?

def handle_request(fileno, event):
    if event &amp;amp; select.POLLIN:
        client_socket = connections[fileno]
        data = client_socket.recv(4096)
        if data:
            handle_input(client_socket, data)
        else:
            poll.unregister(fileno)
            client_socket.close()
            del connections[fileno]
            del handlers[fileno]

#listening fd 的处理函数时handle_accept，它会注册客户连接的handler
def handle_accept(fileno, event):
    (client_socket, client_address) = server_socket.accept()
    print &amp;quot;got connection from&amp;quot;, client_address
    # client_socket.setblocking(0)
    poll.register(client_socket.fileno(), select.POLLIN)
    connections[client_socket.fileno()] = client_socket
    handlers[client_socket.fileno()] = handle_request

poll.register(server_socket.fileno(), select.POLLIN)
handlers[server_socket.fileno()] = handle_accept

while True:
    events = poll.poll(10000)  # 10 seconds
    for fileno, event in events:
        handler = handlers[fileno]
        handler(fileno, event)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因为Linux在互联网中是使用率最高的系统，服务器的I/O多路复用基本都采用epoll方式实现。但是epoll依赖于特定的平台。目前主流的web服务器基本采用Reactor模型(事件驱动模型，EventLoop)，如Nginx、Node.js等。&lt;/p&gt;

&lt;h3 id=&#34;reactor模型&#34;&gt;Reactor模型&lt;/h3&gt;

&lt;p&gt;在高性能的web服务器设计中，使用最广泛的基本是Reactor模式（non-blocking IO + IO multiplexing）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-05-19-server-concurrent-reactor.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在该模式下，程序的基本结构是时间循环（event loop），以时间驱动（event-driven）和事件回调方式实现业务逻辑。伪代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;while(!done) {
    int timeout = getNextTimedCallback();
    int retval = epoll(fds, nfds, timeout);
    if (retval &amp;lt; 0) {
        //处理错误，回调用户的error handler
    } else {
        //处理到期的timers, 回调用户的timer handler
        if（retval &amp;gt; 0）{
        //处理IO事件，回调用户的IO event handler
    }
 } 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reactor模型的优点是通过网络库来管理数据的收发，程序只关心逻辑，通过该模型能够提高用户的并发度。&lt;/p&gt;

&lt;p&gt;该模型适合IO密集的应用，但是不太适合CPU密集的应用，因为较难发挥多核的威力。一定要注意避免在事件回调中执行耗时的操作，否则会影响程序的响应。&lt;/p&gt;

&lt;p&gt;使用该方式的web服务器有很多，包括lighthttpd(reactor)，NodeJs，Nginx(每个工作进程一个reactor)，ACE, Twisted(Python), libevent/libev(事件驱动库，能够兼容不同的系统平台)。&lt;/p&gt;

&lt;h3 id=&#34;协程-coroutine&#34;&gt;协程(coroutine)&lt;/h3&gt;

&lt;p&gt;该方式与reactor模型本质上区别不大，关键在于回调上下文的保存以及执行机制。这种方式试图通过一组少量的线程来实现多个任务，旦某个任务阻塞，则可能用同一线程继续运行其他任务，避免大量上下文的切换。而且，各个协程之间的切换，往往是用户通过代码来显式指定的（跟各种 callback 类似），不需要内核参与。&lt;/p&gt;

&lt;p&gt;综合而言，相对于reactor模型， 协程的优势在于能够允许创建大量实例/连接（百万级别），且类似于同步阻塞方式。缺点与reactor类似，对于CPU密集型计算，其他协程将不能继续运行了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Erlang解决了协程密集计算的问题，它基于自行开发VM，并不执行机器码。即使存在密集计算的场景，VM发现某个协程执行时间过长，也可以进行中止切换。Golang由于是直接执行机器码的，所以无法解决此问题。所以Golang要求用户必须在密集计算的代码中，自行Yield。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;reactors-threads-pool模型&#34;&gt;Reactors + threads pool模型&lt;/h3&gt;

&lt;p&gt;对于上述的reactor模型，已经说过，会存在callback hell问题，不适用于CPU密集型的场景。自然我们会想到将CPU密集型的任务分离出来，单独用线程处理。&lt;/p&gt;

&lt;p&gt;这种方案适合既有突发IO（利用多线程处理多个连接上的IO），又有突发计算的应用（利用线程池把一个连接上的计算任务分配给多个线程去做). 示例图如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-05-19-server-concurrent-reactors.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.jobbole.com/99954/#comment-156379&#34;&gt;聊聊 C10K 问题及解决方案&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://jolestar.com/parallel-programming-model-thread-goroutine-actor/&#34;&gt;并发之痛 Thread，Goroutine，Actor&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>PHP动态脚本Opcode</title>
          <link>https://maodanp.github.io/2016/05/10/opcode/</link>
          <pubDate>Tue, 10 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/05/10/opcode/</guid>
          <description>&lt;p&gt;本篇较为深入的讲述了PHP的Opcode缓存原理。简要分析了PHP的脚本跟踪与分析技术。&lt;/p&gt;

&lt;h3 id=&#34;opcode缓存&#34;&gt;opcode缓存&lt;/h3&gt;

&lt;h4 id=&#34;解释器-v-s-编译器&#34;&gt;解释器 V.S. 编译器&lt;/h4&gt;

&lt;p&gt;如今Web开发人员在写脚本语言时都有很多的选择，PHP、Ruby、Python等，它们属于解释型语言。它们编写的动态语言都需要依赖响应的解释器来运行，那解释型语言到底与编译型语言（C/C++、JAVA等）有啥区别呢？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;解释：解释器完成对脚本代码的分析，将它们生成可以直接运行的中间代码（操作码，Operator Code, opcode）。即从程序代码到中间代码的过程。&lt;/li&gt;
&lt;li&gt;编译：编译器将程序代码生成中间代码。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面两个定义貌似是一样的。是的，原理上编译和解释是相似的，都包括词法分析、语法分析、语义分析等。但是有个本质的不同在于：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;解释器在生成中间代码后便可以直接运行它，所以运行时控制权在编译器&lt;/li&gt;
&lt;li&gt;编译器则将中间代码进一步优化，生成可以直接运行的目标程序，但不执行它，所以控制权在目标程序，与编译器就没有任何关系了&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;正是因为解释器每次运行的时候都将脚本代码作为输入源分析，所以它的数据结构能够动态的改变，这使得解释型语言具备了很多丰富的动态特性，在开发和调试中有很多优势。但是相应的，其性能比不上编译型语言。&lt;/p&gt;

&lt;h4 id=&#34;什么是opcode&#34;&gt;什么是opcode&lt;/h4&gt;

&lt;p&gt;PHP解释器的核心引擎是Zend Engine。那么对于 &lt;code&gt;1+1&lt;/code&gt;这个简单的脚本，Zend引擎生成的opcode会是什么呢？&lt;/p&gt;

&lt;p&gt;我们需要安装PHP的Parsekit扩展，来查看任何PHP文件或者代码段的opcode。直接进行如下调用：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;php  -r &amp;quot;var_dump(parsekit_compile_string(&#39;print 1+1;&#39;));&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们看主要涉及到的opcode部分：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[&amp;quot;opcodes&amp;quot;]=&amp;gt;
  array(4) {
    [0]=&amp;gt;
    array(8) {
      [&amp;quot;address&amp;quot;]=&amp;gt;
      int(107095044)
      [&amp;quot;opcode&amp;quot;]=&amp;gt;
      int(1)
      [&amp;quot;opcode_name&amp;quot;]=&amp;gt;
      string(8) &amp;quot;ZEND_ADD&amp;quot;
      [&amp;quot;flags&amp;quot;]=&amp;gt;
      int(197378)
      [&amp;quot;result&amp;quot;]=&amp;gt;
      array(3) {
        [&amp;quot;type&amp;quot;]=&amp;gt;
        int(2)
        [&amp;quot;type_name&amp;quot;]=&amp;gt;
        string(10) &amp;quot;IS_TMP_VAR&amp;quot;
        [&amp;quot;var&amp;quot;]=&amp;gt;
        int(0)
      }
      [&amp;quot;op1&amp;quot;]=&amp;gt;
      array(3) {
        [&amp;quot;type&amp;quot;]=&amp;gt;
        int(1)
        [&amp;quot;type_name&amp;quot;]=&amp;gt;
        string(8) &amp;quot;IS_CONST&amp;quot;
        [&amp;quot;constant&amp;quot;]=&amp;gt;
        &amp;amp;int(1)
      }
      [&amp;quot;op2&amp;quot;]=&amp;gt;
      array(3) {
        [&amp;quot;type&amp;quot;]=&amp;gt;
        int(1)
        [&amp;quot;type_name&amp;quot;]=&amp;gt;
        string(8) &amp;quot;IS_CONST&amp;quot;
        [&amp;quot;constant&amp;quot;]=&amp;gt;
        &amp;amp;int(1)
      }
      [&amp;quot;lineno&amp;quot;]=&amp;gt;
      int(1)
    }
    [1]=&amp;gt;
    array(7) {
      [&amp;quot;address&amp;quot;]=&amp;gt;
      int(107095164)
      [&amp;quot;opcode&amp;quot;]=&amp;gt;
      int(41)
      [&amp;quot;opcode_name&amp;quot;]=&amp;gt;
      string(10) &amp;quot;ZEND_PRINT&amp;quot;
      [&amp;quot;flags&amp;quot;]=&amp;gt;
      int(770)
      [&amp;quot;result&amp;quot;]=&amp;gt;
      array(3) {
        [&amp;quot;type&amp;quot;]=&amp;gt;
        int(2)
        [&amp;quot;type_name&amp;quot;]=&amp;gt;
        string(10) &amp;quot;IS_TMP_VAR&amp;quot;
        [&amp;quot;var&amp;quot;]=&amp;gt;
        int(1)
      }
      [&amp;quot;op1&amp;quot;]=&amp;gt;
      array(3) {
        [&amp;quot;type&amp;quot;]=&amp;gt;
        int(2)
        [&amp;quot;type_name&amp;quot;]=&amp;gt;
        string(10) &amp;quot;IS_TMP_VAR&amp;quot;
        [&amp;quot;var&amp;quot;]=&amp;gt;
        int(0)
      }
      [&amp;quot;lineno&amp;quot;]=&amp;gt;
      int(1)
    }
    [2]=&amp;gt;
    array(7) {
      [&amp;quot;address&amp;quot;]=&amp;gt;
      int(107095284)
      [&amp;quot;opcode&amp;quot;]=&amp;gt;
      int(70)
      [&amp;quot;opcode_name&amp;quot;]=&amp;gt;
      string(9) &amp;quot;ZEND_FREE&amp;quot;
      [&amp;quot;flags&amp;quot;]=&amp;gt;
      int(271104)
      [&amp;quot;op1&amp;quot;]=&amp;gt;
      array(4) {
        [&amp;quot;type&amp;quot;]=&amp;gt;
        int(2)
        [&amp;quot;type_name&amp;quot;]=&amp;gt;
        string(10) &amp;quot;IS_TMP_VAR&amp;quot;
        [&amp;quot;var&amp;quot;]=&amp;gt;
        int(1)
        [&amp;quot;EA.type&amp;quot;]=&amp;gt;
        int(0)
      }
      [&amp;quot;op2&amp;quot;]=&amp;gt;
      array(3) {
        [&amp;quot;type&amp;quot;]=&amp;gt;
        int(8)
        [&amp;quot;type_name&amp;quot;]=&amp;gt;
        string(9) &amp;quot;IS_UNUSED&amp;quot;
        [&amp;quot;opline_num&amp;quot;]=&amp;gt;
        string(1) &amp;quot;0&amp;quot;
      }
      [&amp;quot;lineno&amp;quot;]=&amp;gt;
      int(1)
    }
    [3]=&amp;gt;
    array(7) {
      [&amp;quot;address&amp;quot;]=&amp;gt;
      int(107095404)
      [&amp;quot;opcode&amp;quot;]=&amp;gt;
      int(62)
      [&amp;quot;opcode_name&amp;quot;]=&amp;gt;
      string(11) &amp;quot;ZEND_RETURN&amp;quot;
      [&amp;quot;flags&amp;quot;]=&amp;gt;
      int(16777984)
      [&amp;quot;op1&amp;quot;]=&amp;gt;
      array(3) {
        [&amp;quot;type&amp;quot;]=&amp;gt;
        int(1)
        [&amp;quot;type_name&amp;quot;]=&amp;gt;
        string(8) &amp;quot;IS_CONST&amp;quot;
        [&amp;quot;constant&amp;quot;]=&amp;gt;
        &amp;amp;NULL
      }
      [&amp;quot;extended_value&amp;quot;]=&amp;gt;
      int(0)
      [&amp;quot;lineno&amp;quot;]=&amp;gt;
      int(1)
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;似乎有些多，但是仔细观察，会发现在opcodes数组中，共有4条操作：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;opcode&lt;/th&gt;
&lt;th&gt;opcode_name&lt;/th&gt;
&lt;th&gt;op 1&lt;/th&gt;
&lt;th&gt;op 2&lt;/th&gt;
&lt;th&gt;op 3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;ZEND_ADD&lt;/td&gt;
&lt;td&gt;IS_CONST(1)&lt;/td&gt;
&lt;td&gt;IS_CONST(1)&lt;/td&gt;
&lt;td&gt;IS_TMP_VAR&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;41&lt;/td&gt;
&lt;td&gt;ZEND_PRINT&lt;/td&gt;
&lt;td&gt;IS_TMP_VAR&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;70&lt;/td&gt;
&lt;td&gt;ZEND_FREE&lt;/td&gt;
&lt;td&gt;IS_TMP_VAR&lt;/td&gt;
&lt;td&gt;IS_UNUSED&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;62&lt;/td&gt;
&lt;td&gt;ZEND_RETURN&lt;/td&gt;
&lt;td&gt;IS_CONST(NULL)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;通过上面的分析，似曾相识的感觉，仿佛和汇编代码类似。的确，Zend核心引擎正式沿用了类似汇编语言的操作码形式（三地址码）。表格中四个运算符，分别对应四种运算形式：&lt;/p&gt;

&lt;p&gt;result = op1 op op2&lt;/p&gt;

&lt;p&gt;result = op op1&lt;/p&gt;

&lt;p&gt;op1 op op2&lt;/p&gt;

&lt;p&gt;op op1&lt;/p&gt;

&lt;p&gt;三地址码生成目标容易就非常容易了。只需要将抽象的操作指令（如上面的ZEND_ADD）翻译成底层的操作指令即可。同样，解释器维护抽象层面的操作码，也是其跨平台运行的重要基础。&lt;/p&gt;

&lt;h4 id=&#34;生成opcode&#34;&gt;生成opcode&lt;/h4&gt;

&lt;p&gt;Zend引擎执行PHP脚本时，会经过如下四个步骤：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. Scanning(Lexing) ,将PHP代码转换为语言片段(Tokens)
2. Parsing, 将Tokens转换成简单而有意义的表达式
3. Compilation, 将表达式编译成Opocdes
4. Execution, 顺次执行Opcodes，每次一条，从而实现PHP脚本的功能
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一步，&lt;strong&gt;&lt;em&gt;词法分析&lt;/em&gt;&lt;/strong&gt;，解释器需要对所有单词进行分类，并给它们打上标记（token）。 我们可以在PHP源码的Zend目录中找到PHP解释器的词法分析文件，其中就有print对应的token为T_PRINT:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Zend/zend_language_scanner.l    
 &amp;lt;ST_IN_SCRIPTING&amp;gt;&amp;quot;print&amp;quot; {
    return T_PRINT;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第二步，&lt;strong&gt;&lt;em&gt;语法分析&lt;/em&gt;&lt;/strong&gt;，当词法分析通过后，将进入语法分析：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Zend/zend_language_parse.y
T_PRINT expr  { zend_do_print(&amp;amp;$$, &amp;amp;$2 TSRMLS_CC); }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;语法分析器将T_RPINT标记以及上下文替换成了&lt;code&gt;zend_do_print()&lt;/code&gt;函数&lt;/p&gt;

&lt;p&gt;第三步，&lt;strong&gt;&lt;em&gt;编译&lt;/em&gt;&lt;/strong&gt;, 下面的函数实现了到opcode的转换，它设置了&lt;code&gt;opcode&lt;/code&gt;指令以及&lt;code&gt;op1&lt;/code&gt;的数据。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void zend_do_print(znode *result, const znode *arg TSRMLS_DC) /* {{{ */
{
    zend_op *opline = get_next_op(CG(active_op_array) TSRMLS_CC);

    opline-&amp;gt;result.op_type = IS_TMP_VAR;
    opline-&amp;gt;result.u.var = get_temporary_variable(CG(active_op_array));
    opline-&amp;gt;opcode = ZEND_PRINT;
    opline-&amp;gt;op1 = *arg;
    SET_UNUSED(opline-&amp;gt;op2);
    *result = opline-&amp;gt;result;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第四步，&lt;strong&gt;&lt;em&gt;执行&lt;/em&gt;&lt;/strong&gt;， 依次执行Opcodes。&lt;/p&gt;

&lt;h4 id=&#34;避免重复编译&#34;&gt;避免重复编译&lt;/h4&gt;

&lt;p&gt;从前面的opcode生成过程看，我们基本能知道为啥要引入opcode缓存了。&lt;/p&gt;

&lt;p&gt;PHP的生命周期可以通过下图展示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-05-10-opcode-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Zend引擎必须从文件系统读取文件、扫描其词典和表达式、解析文件、创建要执行的Opcode，最后执行Opcode。&lt;/p&gt;

&lt;p&gt;每一次请求PHP脚本都会执行一遍以上步骤，如果PHP源代码没有变化，那么Opcode也不会变化，显然没有必要每次都重行生成Opcode，结合在Web中无所不在的缓存机制，我们可以把Opcode缓存下来，以后直接访问缓存的Opcode岂不是更快，启用Opcode缓存之后的流程图如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-05-10-opcode-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;有一些优秀的opcode缓存器扩展，比如PHP可以选择APC、eAccelerator、XCache等。它们都可以将opcode缓存到共享内存中，而你几乎不需要修改任何代码。&lt;/p&gt;

&lt;p&gt;下面是使用APC扩展前后的压测对比：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ab -n 1000 -c 10 http://localhost/upload/index.php\?m\=medal

Concurrency Level:      20
Time taken for tests:   43.814396 seconds
Complete requests:      1000
Failed requests:        0
Write errors:           0
Total transferred:      14933576 bytes
HTML transferred:       14387000 bytes
Requests per second:    22.82 [#/sec] (mean)
Time per request:       876.288 [ms] (mean)
Time per request:       43.814 [ms] (mean, across all concurrent requests)
Transfer rate:          332.84 [Kbytes/sec] received
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;开启opcode cache缓存后：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Concurrency Level:      10
Time taken for tests:   12.394085 seconds
Complete requests:      1000
Failed requests:        0
Write errors:           0
Total transferred:      15586000 bytes
HTML transferred:       15241000 bytes
Requests per second:    80.68 [#/sec] (mean)
Time per request:       123.941 [ms] (mean)
Time per request:       12.394 [ms] (mean, across all concurrent requests)
Transfer rate:          1228.01 [Kbytes/sec] received
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到吞吐量有一定的提升，但是感觉提升不是很大，因为并不是所有的动态内容都在应用了opcode cache之后有了大幅度的性能提升，因为opcode cache的目的是减少CPU和内存的开销，如果动态内容的性能瓶颈不在于CPU和内存，而是I/O操作，那opcode cache的提升是非常有限的。&lt;/p&gt;

&lt;h3 id=&#34;解释器扩展-脚本跟踪与分析&#34;&gt;解释器扩展——脚本跟踪与分析&lt;/h3&gt;

&lt;p&gt;动态内容在计算过程中，还有很多开销是无法通过opcode 缓存来避免的。我们也需要知道主要的时间消耗，我们有时候需要了解究竟开销来自于脚本程序本身还是其他的外部原因。&lt;/p&gt;

&lt;p&gt;Xdebug是一个PHP的PECL扩展，它提供了一组用于代码跟踪和调试的API。能够进行脚本信息上下文收集，函数栈跟踪，错误信息收集等。&lt;/p&gt;

&lt;p&gt;下图展示了PHP脚本跟踪扩展的细节：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-05-10-opcode-3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;目前对于服务器应用程序的监测（Application Performance Monitor, APM）也是很多公司在做的，比如听云、OneAPM、Mmtrix等（笔者之前参与过关于PHP的探针研发）。相对于开源的Xdebug跟踪，这些产品化的APM有自身的优势：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;全面的监控数据&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PHP监测能够对脚本运行中的各项性能数据进行智能采集、多维度分析。从服务器本身的系统资源（CPU、内存、网络IO等），到PHP运行中的数据收集（函数堆栈、数据库、错误、异常、外部服务等），都能给出全面的监测结果。给用户提供每项性能数据。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;定制化的监测需求&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除了全面的监测功能（函数调用堆栈、错误异常监控、系统资源监控）。PHP监测根据用户自身需求，提供了对应的配置文件，用户可以根据自身应用特点及需求，定制化性能数据的上报、告警。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;完善的告警机制&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;告警是监测中相当重要的环节。PHP监测提供较为完善的告警机制（自定义告警策略、多样化告警渠道等），用户能够及时根据告警信息，定位问题。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/21aspnet/article/details/7035667&#34;&gt;PHP安装parsekit扩展查看opcode&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.laruence.com/2008/06/18/221.html&#34;&gt;深入理解PHP原理之Opcodes&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.linuxeye.com/361.html&#34;&gt;深入理解PHP Opcode缓存原理&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;《构建高性能web站点》 Ch5 动态脚本加速&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>I/O多路复用</title>
          <link>https://maodanp.github.io/2016/05/05/io-multiplexing/</link>
          <pubDate>Thu, 05 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/05/05/io-multiplexing/</guid>
          <description>&lt;p&gt;I/O多路复用是常用的服务器I/O模型，包括select/poll/epoll等方式。本篇针对这几种方式的优缺点分别做讲解。&lt;/p&gt;

&lt;p&gt;在&lt;a href=&#34;https://maodanp.github.io/2016/05/01/io-model&#34;&gt;上一篇文章&lt;/a&gt;中介绍了I/O的几种网络模型，并且提到了多路I/O复用方案，它提供了对大量文件描述符就绪检查的高性能方案，允许进程通过一 种方法来同时监听所有fd，并且快速获得所有就绪的fd，然后只针对这些fd进行数据访问。&lt;/p&gt;

&lt;p&gt;I/O多路复用技术适用如下场合：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;当客户端处理多个描述符，必须适用适用I/O复用&lt;/li&gt;
&lt;li&gt;TCP服务器既要处理监听套接字，又要处理已连接套接字，一般也要用到I/O复用&lt;/li&gt;
&lt;li&gt;服务器要处理多个服务或协议，一般也要用到I/O复用&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;目前支持I/O多路复用的系统调用者有select, pselect, poll, epoll。 这些系统调用本质上是同步I/O，它们都需要在读写事件就绪后用户自己负责进行读写。&lt;/p&gt;

&lt;h3 id=&#34;select&#34;&gt;select&lt;/h3&gt;

&lt;p&gt;它通过一个select()系统调用来监视包含多个fd的数据，当select()返回后，该数组中就绪的fd便会被北河修改标志位，使得进程可以获得这些fd从而进行后续的读写操作。唯一的优点就是良好的跨平台性，能够支持几乎所有的平台。&lt;/p&gt;

&lt;p&gt;但是缺点也非常的明显：
* 单个进程能够监听的fd数量存在最大限制（Linux上一般为1024, 可以通过宏定义甚至编译内核方式提升这一限制，但会造成效率降低）
* 调用select()会对所有socket进行一次线性扫描，浪费了一定的开销
* 需要维护一个用来存放大量fd的数据结构，随着fd数量的增大，用户空间和内核空间的相互拷贝的开销也在增长&lt;/p&gt;

&lt;h3 id=&#34;poll&#34;&gt;poll&lt;/h3&gt;

&lt;p&gt;poll和select在本质上差别不大，但是poll是基于链表来存储的，没有最大fd的数量限制。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;它和select类似，存在缺点：大量fd数组被整体复制于用户态和内核的地址空间之间，不论socket是否处于活跃还是非活跃，大多是没有意义的socket复制。另外select()和epoll()都是“水平触发（Level Triggered）”的方式，如果就绪的fd告诉用户进程，但没有被处理，则下次还会继续报告该fd。&lt;/p&gt;

&lt;h3 id=&#34;epoll&#34;&gt;epoll&lt;/h3&gt;

&lt;p&gt;epoll直到Linux2.6才由内核实现的方法，它相对于select和epoll来说，更加灵活，没有描述符的限制。epoll将用户关系的fd事件(EPOLLIN, EPOLLOUT)存放在内核的一个事件表中，这样在用户空间和内核空间的拷贝只需要一次。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;epoll支持水平和边缘触发，它会通知进程哪些fd刚刚变为就绪状态，但仅仅通知一次。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;理论上边缘触发的性能要更高些，但是用户层的代码需要一次性循环读完，不然会存在漏读问题。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;epoll使用“事件”的就绪通知方式，通过epoll_ctl()注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait()便可以收到通知；&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里epoll_wait()返回的是代表就绪fd数量的值，我们只需要去epoll指定的一个数组中一次取得相应数量的fd即可。&lt;/p&gt;

&lt;p&gt;epoll相对于select、epoll的优点较为明显：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;没有最大并发连接数的限制&lt;/li&gt;
&lt;li&gt;它只管“活跃”的连接，而跟连接总数无关（注意：如果没有大量空闲连接或死连接，epoll效率并不会比select/poll高很多，但是实际网络环境中，效率远高于select和poll）&lt;/li&gt;
&lt;li&gt;内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递，较少复制拷贝&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;epoll对fd的操作有两种模式：LT(level trigger)和ET(edge trigger)，默认使用的是LT模式。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;LT模式&lt;/code&gt;： 当fd就绪时，应用程序如果不立即处理时间，下次在epoll_wait返回时，会再次将该fd通知给应用程序，select也属于该类，长期关注socket读写事件，会出现CPU的忙循环（busy loop）问题。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ET模式&lt;/code&gt;： 内核在描述符就绪的时候只会通知进程一次，如果不处理，下次调用epoll_wait时，将不会通知该事件。也就是说，如果采用该模式，需要一直read/write直到errno变为EAGAIN(或EWOULDBLOCK)。epoll工作在ET时必须使用非阻塞套接字，以避免由于一个fd的阻塞读写影响对其他fd操作。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;由于存在自身的特点，所以在选择select、poll、epoll时要根据具体使用场合：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;总的而言epoll的性能最好，但是在连接数少且连接都十分活跃的情况下， select和poll的性能不一定比epoll差，epoll内部有自己的事件通知机制&lt;/li&gt;
&lt;li&gt;由于select是跨平台的系统调用，如果考虑到应用程序的跨平台性，以及连接数的实际情况，也是一种选择方式。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;《 构建高性能web站点 》 Ch3 服务器并发处理能力&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>程序猿的自我修养 — coding</title>
          <link>https://maodanp.github.io/2016/05/03/coding/</link>
          <pubDate>Tue, 03 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/05/03/coding/</guid>
          <description>&lt;p&gt;工作三年多，记录下自己对写代码的一些认识。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-05-03-coding.jpg&#34; alt=&#34;标题图片&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;技术积累阶段&#34;&gt;技术积累阶段&lt;/h3&gt;

&lt;p&gt;离开校园，从事软件行业，就意味着在代码的道路上要不断升级打怪，不断提高自我了。开始可能从项目的增加功能开始，或者做个轻量型的产品/demo。多数情况下，公司的产品已经趋于成熟稳定，代码稳定，所以写起来难度不是，按照已有的风格方式去写就OK。&lt;/p&gt;

&lt;p&gt;这个阶段主要是在于学习。当然不光是代码的学习，包括很多其他方面：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;系统： 如果是Linux， 那么需要了解Linux，掌握常用命令，一些提高工作效率的个性化配置，工具&lt;/li&gt;
&lt;li&gt;语言： C/Java/Go/Swift等等&lt;/li&gt;
&lt;li&gt;代码管理：svn/git&lt;/li&gt;
&lt;li&gt;配置管理：puppet/salt/ansible&lt;/li&gt;
&lt;li&gt;&amp;hellip;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当然，不光是技术，还包括其他软实力的提高：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;沟通： 对于稍大的项目，总是需要多人合作开发，良好、有效的沟通是非常重要的一步&lt;/li&gt;
&lt;li&gt;问题解决能力：这个需要长期的实践才能提高的，实践是检验真理的唯一标准嘛&lt;/li&gt;
&lt;li&gt;好奇心：对技术要有足够的好奇心，将持续学习当做一种人生的态度，这样才能有持续的学习动力&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;技术提高阶段&#34;&gt;技术提高阶段&lt;/h3&gt;

&lt;p&gt;这个阶段对产品的业务逻辑有了清晰的认识，各方面都能够适应了。毕竟产品注重的是业务逻辑，对技术的运用是有限的，可能不需要考虑到大并发、高性能（当然跟具体业务有关）。这个时候就需要有所专研了，找到自己感兴趣的领域去深入&lt;/p&gt;

&lt;p&gt;比如后端的专研方向大致有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;网络方向 (网络优化、加速)&lt;/li&gt;
&lt;li&gt;消息中间件 (mq, jms)&lt;/li&gt;
&lt;li&gt;分布式方向（缓存、 数据库、 分锁）&lt;/li&gt;
&lt;li&gt;大数据方向（hadoop、 openstack）&lt;/li&gt;
&lt;li&gt;负载均衡方向（apache、 nginx）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;技术的提高不光是靠看书，也需要经过实践的。 可以自己动手开发个demo，托管在github上，说不定就会备受关注，做成个成熟的开源产品呢。&lt;/p&gt;

&lt;h3 id=&#34;全栈阶段&#34;&gt;全栈阶段&lt;/h3&gt;

&lt;p&gt;全栈工程师是：“掌握多种技能，病能利用多种技能独立完成产品的人”（baidu定义）。这个阶段应该不是局限在代码本身了吧，更多的是在项目架构设计、项目技术选择、项目整体进度调控等等。（此阶段离本程序汪还很是遥远， 需要继续奋斗）&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>服务器的I/O模型</title>
          <link>https://maodanp.github.io/2016/05/01/io-model/</link>
          <pubDate>Sun, 01 May 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/05/01/io-model/</guid>
          <description>&lt;p&gt;I/O模型的设计是后台服务能否支持高并发的至关因素。好的服务器性能必然需要良好的IO模型作为支撑。本篇重新复习下服务器常用的IO模型。&lt;/p&gt;

&lt;p&gt;I/O操作根据设备的不同分为很多种，如内存I/O、网络I/O、磁盘I/O等。相对于后两种I/O操作，内存I/O速度已经足够快了。尽管可以用多进程等方式来充分利用空闲的CPU资源，但CPU资源毕竟有限，而且在遇到高并发情况时，CPU调度、服务器资源数将成为很大的限制。&lt;/p&gt;

&lt;p&gt;我们希望花让CPU花费足够少的时间在I/O的调度上，而是花在对I/O的操作处理上。如何让高速的CPU和慢速的I/O设备更好的协调工作，也是现代计算机处理高并发、高可用的一个持续的技术话题。&lt;/p&gt;

&lt;p&gt;网络IO的本质是socket的流操作，当一个read操作发生时，实际需要经历两个阶段：
1. 等待数据就绪/准备（等待网络上的数据分组到达，然后被复制到内核的某个缓冲区）
2. 将数据从内核拷贝到用户进程空间（将数据从内核缓冲区复制到用户进程缓冲区）&lt;/p&gt;

&lt;p&gt;由于网络I/O存在上述两个阶段的时间等待，所以网络I/O的延时将是影响服务器性能的主要瓶颈。好的I/O模型也是至关重要的。 网络I/O模型大致分为以下几种：
* 同步阻塞I/O
* 同步非阻塞IO/
* 多路复用I/O
* 信号驱动式I/O
* 异步I/O&lt;/p&gt;

&lt;h3 id=&#34;同步阻塞i-o&#34;&gt;同步阻塞I/O&lt;/h3&gt;

&lt;p&gt;同步阻塞I/O是指当进程调用某些涉及IO操作的系统调用或库函数时，进程暂停，等待IO操作完成再继续运行。在调用recv()/recvfrom()这个系统调用，发生在内核中等待数据和复制数据过程如下：
&lt;img src=&#34;../../../../pic/2016/2016-05-01-io-model-block.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从上图看出，进程在I/O的两个阶段都被阻塞了。阻塞I/O在简单环境下较适用，如果没有其他事需要同时进行处理，阻塞I/O也不错。但是，如果存在多个连接的情况，则会引发问题。代码片段如下示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;char buf[1024];
int i, n;
while (i_still_want_to_read()) {
    for (i=0; i&amp;lt;n_sockets; ++i) {
        n = recv(fd[i], buf, sizeof(buf), 0);
        if (n==0)
            handle_close(fd[i]);
        else if (n&amp;lt;0)
            handle_error(fd[i], errno);
        else
            handle_input(fd[i], buf, n);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;即使fd[2]上最先有数据达到，对fd[0]和fd[1]的读取操作取得一些数据并且完成之前，程序不会试图从fd[2]进行读取。这就引起了累计的时延，影响整体的接收速度。&lt;/p&gt;

&lt;p&gt;有时会用多进程或者多线程解决多个连接的问题。就是每个连接拥有独立的进程或者线程，这样一个连接上的I/O阻塞并不会影响其他任务连接的进程或线程。代码片段如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void child(int fd)
{
    char outbuf[MAX_LINE+1];
    size_t outbuf_used = 0;
    ssize_t result;

    while (1) {
        result = recv(fd, outbuf,MAX_LINE, 0);
        if (result == 0) {
            break;
        } else if (result == -1) {
            perror(&amp;quot;read&amp;quot;);
            break;
        }
    }
    //use outbuf todo something
}

void run(void)
{
    //do something init socket
    while (1) {
        struct sockaddr_storage ss;
        socklen_t slen = sizeof(ss);
        int fd = accept(listener, (struct sockaddr*)&amp;amp;ss, &amp;amp;slen);
        if (fd &amp;lt; 0) {
            perror(&amp;quot;accept&amp;quot;);
        } else {
            if (fork() == 0) {
                child(fd);
                exit(0);
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为每个连接创建一个进程或者线程是否可行呢？ 如果作为服务器，连接数达到成千上万个，如此多的进程或者线程并不是明智的选择。&lt;/p&gt;

&lt;h3 id=&#34;同步非阻塞i-o&#34;&gt;同步非阻塞I/O&lt;/h3&gt;

&lt;p&gt;同步非阻塞I/O的调用不会等待数据的就绪，如果数据不可读或可写，它会立即告诉进程。此时，read操作可能会返回一个错误代码，说明这个命令不能立即满足（EAGIN或EWOULDBLOCK）。流程如图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-05-01-io-model-noblock.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;与阻塞I/O不一样，”非阻塞将大的整片时间的阻塞分成N多个小阻塞，所以进程不断地被CPU调度“，该模式会消耗CPU, 且需要对每个连接描述符fd进行内核调用，不论连接上是否有数据。由于该模式会消耗大量CPU，所以极少情况使用。代码片段如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;while (i_still_want_to_read()) {
    for (i=0; i &amp;lt; n_sockets; ++i) {
        n = recv(fd[i], buf, sizeof(buf), 0);
        if (n == 0) {
            handle_close(fd[i]);
        } else if (n &amp;lt; 0) {
            if (errno == EAGAIN)
                 ; /* The kernel didn&#39;t have any data for us to read. */
            else
                 handle_error(fd[i], errno);
         } else {
            handle_input(fd[i], buf, n);
         }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;多路复用-i-o-multiplexing&#34;&gt;多路复用(I/O multiplexing)&lt;/h3&gt;

&lt;p&gt;多路复用I/O，就是我们常说的select/poll/epoll， 它提供了对大量文件描述法就绪检查的高性能方案，它允许进程通过一种方法来同时监视所有文件描述符，并可以快速获得所有就绪的文件描述符，然后只针对这些文件描述符进行访问。&lt;strong&gt;优势就是同时可以监听多个fd。&lt;/strong&gt; 流程如图所示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-05-01-io-model-io-multiplexing.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当得知数据就绪后，就访问数据本身而言，仍然需要选择阻塞或非阻塞的访问方式（一般我们选择非阻塞方式，以防止任何意外的等待阻塞整个进程）。代码片段如下所示：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;while (i_still_want_to_read()) {
    int maxfd = -1;
    FD_ZERO(&amp;amp;readset);
    for (i=0; i &amp;lt; n_sockets; ++i) {
         if (fd[i]&amp;gt;maxfd) maxfd = fd[i];
         FD_SET(fd[i], &amp;amp;readset);
    }

    select(maxfd+1, &amp;amp;readset, NULL, NULL, NULL);   //这里阻塞

    for (i=0; i &amp;lt; n_sockets; ++i) {
        if (FD_ISSET(fd[i], &amp;amp;readset)) {
            n = recv(fd[i], buf, sizeof(buf), 0);
            if (n == 0) {
                //对端关闭套接字
                handle_close(fd[i]);
            } else if (n &amp;lt; 0) {
                //数据传输完，内核没数据了
                if (errno == EAGAIN)
                     ; /* The kernel didn&#39;t have any data for us to read. */
                else
                     handle_error(fd[i], errno);
             } else {
                handle_input(fd[i], buf, n);
             }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;在整个用户的进程中，进程是被select阻塞的，没有阻塞在真正的I/O系统调用（如recv/recvfrom）之上。从整个I/O执行过程来看，他们都是顺序执行的，因此可以归为同步模型（synchronous）,都是进程主动等待内核状态。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;信号驱动式i-o&#34;&gt;信号驱动式I/O&lt;/h3&gt;

&lt;p&gt;我们也可以用信号，让内核在描述符就绪时发送SIGIO信号通知我们，该模型即为信号驱动式I/O。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-05-01-io-model-signal.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这种模型的优势在于等待数据报到达期间进程不被阻塞。主循环可以继续执行。只要等待来自信号处理函数的通知。&lt;/p&gt;

&lt;h3 id=&#34;异步i-o&#34;&gt;异步I/O&lt;/h3&gt;

&lt;p&gt;异步I/O模型，该模型工作机制是：告知内核启动某个操作，并让在整个操作（包括将数据从内核复制到我们自己的缓冲区）完成后通知我们。I/O的两个阶段，进程都是非阻塞的。&lt;/p&gt;

&lt;p&gt;Linux提供了AIO库函数实现异步，但基本都是用开源的异步IO库，如libevent、libv、libuv。&lt;/p&gt;

&lt;p&gt;从内核的角度看，当它接收到一个异步read之后，首先它会立即，对用户进程不会造成阻塞。然后内核会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，内核会给用户进程发送一个signal或执行一个基于线程的回调函数来完成这次IO处理过程。&lt;/p&gt;

&lt;h3 id=&#34;五种i-o模型&#34;&gt;五种I/O模型&lt;/h3&gt;

&lt;p&gt;同步I/O做I/O操作时将进程阻塞。 之前的阻塞I/O、非阻塞I/O、I/O复用、信号驱动I/O 都属于同步I/O(这里定义的I/O操作就是例子中recvfrom这个系统调用)。异步I/O则不一样，进程发起I/O操作后，就直接返回，直到内核发送一个信号，告诉进程说I/O完成。下图给出各种I/O的比较：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-05-01-io-model-summarize.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;对于同步IO，都需要进程主动的调用 recvfrom来将数据拷贝到用户内存。而异步 I/O则完全不同。它就像是用户进程将整个IO操作交给了内核（kernel）完成，然后内核做完后发信号通知用户进程。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cppblog.com/mysileng/archive/2013/02/04/197715.html&#34;&gt;异步I/O简介&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;《 UNIX网络编程卷1 》：6.2节 I/O模型&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Golang — 面向对象语言(方法、接口、匿名组合)</title>
          <link>https://maodanp.github.io/2016/04/30/golang-interface/</link>
          <pubDate>Sat, 30 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/04/30/golang-interface/</guid>
          <description>&lt;p&gt;初学Golang时，一直困惑其中的&lt;code&gt;struct类型&lt;/code&gt;是否等同于面向对象中的object, &lt;code&gt;interface&lt;/code&gt;是否等同于多态。下面来好好扒一扒Golang与面向对象的关系。&lt;/p&gt;

&lt;h3 id=&#34;go中的对象&#34;&gt;Go中的对象&lt;/h3&gt;

&lt;p&gt;在面向对象的编程中，封装、继承、多态是主要的三大要素，表示对象本身的状态、行为；不同对象之间的相互关系等。Steve Francia对面向对象做了一个标准的定义：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;面向对象系统将数据和代码通过“对象”集成到一起，而不是将程序看成由分离的数据和代码组成。对象是数据类型的抽象，它有状态（数据）和行为（代码）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;那在Go语言中，并不像C++/Java那样通过class定义类对象及其方法，Go中实际并没有对象，但是Go中的结构体类型/struct有着跟object相同的特性。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;struct是一种包含了命名字段和方法的类型&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Go语言有意得被设计为没有继承语法。但这并不意味go中的对象（struct value)之间没有关系，只不过go的作者选择了另外一种机制来暗含这种特性。Go语言严格遵循着 &lt;a href=&#34;https://en.wikipedia.org/wiki/Composition_over_inheritance&#34;&gt;组合优于继承的原则&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;go通过在struct和interface上使用组合和多态来实现继承关系， 通过struct实现 has-a 关系； 通过interface实现 is-a 关系。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;方法&#34;&gt;方法&lt;/h3&gt;

&lt;p&gt;Go 语言中同时有函数和方法。一个方法就是一个包含了&lt;strong&gt;接受者(类型对象)&lt;/strong&gt;的函数，接受者可以是命名类型或者结构体类型的一个值或者是一个指针。也就是说我们可以给任意类型(包括内置类型，但不包括指针类型)添加相应的方法。&lt;/p&gt;

&lt;p&gt;下面简单给出示例说明：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import ”fmt“
type User struct {
    Name  string
    Email string
    age   int
}

//User(值) 的Notify()方法
func (u User) Notify() error {
    u.age += 1
    return nil
}

//User(指针) 的NotifyPtr()方法
func (u *User) NotifyPtr() error {
    u.age += 1
    return nil
}

func main() {

    // User 类型的值可以调用接受者是值的方法
    damon := User{&amp;quot;AriesDevil&amp;quot;, &amp;quot;ariesdevil@xxoo.com&amp;quot;, 20}
    damon.Notify()
    fmt.Printf(&amp;quot;client.do info:%v\n&amp;quot;, damon)
    // User 类型的值可以调用接受者是指针的方法
    damon.NotifyPtr()
    fmt.Printf(&amp;quot;client.do info:%v\n&amp;quot;, damon)

    // User 类型的指针同样可以调用接受者是值的方法
    alimon := &amp;amp;User{&amp;quot;A-limon&amp;quot;, &amp;quot;alimon@ooxx.com&amp;quot;, 20}
    alimon.Notify()
    fmt.Printf(&amp;quot;client.do info:%v\n&amp;quot;, alimon)
    //User 类型的指针同样可以调用接受者是指针的方法
    alimon.NotifyPtr()
    fmt.Printf(&amp;quot;client.do info:%v\n&amp;quot;, alimon)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;当接受者命名为一个值时，原来的对象的成员都没有变（age=20）&lt;/li&gt;
&lt;li&gt;当接受者命名为一个指针时，原来的对象成员发生了变化（age=21）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;当接受者不是一个&lt;code&gt;指针&lt;/code&gt;而是&lt;code&gt;值&lt;/code&gt;时，该方法操作对应接受者的值的副本（即使使用了指针调用函数，但是函数的接受者是值类型，所以函数内部操作还是对副本的操作）。&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;接口&#34;&gt;接口&lt;/h3&gt;

&lt;p&gt;Go语言中的接口很特别，而且提供了难以置信的一系列灵活性和抽象性。接口(interface)是一组抽象方法的集合，如果实现了interface中的所有方法，即该对象就实现了该接口。在Go语言中，只要两个接口有相同的方法列表，那么就可以互相赋值，而不需要知道继承于哪里。&lt;/p&gt;

&lt;p&gt;当一个接口只包含一个方法时，按照Go语言的约定命名该接口时添加 -er 后缀。这个约定很有用，特别是接口和方法具有相同名字和意义的时候(在 Go 语言标准库中，一个接口基本包含一种方法)。&lt;/p&gt;

&lt;p&gt;下面简单给出示例说明：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main
import &amp;quot;fmt&amp;quot;
type User struct {
    Name  string
    Email string
    age   int
}

//定义了一个 Notifier 接口并包含一个 Notify 方法
type Notifier interface {
    Notify() error
}

//定义函数接受任意一个实现了接口 Notifier 的类型的值或者指针
func SendNotification(notify Notifier) error {
    return notify.Notify()
}

func (u *User) Notify() error {
    log.Printf(&amp;quot;User: Sending User Email To %s&amp;lt;%s&amp;gt;\n&amp;quot;,
        u.Name,
        u.Email)
    return nil
}

func main() {
    user := User{
        Name:  &amp;quot;AriesDevil&amp;quot;,
        Email: &amp;quot;ariesdevil@xxoo.com&amp;quot;,
    }

    SendNotification(user)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果如下：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;cannot use user (type User) as type Notifier in argument to SendNotification:&lt;/code&gt;
    &lt;code&gt;User does not implement Notifier (Notify method has pointer receiver)&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上面运行说：User类型没有实现Notifier接口，但是User指针类型接受者实现了Notifier接口。 如果将上述的接受者改为值类型，就正常运行了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (u User) Notify() error {
    log.Printf(&amp;quot;User: Sending User Email To %s&amp;lt;%s&amp;gt;\n&amp;quot;,
        u.Name,
        u.Email)
    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;或者只需要传入 User 值的地址到 SendNotification 函数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;user := &amp;amp;User{
        Name:  &amp;quot;AriesDevil&amp;quot;,
        Email: &amp;quot;ariesdevil@xxoo.com&amp;quot;,
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;接口的调用规则不同于方法的调用， 接口的调用规则需要建立在这些方法的接受者和接口如何被调用的基础上。&lt;/strong&gt; 下面是Go语言规范中定义的规则：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;类型 T 的可调用方法集不包含接受者为 *T 的方法&lt;/p&gt;

&lt;p&gt;即我们传入 SendNotification 函数的接口变量一个值类型的话，那 Notify() 方法的接受者必须是值类型的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;类型 *T 的可调用方法集包含接受者为 *T 或 T 的所有方法集&lt;/p&gt;

&lt;p&gt;即我们传入 SendNotification 函数的接口变量一个指针类型的话，那 Notify() 方法的接受者可以是值类型也可以是指针类型。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;匿名域-匿名组合&#34;&gt;匿名域/匿名组合&lt;/h3&gt;

&lt;p&gt;结构体类型可以包含匿名或者嵌入字段(嵌入类型的名字充当了匿名组合的字段名)。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Admin struct {
  User
  Level  string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Effective Go中有关于嵌入类型的规则描述：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;当我们嵌入一个类型，这个类型的方法就变成了外部类型的方法；但是当它被调用时，方法的接受者是内部类型(嵌入类型)，而非外部类型。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下面的例子中，Admin和匿名组合User同时实现了Notifier接口，那么编译器该确定使用哪个接口？如下&lt;a href=&#34;https://play.golang.org/p/8V4yo97AxN&#34;&gt;完整代码&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {

    a := &amp;amp;Admin{
        User: User{
            Name:  &amp;quot;admin&amp;quot;,
            Email: &amp;quot;ariesdevil@xxoo.com&amp;quot;,
        },
        Level: &amp;quot;master&amp;quot;,
    }

    //Sending User Email To AriesDevil&amp;lt;ariesdevil@xxoo.com&amp;gt;
    a.User.Notify()

    //Sending Admin Email To AriesDevil&amp;lt;ariesdevil@xxoo.com&amp;gt;
    a.Notify()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上述代码中可以看出，如果Admin类型的接口实现的输出，User 类型的接口实现不被提升到外部类型了。&lt;/p&gt;

&lt;p&gt;对于Go语言中外部类型方法集提升的规则：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;如果 S 包含一个匿名字段 T，S 和 *S 的方法集都包含接受者为 T 的方法提升&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;对于 *S 类型的方法集包含接受者为 *T&lt;/p&gt;

&lt;p&gt;当外部类型使用指针调用内部类型的方法时，只有接受者为指针类型的内部类型方法集将被提升&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果S包含一个匿名字段 *T，S 和 *S 的方法集都包含接受者为 T 或者 *T 的方法提升&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果 S 包含一个匿名字段 T，S 的方法集不包含接受者为 *T 的方法提升&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;go中的多态实现&#34;&gt;Go中的多态实现&lt;/h3&gt;

&lt;p&gt;真正意义上，如果匿名域能实现多态，则外层独享应该等同于嵌入的对象，而实际上并非如此，他们仍然是不同的存在：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

type A struct{
}

type B struct {
    A  //B is-a A
}

func save(A) {
    //do something
}

func main() {
    b := B
    save(&amp;amp;b);  //OOOPS! b IS NOT A
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多态是一种is-a的关系。在go语言中，每种类型(type)都是不同的，一种类型不能完全等同于另外一种类型，但它们可以绑定到同一个接口（interface）上。接口能用于函数（方法）的输入输出中，因而可以在类型之间建立起is-a的关系。 &lt;a href=&#34;https://play.golang.org/p/Iw0g_OO0nj&#34;&gt;完整代码&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func SendNotification(notify Notifier) error {
    return notify.Notify()
}

func main() {
    u := &amp;amp;User{
            Name:  &amp;quot;user&amp;quot;,
            Email: &amp;quot;user@xxoo.com&amp;quot;,
        }

    a := &amp;amp;Admin{
        User: User{
            Name:  &amp;quot;admin&amp;quot;,
            Email: &amp;quot;admin@xxoo.com&amp;quot;,
        },
        Level: &amp;quot;master&amp;quot;,
    }

    //Sending User Email To AriesDevil&amp;lt;ariesdevil@xxoo.com&amp;gt;
    SendNotification(u)

    //Sending Admin Email To AriesDevil&amp;lt;ariesdevil@xxoo.com&amp;gt;
    SendNotification(a)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://studygolang.com/articles/4390&#34;&gt;Go是面向对象语言吗？&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.goinggo.net/2014/05/methods-interfaces-and-embedded-types.html&#34;&gt;Methods, Interfaces and Embedded Types in Go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.jb51.net/article/56812.htm&#34;&gt;Go语言中的方法、接口和嵌入类型详解&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>golang中域名解析问题</title>
          <link>https://maodanp.github.io/2016/04/28/golang-resolve/</link>
          <pubDate>Thu, 28 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/04/28/golang-resolve/</guid>
          <description>&lt;p&gt;在近期的Golang项目中遇到过类似这样的报错信息：&lt;code&gt;lookup www.baidu.com on 10.10.100.1:53 no such host&lt;/code&gt;. 本篇就来说说golang中域名解析遇到的问题。&lt;/p&gt;

&lt;p&gt;其中，&lt;code&gt;10.10.100.1&lt;/code&gt;为公司内部的bind域名解析服务器。这个可是我编译上线版本，出这种问题我着实捏把汗。 这部分代码没改动，那肯定是golang的问题，早前同事遇到过类似问题，说Golang的1.4版本就没有这个问题。的确我用的是1.5版本的Go，于是立即用1.4编译后重新上线。&lt;/p&gt;

&lt;h3 id=&#34;两种解析方式&#34;&gt;两种解析方式&lt;/h3&gt;

&lt;p&gt;网上说Go在1.5版本中使用两种解析方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;纯Go语言实现的域名解析，从/etc/resolve.conf中取出本地dns地址列表，然后发送DNS请求并获得结果；&lt;/li&gt;
&lt;li&gt;使用cgo方式，最终会调用到c标准库的getaddrinfo或getnameinfo&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为何采用两种方式？ 因为Go在1.4与1.5的默认调用方式是不一样的，1.4版本中默认使用的是cgo的方式解析，在1.5版本中默认使用纯Go的域名解析。如果使用cgo的方式，则对于一个协程调用cgo的getAddrInfo方法，会阻塞一个系统线程；而GO得域名解析，只会消耗一个协程。所以在1.5以后版本中默认使用纯Go的解析。&lt;/p&gt;

&lt;p&gt;Go的net包中有这么一段注释（src/net/net.go）：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Limit the number of concurrent cgo-using goroutines, because each will block an entire operating system thread. The usual culprit is resolving many DNS names in separate goroutines but the DNS server is not responding. Then the many lookups each use a different thread, and the system or the program runs out of threads.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;大致意思就是上面讲的一样。&lt;/p&gt;

&lt;p&gt;那么问题来了，为啥使用Go的解析方式反而报错？暂时没有办法，只能看Go的相关代码了。&lt;/p&gt;

&lt;h3 id=&#34;纯go的域名解析方式&#34;&gt;纯Go的域名解析方式&lt;/h3&gt;

&lt;p&gt;在业务代码中，调用的是 &lt;code&gt;lookupHost()&lt;/code&gt; 函数，逐步跟踪，会调用到后续的&lt;code&gt;tryOneName()&lt;/code&gt;。下面简要描述该函数的信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tryOneName(conf, fqdn, qtype)    //对所需解析的域名，依次使用 /etc/resolve.conf 中的DNS IP解析                   
|---exchange(server, name, qtype, timeout)  //DNS请求(建立连接、dns报文格式封装、发送dns请求、获取请求)
    |---writeDNSQuery                               
    |---readDNSQuery
|---answer(name, server, msg, qtype)    //解析获取到dns信息，解析出CNAME/A记录
|---判断是否符合条件
    if err == nil || msg.rcode == dnsRcodeSuccess || msg.rcode == dnsRcodeNameError &amp;amp;&amp;amp; msg.recursion_available {
        return cname, rrs, err
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Go的域名解析就是通过读取&lt;code&gt;/etc/resolve.conf&lt;/code&gt;的dns server, 然后通过DNS的解析流程，依次获取记录，如果首个dns server返回失败，则选第二个dns server，依次进行。 如果首个dns server解析成功了（dnsRcodeSuccess），则解析就算成功。&lt;/p&gt;

&lt;p&gt;线上环境的 &lt;code&gt;/etc/resolve.conf&lt;/code&gt; 为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10.10.100.11
8.8.8.8 
114.114.114.114
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;code&gt;tryOneName()&lt;/code&gt;中加打印信息，确实能在内部dns server中返回成功。&lt;/p&gt;

&lt;p&gt;那么问题来了，是内网的dns server出问题了？ 但是内网大家用的都是正常的啊。问题在哪里呢？&lt;/p&gt;

&lt;h3 id=&#34;bind域名解析器&#34;&gt;Bind域名解析器&lt;/h3&gt;

&lt;p&gt;内网的dns解析使用的bind，为了模拟线上的Bind，我也装了一个dns服务，且配置与内网的相同。&lt;code&gt;options&lt;/code&gt;部分如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;options {
     allow-query { any; };
     allow-query-cache { any; };
     recursion yes;
     allow-recursion { none; };
     version &amp;quot;gaint-d1&amp;quot;;
 }   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;内网配置很纳闷。既然允许递归，但是允许递归的白名单(allow-recursion为none),实际上还是不允许递归的。关键就在&lt;code&gt;allow-query-cache&lt;/code&gt;这个字段了。如果关闭(设置为none)或者不设置这个字段，Go解析尽然正常了；否则上述方式，Go解析不到主机。&lt;/p&gt;

&lt;p&gt;开启&lt;code&gt;allow-query-cache&lt;/code&gt;， dig了一下，发现返回的错误码是NOERROR，且返回一串root dns server的信息； 而关闭该字段，则返回REFUSE. 这就是关键了，该字段是起缓存作用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-04-28-golang-resolve-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;开启&lt;code&gt;allow-query-cache&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-04-28-golang-resolve-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;不开启&lt;code&gt;allow-query-cache&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如果缓存中没有所需查询的域名记录信息，则会将root dns server的信息返回（相当于告诉你，去rootserver查询吧）；否则表示没查到，返回查询失败&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;解决方案&#34;&gt;解决方案&lt;/h3&gt;

&lt;p&gt;问题是找到了，那基于目前的怎么解决呢？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;修改内网的bind配置，去掉 &lt;code&gt;allow-query-cache&lt;/code&gt; （这个运维负责人表示不干，万一影响其他服务的域名解析呢？）&lt;/li&gt;
&lt;li&gt;回退Go的版本，线上一律使用1.4版本（这个不就体验不到1.5以上的版本性能了么）&lt;/li&gt;
&lt;li&gt;仍然使用1.5版本编译，在编译之前添加： &lt;code&gt;export GODEBUG=netdns=cgo&lt;/code&gt; (目前折中方案就是这条了)&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
      
    
      
        <item>
          <title>apache配置与性能</title>
          <link>https://maodanp.github.io/2016/04/25/apache-conf/</link>
          <pubDate>Mon, 25 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/04/25/apache-conf/</guid>
          <description>&lt;p&gt;本篇将通过apache的配置项，结合实际应用，直观感受这些配置参数对吞吐量的影响。&lt;/p&gt;

&lt;h3 id=&#34;系统调用&#34;&gt;系统调用&lt;/h3&gt;

&lt;p&gt;进程有两种运行模式：用户态和内核态，进程在这两种模式中切换就需要一定的开销。 进程通常运行在用户态，可以利用内存和CPU完成一些任务；而当进程需要对硬件外设进行操作时，就需要切换到内核态；等内核态任务完成后再切换回用户态。&lt;/p&gt;

&lt;p&gt;为何要分两种运行模式呢？主要是为了提高底层的安全，简化上层开发。不用担心用户的非法操作对底层硬件产生影响，因为非法操作在系统调用这一层被屏蔽了。&lt;/p&gt;

&lt;p&gt;Apache中通过.htaccess文件来为访问目录下各个子目录进行局部配置，但是也会产生一定的系统开销。
可以将httpd.conf中AllowOverrid设置为All,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Directory /&amp;gt;
    AllowOverride all
    Require all denied
&amp;lt;/Directory&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通过strace命令跟踪某一子进程，获得某次请求的系统调用如下：
&lt;img src=&#34;../../../../pic/2016/2016-04-25-apache-conf-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;此时，通过ab压测，结果如下：
&lt;img src=&#34;../../../../pic/2016/2016-04-25-apache-conf-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后我们关闭.htacess功能，重启apache，再次使用strace跟踪，结果如下所示：
&lt;img src=&#34;../../../../pic/2016/2016-04-25-apache-conf-3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ab压测结果如下：
&lt;img src=&#34;../../../../pic/2016/2016-04-25-apache-conf-4.png&#34; alt=&#34;&#34; /&gt;
比较两次压测结果，可见系统调用对服务器的吞吐量影响还是非常明显的。&lt;/p&gt;

&lt;h3 id=&#34;持久连接-长连接&#34;&gt;持久连接/长连接&lt;/h3&gt;

&lt;p&gt;持久连接（Keep-Alive）即为长连接，即对同一次连接的多次复用（连续发送多份数据）。而对应的短连接则是建立连接并发送完数据后断开，下次再建连接、发送、断开，如此反复。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;HTTP长连接需要浏览器和服务器的共同协作，缺一不可&lt;/strong&gt;。因为TCP连接是双向通信的，双方都可以主动关闭，任何一方断开都会引起另一方的关闭。对于长连接而言，关键的一点就是长连接的时间设置，在运行过程中，以时间段的为准，时间段的一方先断开连接。不同浏览器的长连接超时时间也不一致。&lt;/p&gt;

&lt;p&gt;在Apache中可以通过以下方法关闭：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;KeepAlive Off
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同样可以设置长连接的超时时间：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;KeepAliveTimeout 30
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面通过在Nginx服务器下的压测，通过ab启动长连接模拟发起支持长连接的HTTP请求。通过strace统计得出结果&lt;/p&gt;

&lt;p&gt;不使用长连接：
&lt;img src=&#34;../../../../pic/2016/2016-04-25-apache-conf-5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;使用长连接：
&lt;img src=&#34;../../../../pic/2016/2016-04-25-apache-conf-6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可见，长连接对吞吐量的提高有显著的改善，accept的调用耗时、调用次数都有所降低。&lt;/p&gt;

&lt;p&gt;长连接的超时对web服务器的性能也有影响，并不是超时时间越长越好。如果客户端没有任何请求，但超时时间还没到，服务器不得不维持空闲着的连接（对于Apache，将维持大量空闲进程，影响服务器性能 ）。&lt;/p&gt;

&lt;h3 id=&#34;sendfile&#34;&gt;sendfile&lt;/h3&gt;

&lt;p&gt;对于静态文件的请求（图片、样式表等），在请求过程中，磁盘文件数据先经过内核缓冲区，到用户内存空间，然后静态文件又会原封不动的送到网卡对应的内核缓冲区。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;sendfile的目的就在于内核希望请求的处理尽量在内核完成，减少内核态的切换，以及用户态数据的开销。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Apache默认是开启sendfile(sendfile on)的。通过对静态文件的访问，用strace跟踪如下图：
&lt;img src=&#34;../../../../pic/2016/2016-04-25-apache-conf-7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上述截图中，9代表的是磁盘的文件描述符；10代表的静态文件的文件描述符。可见直接通过sendfile对文件发送，而不经过用户内存空间。该方式下ab压测（用户并发数100， 总请求数1000， 文件大小1.5M）,吞吐量为1440.44 req/s。&lt;/p&gt;

&lt;p&gt;而关闭sendfile，跟踪如下图：
&lt;img src=&#34;../../../../pic/2016/2016-04-25-apache-conf-8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;好吧，截图中全是read，lseek函数，吞吐量为437.32 req/s(不忍直视)。但是sendfile对小文件而言发挥的作用应该不大，因为此时拷贝耗时已经不是主要因素了，所以还是需要结合具体业务来选择。&lt;/p&gt;

&lt;p&gt;其实要达到这种效果，还需要设置(EnableMMAP off).内存映射能够直接将磁盘文件映射到内存，以提高磁盘I/O的性能。使得访问文件能像访问内存一样自由，但是也是有代价的，对于共享型内存映射，如果一个文件被很多进程映射，那每次修改同步将有一定的时间开销。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;《构建高性能web站点》&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>ApacheBench(ab)压力测试</title>
          <link>https://maodanp.github.io/2016/04/24/apache-bench/</link>
          <pubDate>Sun, 24 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/04/24/apache-bench/</guid>
          <description>&lt;p&gt;通常考察服务器性能都离不开高并发、高吞吐率，本文主要描述了一些基本的概念，并通过ab压测分析其中的影响因素。&lt;/p&gt;

&lt;h3 id=&#34;吞吐率&#34;&gt;吞吐率&lt;/h3&gt;

&lt;p&gt;对于web服务器的并发处理能力，一般都用&lt;code&gt;吞吐率&lt;/code&gt;来表示（req/s），即单位时间内服务器处理的请求数。
而我们说明服务器性能的重要指标就是&lt;code&gt;最大吞吐率&lt;/code&gt;，表示在单位时间内该服务器能处理的最大请求数。&lt;/p&gt;

&lt;p&gt;但是实际中，服务器的最大吞吐量是跟业务相关的，线上环境我们也很难模拟，准确算出一台服务器的最大吞吐量。影响因素主要有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;并发用户数：如果并发用户数大于服务器所能支撑的最大并发数，那肯定会对服务器性能造成影响&lt;/li&gt;
&lt;li&gt;总请求数：即总共向服务器发送多少个请求，该值大于等于并发用户数，每个用户可以发送多个请求。&lt;/li&gt;
&lt;li&gt;请求资源类型：静态、动态内容， 文本、图片内容等都是影响吞吐量的直接因素&lt;/li&gt;
&lt;li&gt;服务器硬件：服务器本身硬件条件，包括内存容量、CPU核心、是否缓存等&lt;/li&gt;
&lt;li&gt;服务器软件：服务器用的Apache、Nginx等软件也是至关重要的因素&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以上影响因素中，并发用户数、总请求数是不可控的，作为&lt;strong&gt;压力测试的主要变量&lt;/strong&gt;；而后续几项则是&lt;strong&gt;服务器压测对象的描述&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&#34;并发用户数&#34;&gt;并发用户数&lt;/h4&gt;

&lt;p&gt;并发用户数是指某一时刻&lt;code&gt;同时&lt;/code&gt;向服务器发送请求的用户数量, 这里的同时意味着同一时间的发送。&lt;strong&gt;注意：真是的用户可能会给服务器带来多个并发用户数(浏览器下载一个网页可能采用多线程的并发下载)&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&#34;请求等待时间&#34;&gt;请求等待时间&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;用户平均等待时间：单个用户的质量体验&lt;/li&gt;
&lt;li&gt;服务器平均请求处理时间：服务器的质量体验（吞吐量的倒数）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以一般分析、提高服务器的并发处理能力，都是*固定某些方面因素，单独考察某一因素。并没有提高服务器并发能力的通用策略*。&lt;/p&gt;

&lt;h3 id=&#34;ab压力测试&#34;&gt;ab压力测试&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-04-24-apache-bench-1.png&#34; alt=&#34;标题图片&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;参数说明&#34;&gt;参数说明&lt;/h4&gt;

&lt;p&gt;其中，一些重要的参数说明如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;-n: 表示总请求数为1000&lt;/li&gt;
&lt;li&gt;-c 10: 表示并发用户数为10&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost/phpinfo.php:&#34;&gt;http://localhost/phpinfo.php:&lt;/a&gt; 表示压测的目标URL&lt;/li&gt;
&lt;li&gt;Concurrency Level: 表示&lt;strong&gt;并发用户数&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Time taken for tests: 表示所有这些请求被处理完的总时间&lt;/li&gt;
&lt;li&gt;Complete requests: 表示总请求数&lt;/li&gt;
&lt;li&gt;Failed requests: 表示失败的请求数&lt;/li&gt;
&lt;li&gt;Total transferred: 表示所有请求响应数据长度总和（响应头+正文数据长度）&lt;/li&gt;
&lt;li&gt;HTML transferred: 表示所有请求响应的正文长度总和（正文数据长度）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Request per second&lt;/code&gt;: 吞吐量， 等于 [ Complete requests / Time taken for tests ]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Time per request&lt;/code&gt;:  用户平均等待时间, 等于 [ Time taken for tests /（Complete requests / Cocurrency Level）]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Time per request(accross all concurrent requests)&lt;/code&gt;:  服务器平均请求处理时间, 等于吞吐量的倒数。 同时也等于 [ Time per request / Cocurrency Level ]&lt;/li&gt;
&lt;li&gt;Transfer rate: 表示这些请求在单位时间内从服务器获取的数据长度，等于 [ Total transferred / Time taken for tests ]&lt;/li&gt;
&lt;li&gt;Percentage of the requests served within a certain time(ms): 每个请求处理时间的分布情况（指的是Time per request）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;注意： 参数&lt;strong&gt;Failed Requests&lt;/strong&gt;表示连接请求发生异常，或者相应超时的情况（对于返回2XX以外的状态码，将显示另一个名为“Non-2xx responses”的统计项，返回状态码的不算请求失败), 上述截图中，在Failed requests下面出现了统计失败的原因，分别有Connect、Receive、Length、Exceptions&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Connect 无法送出要求、目标主机连接失败、要求的过程中被中断。&lt;/li&gt;
&lt;li&gt;Receive 服务器接受连接异常。&lt;/li&gt;
&lt;li&gt;Length 响应的内容长度不一致 ( 以 Content-Length 头值为判断依据 )。&lt;/li&gt;
&lt;li&gt;Exception 发生无法预期的错误。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里的Length是以“第一次”响应取得的Content-Length为主，如果后续的HTTP Request所得到的HTTP 响应头的Content-Length与第一次的不一致，就会得到Length的错误。 这个对于动态页面来说正常。&lt;/p&gt;

&lt;h4 id=&#34;不同并发数的测试对比&#34;&gt;不同并发数的测试对比&lt;/h4&gt;

&lt;p&gt;不同压测基于Nginx，请求总数为10000，不同并发数的测试结果如下表：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;用户并发数&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;吞吐量(req/sec)&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;用户请求等待时间(s）&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;服务器请求处理时间(s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3383.05&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.295&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.295&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3647.08&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.548&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.274&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3690.62&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.355&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.271&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3815.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2.621&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.262&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3497.34&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.719&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.286&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;50&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4127.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12.114&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.242&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4123.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;24.249&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.242&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;150&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4182.19&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;35.866&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.239&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3293.41&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;60.727&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.304&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;500&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2349.03&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;212.854&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.426&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;如图示，在用户并发数达到100之前，随着并发数的增长，服务器的资源被不断的利用，所以吞吐量不断提高；当用户并发数达到100，则吞吐量最高；超过100后，由于资源所限（fastcgi的进程最大限制为50），吞吐量开始下滑。
&lt;img src=&#34;../../../../pic/2016/2016-04-24-apache-bench-2.png&#34; alt=&#34;标题图片&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如果使用Apache服务器测试，或者压测的URL为静态资源，或者优化服务器的参数（最大进程个数、是否开启缓存）等等，压测的结果又是不同的。 所以并没有一个提高服务器吞吐量的通用策略，需要结合具体业务。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;《构建高性能web站点》&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>《功夫小蝇》- 苍蝇复仇记</title>
          <link>https://maodanp.github.io/2016/04/24/gongfu/</link>
          <pubDate>Sun, 24 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/04/24/gongfu/</guid>
          <description>&lt;p&gt;最近是迷上了印度电影，从早些的《三傻》，到《OMG》、《未知死亡》、《爱无止境》、《我的个神啊》&amp;hellip;看了很多。感觉阿三的电影都很有内涵，表达宗教与信仰、人性与冲突，穿插的歌曲也都与故事情节衔接的十分自然。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-04-24-gongfu.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;《功夫小蝇》是一部取材新颖的电影，讲述以苍蝇的视觉复仇的故事。电影依旧延续印度招牌式的歌舞，前十几分钟讲述男女的爱情，音乐穿插的自然，场景唯美，拍摄角度自然。印度电影基本都是如此，传递的东西简单，正能量，直指人心，使人影响深刻。&lt;/p&gt;

&lt;p&gt;真正剧情有些突兀的是男主角被残害，显得不是太自然。唯美的爱情片瞬间变成了充满血腥的复仇记，不过看了后续的剧情也就适应了（影片十几分钟我都快睡了，纳闷这部片想表达男女温情烂漫的爱情么，被影片的转折惊醒了）。&lt;/p&gt;

&lt;p&gt;影片中间主要描述苍蝇如何复仇的种种手段，无论是电影的特效、剪辑还是故事的情节都非常的精彩。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;这部以电影特效打造的电影主角—苍蝇，展现出的是如此的自然，仿佛就是我们的镜头跟着它飞，跟着它冲出激流，飞翔空中，钻于夹缝。当它跑步、举重锻炼时，就感觉它是那么的可爱。丝毫未看出电影特效的痕迹。&lt;/li&gt;
&lt;li&gt;更重要的是故事的情节，以苍蝇的躯体赋予人的智商，想着怎么依靠外力去复仇？是的，大部分复仇方式都是匪夷所思，拍案叫好的。故事的情节推进，直到最后的复仇高潮，都仅仅勾住了大家的心，时不时为小蝇叫好，为小蝇捏汗。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后的结局延续一贯的正能量价值观, 坏蛋被成功复仇。但是结局没有呈现出爱情故事应该有的结局，如苍蝇复活和女主角快乐的生活在一起。也许留有些遗憾大家才能深刻记住，不完美也许更好。&lt;/p&gt;

&lt;p&gt;总的来说，是很值得看的一部电影。虽然是小成本的电影，但表达的价值观是正向的，影片的构思是非常精妙的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;认准目标，坚定信心，不管困难有多强大，发挥自己的优势，一定能做到！&lt;/strong&gt;&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>golang错误处理(二)</title>
          <link>https://maodanp.github.io/2015/04/15/error-handling-in-go-part-ii/</link>
          <pubDate>Fri, 15 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2015/04/15/error-handling-in-go-part-ii/</guid>
          <description>&lt;p&gt;该篇作为系列(二)，自然要更深入一层。本文翻译自&lt;a href=&#34;https://www.goinggo.net/2014/11/error-handling-in-go-part-ii.html&#34;&gt;Error Handling In Go, Part II&lt;/a&gt;，作者在该篇中将教我们怎么写自定义error接口，并且根据error如何识别具体的错误。&lt;/p&gt;

&lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;

&lt;p&gt;在第一部分中，我们学习了&lt;code&gt;error&lt;/code&gt;接口，以及标准库如何通用&lt;code&gt;errors&lt;/code&gt;包创建的&lt;code&gt;error&lt;/code&gt;接口来提供支持的。 我们也学习了当错误发生时，我们如何识别是那种类型的错误。最后，我们看到在有些标准库中，如何对外提供&lt;code&gt;error&lt;/code&gt;接口变量来帮助我们识别具体错误。&lt;/p&gt;

&lt;p&gt;知道如何创建以及使用&lt;code&gt;error&lt;/code&gt;类型在Go语言中常常会使我们感到迷惑。大多数情况下，通过&lt;code&gt;errors&lt;/code&gt;包创建的&lt;code&gt;error&lt;/code&gt;接口值已经足够了，然后有时候调用者需要额外的基于上下文的信息，以便能够基于详细的错误处理做处理。这就是本篇文章要讲的自定义错误类型。&lt;/p&gt;

&lt;p&gt;在本篇文章我，我想将要学习如何自定义错误类型，以及给出两个标准库中的示例。其中每个示例都提供了关于如何实现自定义错误类型的非常有意思的实现方式。然后我们将会学习如何识别具体的错误接口值（值类型或者指针类型）。&lt;/p&gt;

&lt;h3 id=&#34;net-包&#34;&gt;&lt;code&gt;net&lt;/code&gt; 包&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;net&lt;/code&gt; 包中声明了一个自定义的错误类型—&lt;code&gt;OpError&lt;/code&gt;. 在这个包的很多函数、方法中都将这个结构体的指针作为具体的类型（存储在返回的&lt;code&gt;error&lt;/code&gt;接口值当中）：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.1&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/pkg/net/dial.go

01 func Listen(net, laddr string) (Listener, error) {
02     la, err := resolveAddr(&amp;quot;listen&amp;quot;, net, laddr, noDeadline)
03     if err != nil {
04         return nil, &amp;amp;OpError{Op: &amp;quot;listen&amp;quot;, Net: net, Addr: nil, Err: err}
05     }
06     var l Listener
07     switch la := la.toAddr().(type) {
08     case *TCPAddr:
09         l, err = ListenTCP(net, la)
10     case *UnixAddr:
11         l, err = ListenUnix(net, la)
12     default:
13         return nil, &amp;amp;OpError{Op: &amp;quot;listen&amp;quot;, Net: net, Addr: la, Err: &amp;amp;AddrError{Err: &amp;quot;unexpected address type&amp;quot;, Addr: laddr}}
14     }
15     if err != nil {
16         return nil, err // l is non-nil interface containing nil pointer
17     }
18     return l, nil
19 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.1 展示了&lt;code&gt;net&lt;/code&gt;包中的&lt;code&gt;Listen&lt;/code&gt;函数的实现。我们看到在04和13行中，&lt;code&gt;OpError&lt;/code&gt;结构体的指针被创建了，并且作为&lt;code&gt;error&lt;/code&gt;接口值返回。因为&lt;code&gt;OpError&lt;/code&gt;结构体指针实现了&lt;code&gt;error&lt;/code&gt;接口，这个指针能够存储在&lt;code&gt;error&lt;/code&gt;接口值中并且返回。而在09和11行，&lt;code&gt;ListenTCP&lt;/code&gt;和&lt;code&gt;ListenUnix&lt;/code&gt;函数也能返回&lt;code&gt;OpError&lt;/code&gt;结构体指针, 只是它们已经被包含在了返回的&lt;code&gt;error&lt;/code&gt;接口值中。&lt;/p&gt;

&lt;p&gt;线面，让我来看下&lt;code&gt;OpError&lt;/code&gt;结构的具体&lt;strong&gt;声明&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.2&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/pkg/net/#OpError

01 // OpError is the error type usually returned by functions in the net
02 // package. It describes the operation, network type, and address of
03 // an error.
04 type OpError struct {
05     // Op is the operation which caused the error, such as
06     // &amp;quot;read&amp;quot; or &amp;quot;write&amp;quot;.
07     Op string
08
09     // Net is the network type on which this error occurred,
10     // such as &amp;quot;tcp&amp;quot; or &amp;quot;udp6&amp;quot;.
11     Net string
12
13     // Addr is the network address on which this error occurred.
14     Addr Addr
15
16     // Err is the error that occurred during the operation.
17     Err error
18 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.2中显示了&lt;code&gt;OpError&lt;/code&gt;结构的定义。其中前三个字段（07、11、14行）提供了当执行网络操作时，错误发生的上下文信息。17行第四个字段声明为一个&lt;code&gt;error&lt;/code&gt;接口类型，这个字段将包含具体当错误发生时的真实信息，这个具体类型的值多数情况下会是一个&lt;code&gt;errorString&lt;/code&gt;类型的指针。&lt;/p&gt;

&lt;p&gt;另外我们需要注意到：对于自定义的错误类型，Go语言中有一个约定俗成的规则，就是在自定义错误类型后面加&lt;code&gt;Error&lt;/code&gt;后缀。基本上其他包中也是这么定义的。&lt;/p&gt;

&lt;p&gt;下面，我们来看看&lt;code&gt;OpError&lt;/code&gt;的具体&lt;strong&gt;定义&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.3&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/pkg/net/net.go

01 func (e *OpError) Error() string {
02     if e == nil {
03         return &amp;quot;&amp;lt;nil&amp;gt;&amp;quot;
04     }
05     s := e.Op
06     if e.Net != &amp;quot;&amp;quot; {
07         s += &amp;quot; &amp;quot; + e.Net
08     }
09     if e.Addr != nil {
10         s += &amp;quot; &amp;quot; + e.Addr.String()
11     }
12     s += &amp;quot;: &amp;quot; + e.Err.Error()
13     return s
14 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.3中关于&lt;code&gt;error&lt;/code&gt;接口的实现，我们能看到如何关联上下文与错误信息，从而产生基于上下的错误信息描述。这种包含上下文描述的错误能够帮助调用者关于如何处理错误提供更有价值性的参考。&lt;/p&gt;

&lt;h3 id=&#34;json-包&#34;&gt;&lt;code&gt;json&lt;/code&gt; 包&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;json&lt;/code&gt;包能够实现从编码后的JSON数据到原生的Go类型的转换，反之亦然。 所有可能返回的错误都是在包内部产生的。对于错误信息而言保留上下文信息显得至关重要，否则就不能对于发生的错误提供正确的信息。对于&lt;code&gt;json&lt;/code&gt;包来说有包含多自定义的错误类型，而且这些类型都能够通过相同的函数或者方法返回。&lt;/p&gt;

&lt;p&gt;下面，我们来看下其中的一个自定义错误类型：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.4&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/pkg/encoding/json/decode.go

01 // An UnmarshalTypeError describes a JSON value that was
02 // not appropriate for a value of a specific Go type.
03 type UnmarshalTypeError struct {
04     Value string // description of JSON value
05     Type reflect.Type // type of Go value it could not be assigned to
06 }
07
08 func (e *UnmarshalTypeError) Error() string {
09     return &amp;quot;json: cannot unmarshal &amp;quot; + e.Value + &amp;quot; into Go value of type &amp;quot; + e.Type.String()
10 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.4 显示了&lt;code&gt;UnmarshalTypeError&lt;/code&gt;类型的声明，以及对&lt;code&gt;error&lt;/code&gt;接口的实现。这个结构通常对于那些JSON数据不能转换成原生的Go类型时发生的错误。这个结构包含两个字段，第一个(04行)包含了试图解码的值类型描述；第二个(05行)包含了试图转化成的Go类型的描述。08行是&lt;code&gt;error&lt;/code&gt;接口的具体实现，它用于错误信息的上下文，并产生一个正确的错误信息。&lt;/p&gt;

&lt;p&gt;在这个例子中，&lt;code&gt;UnmarshalTypeError&lt;/code&gt;类型本身提供了错误的上下文信息。 当有关于解码类型的错误发生时，就会返回基于该结构指针的&lt;code&gt;error&lt;/code&gt;接口值作为返回。&lt;/p&gt;

&lt;p&gt;那么，当无效的参数传递到&lt;code&gt;unmarshal&lt;/code&gt;函数呢，那返回的就不是&lt;code&gt;UnmarshalTypeError&lt;/code&gt;类型指针了，而是&lt;code&gt;InvalidUnmarshalError&lt;/code&gt;类型的指针：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.5&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/pkg/encoding/json/decode.go

01 // An InvalidUnmarshalError describes an invalid argument passed to Unmarshal.
02 // (The argument to Unmarshal must be a non-nil pointer.)
03 type InvalidUnmarshalError struct {
04     Type reflect.Type
05 }
06
07 func (e *InvalidUnmarshalError) Error() string {
08     if e.Type == nil {
09         return &amp;quot;json: Unmarshal(nil)&amp;quot;
10     }
11
12     if e.Type.Kind() != reflect.Ptr {
13         return &amp;quot;json: Unmarshal(non-pointer &amp;quot; + e.Type.String() + &amp;quot;)&amp;quot;
14     }
15     return &amp;quot;json: Unmarshal(nil &amp;quot; + e.Type.String() + &amp;quot;)&amp;quot;
16 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.5展示了&lt;code&gt;InvalidUnmarshalError&lt;/code&gt;结构的声明以及对&lt;code&gt;error&lt;/code&gt;接口的实现。这里也同样在错误中提供了上下文信息描述。这种实现方式能够帮助产生错误信息，产生的错误信息能够有助于调用者根据错误处理做准确的判断。&lt;/p&gt;

&lt;h3 id=&#34;具体类型的定义&#34;&gt;具体类型的定义&lt;/h3&gt;

&lt;p&gt;在&lt;code&gt;json&lt;/code&gt;的&lt;code&gt;Unmarshal&lt;/code&gt;函数中，&lt;code&gt;error&lt;/code&gt;接口值返回的类型指针可能是&lt;code&gt;UnmarshalTypeError&lt;/code&gt;，或&lt;code&gt;InvalidUnmarshalError&lt;/code&gt;或是&lt;code&gt;errorString&lt;/code&gt;类型：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.6&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/pkg/encoding/json/decode.go

01 func Unmarshal(data []byte, v interface{}) error {
02     // Check for well-formedness.
03     // Avoids filling out half a data structure
04     // before discovering a JSON syntax error.
05     var d decodeState
06     err := checkValid(data, &amp;amp;d.scan)
07     if err != nil {
08         return err
09     }
10
11     d.init(data)
12     return d.unmarshal(v)
13 }
14
15 func (d *decodeState) unmarshal(v interface{}) (err error) {
16     defer func() {
17         if r := recover(); r != nil {
18             if _, ok := r.(runtime.Error); ok {
19                 panic®
20             }
21             err = r.(error)
22         }
23     }()
24
25     rv := reflect.ValueOf(v)
26     if rv.Kind() != reflect.Ptr || rv.IsNil() {
27         return &amp;amp;InvalidUnmarshalError{reflect.TypeOf(v)}
28     }
29
30     d.scan.reset()
31     // We decode rv not rv.Elem because the Unmarshaler interface
32     // test must be applied at the top level of the value.
33     d.value(rv)
34     return d.savedError
35 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.6，展示了作为&lt;code&gt;Unmarshal&lt;/code&gt;函数调用返回的&lt;code&gt;error&lt;/code&gt;接口值，存在的不同具体类型。 第27行，&lt;code&gt;unmarshal&lt;/code&gt;方法返回了一个&lt;code&gt;InvalidUnmarshalError&lt;/code&gt;类型的指针，第34行，返回了&lt;code&gt;decodeState&lt;/code&gt;中的变量&lt;code&gt;savedError&lt;/code&gt;，&lt;strong&gt;这个值可以是很多不同的具体类型的指针&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;通过以上我们了解到了&lt;code&gt;json&lt;/code&gt;包是自定义了&lt;code&gt;error&lt;/code&gt;类型作为上下文的错误信息，那我们如何区分这些具体值得类型，使得调用者能够根据详细描述做判断？&lt;/p&gt;

&lt;p&gt;下面给出一个示例，能够使得&lt;code&gt;Unmarshal&lt;/code&gt;函数返回一个具体的&lt;code&gt;UnmarshalTypeError&lt;/code&gt;类型的指针：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.7&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://play.golang.org/p/FVFo8mJLBV

01 package main
02
03 import (
04     &amp;quot;encoding/json&amp;quot;
05     &amp;quot;fmt&amp;quot;
06     &amp;quot;log&amp;quot;
07 )
08
09 type user struct {
10     Name int
11 }
12
13 func main() {
14     var u user
15     err := json.Unmarshal([]byte({&amp;quot;name&amp;quot; : &amp;quot;bill&amp;quot;}), &amp;amp;u)
16     if err != nil {
17         log.Println(err)
18         return
19     }
20
21     fmt.Println(&amp;quot;Name:&amp;quot;, u.Name)
22 }

Output:
2009/11/10 23:00:00 json: cannot unmarshal string into Go value of type int
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.7，展示了一个简单的代码，尝试将JSON格式数据转换成Go类型。在第15行，JSON数据包含一个名为&lt;code&gt;name&lt;/code&gt;的字段，值为&lt;code&gt;bill&lt;/code&gt;。 因为&lt;code&gt;user&lt;/code&gt;类型中&lt;code&gt;Name&lt;/code&gt;字段声明的是一个整型，&lt;code&gt;Unmarshal&lt;/code&gt;函数返回了一个错误接口值，该值实际存储的是一个&lt;code&gt;UnmarshalTypeError&lt;/code&gt;类型的具体指针。&lt;/p&gt;

&lt;p&gt;现在我们可以做上面的代码做些改变，对于同样的&lt;code&gt;Unmarshal&lt;/code&gt;调用返回的&lt;code&gt;error&lt;/code&gt;接口，存储的是不一样的具体指针类型：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.8&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://play.golang.org/p/n8dQFeHYVp

01 package main
02
03 import (
04     &amp;quot;encoding/json&amp;quot;
05     &amp;quot;fmt&amp;quot;
06     &amp;quot;log&amp;quot;
07 )
08
09 type user struct {
10     Name int
11 }
12
13 func main() {
14     var u user
15     err := json.Unmarshal([]byte({&amp;amp;quot;name&amp;amp;quot;:&amp;amp;quot;bill&amp;amp;quot;}), u)
16     if err != nil {
17         switch e := err.(type) {
18         case *json.UnmarshalTypeError:
19             log.Printf(&amp;quot;UnmarshalTypeError: Value[%s] Type[%v]\n&amp;quot;, e.Value, e.Type)
20         case *json.InvalidUnmarshalError:
21             log.Printf(&amp;quot;InvalidUnmarshalError: Type[%v]\n&amp;quot;, e.Type)
22         default:
23             log.Println(err)
24         }
25         return
26     }
27
28     fmt.Println(&amp;quot;Name:&amp;quot;, u.Name)
29 }

Output:
2009/11/10 23:00:00 json: Unmarshal(non-pointer main.user)
2009/11/10 23:00:00 InvalidUnmarshalError: Type[main.user]  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we do something interesting on lines 17 through 24:&lt;/p&gt;

&lt;p&gt;Listing 1.8，同样的代码我们做了小小的修改，在15行中我们传递了变量&lt;code&gt;u&lt;/code&gt;的值，而不是它的地址。 这个改变导致了&lt;code&gt;Unmarshal&lt;/code&gt;函数返回了一个错误接口值，它实际存储的是&lt;code&gt;InvalidUnmarshalError&lt;/code&gt;这个具体的指针类型。&lt;/p&gt;

&lt;p&gt;对于17-24行，我们进行了错误的处理：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.9&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    17     switch e := err.(type) {
    18         case *json.UnmarshalTypeError:
    19             log.Printf(&amp;quot;UnmarshalTypeError: Value[%s] Type[%v]\n&amp;quot;, e.Value, e.Type)
    20         case *json.InvalidUnmarshalError:
    21             log.Printf(&amp;quot;InvalidUnmarshalError: Type[%v]\n&amp;quot;, e.Type)
    22         default:
    23             log.Println(err)
    24         }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在17行，我们加入了&lt;code&gt;switch&lt;/code&gt;语句进行具体指针类型的识别（这个指针当然是存储在&lt;code&gt;error&lt;/code&gt;接口值下的）。这里要注意如何在接口值转换中使用关键字类型的。我们也能够获取到具体类型的值,并且在每个&lt;code&gt;case&lt;/code&gt;语句中使用它。&lt;/p&gt;

&lt;p&gt;在18、20行的&lt;code&gt;case&lt;/code&gt;语句中，进行了不同具体类型的检测，然后执行了关于错误处理的操作。在Go中是普遍采这种方式来识别具体类型的值或者指针。这些值或指针是存储在在&lt;code&gt;error&lt;/code&gt;接口值当中的。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;我们所返回的函数或者方法中的&lt;code&gt;error&lt;/code&gt;接口值，包含特定的运行上下文信息。它必须能够提供足够多的信息，以便调用者能够根据这些信息分辨。通常一个简单的错误消息就足够了，但是有时调用者需要知道更多信息。&lt;/p&gt;

&lt;p&gt;我们能够看出，在&lt;code&gt;net&lt;/code&gt;包中，一个自定义的&lt;code&gt;error&lt;/code&gt;类型，声明中包含了原始&lt;code&gt;error&lt;/code&gt;以及关联的上下文信息。而在&lt;code&gt;json&lt;/code&gt;包中，我们看到自定义的错误类型提供了上下文信息以及关联状态。 在两者中，保持错误关联的上下文信息是一个必要的因素。&lt;/p&gt;

&lt;p&gt;当传统的&lt;code&gt;error&lt;/code&gt;接口值通过&lt;code&gt;errors&lt;/code&gt;包创建, 并且提供了足够的信息，那么久使用它吧。这通常包含在标准库中，通常这些就已经足够了。如果你需要其他上下文信息以帮助调用者做具体决定，那么我们可以从标准库中找找线索，然后构建自定化&lt;code&gt;error&lt;/code&gt;类型。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>golang错误处理(一)</title>
          <link>https://maodanp.github.io/2015/04/12/error-handling-in-go-part-i/</link>
          <pubDate>Tue, 12 Apr 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2015/04/12/error-handling-in-go-part-i/</guid>
          <description>&lt;p&gt;Golang中Error作为返回值是很常见的，几乎每个函数返回值都有error的interface。本文翻译自&lt;a href=&#34;https://www.goinggo.net/2014/10/error-handling-in-go-part-i.html&#34;&gt;Error Handling In Go, Part I&lt;/a&gt;，作者在该篇中对error接口的创建、使用等做了详细描述。&lt;/p&gt;

&lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;

&lt;p&gt;在Go语言中，使用error接口作为函数或者方法的返回值是一种很惯用的方法。这个接口同样在Go的标准库中也作为返回值。&lt;/p&gt;

&lt;p&gt;例如，这是http包的Get方法声明：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.1&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Client) Get(url string) (resp *Response, err error)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一般都会在函数、方法的返回中，判断error的值是否为&lt;code&gt;nil&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.2&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resp, err := c.Get(&amp;quot;http://goinggo.net/feeds/posts/default&amp;quot;)
if err != nil {
    log.Println(err)
    return
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 listing 1.2, 对&lt;code&gt;Get&lt;/code&gt;方法的调用通过两个局部变量返回。 然后比较&lt;code&gt;err&lt;/code&gt;变量是否等于&lt;code&gt;nil&lt;/code&gt;。 如果不等，则表示有错误。&lt;/p&gt;

&lt;p&gt;因为&lt;code&gt;error&lt;/code&gt;是用于处理错误的接口，我们需要根据提供的接口实现具体的代码。标准库中&lt;code&gt;errorString&lt;/code&gt;已经实现了该接口。&lt;/p&gt;

&lt;h3 id=&#34;error接口与errstring结构&#34;&gt;Error接口与errString结构&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;error&lt;/code&gt;的接口声明如下：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.3&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type error interface {
Error() string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 listing 1.3中, 我们看到&lt;code&gt;err&lt;/code&gt;接口的声明仅仅包括一个&lt;code&gt;Error&lt;/code&gt;, 该方法返回&lt;code&gt;string&lt;/code&gt;类型。因此，&lt;strong&gt;任何类型只要实现了&lt;code&gt;Error&lt;/code&gt;方法，也就实现了&lt;code&gt;err&lt;/code&gt;接口&lt;/strong&gt;。 关于&lt;code&gt;Go&lt;/code&gt;中的接口，可以参考&lt;a href=&#34;https://www.goinggo.net/2014/05/methods-interfaces-and-embedded-types.html&#34;&gt;Methods, Interfaces and Embedded Types in Go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;标准库中也声明了&lt;code&gt;errorString&lt;/code&gt;的结构，该结构在&lt;code&gt;errors&lt;/code&gt;包中：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.4&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/pkg/errors/errors.go
type errorString struct {
 s string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 listing 1.4中, 我们看到&lt;code&gt;errorString&lt;/code&gt;中只有一个类型为&lt;code&gt;string&lt;/code&gt;的字段。我们能够看到结构以及内部的字段都是不能够被外部访问的，我们不能直接访问该结构或者它内部的变量，具体可以参考&lt;a href=&#34;https://www.goinggo.net/2014/03/exportedunexported-identifiers-in-go.html&#34;&gt;Exported/Unexported Identifiers in Go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.5&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (e *errorString) Error() string {
    return e.s
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看到listing 1.5中，&lt;code&gt;error&lt;/code&gt;接口通过指针类型的接受者&lt;code&gt;(*errorString)&lt;/code&gt;实现了。&lt;code&gt;errorString&lt;/code&gt;类型是标准库中最常用的类型，它能够作为&lt;code&gt;error&lt;/code&gt;类型接口的返回值。&lt;/p&gt;

&lt;p&gt;下面我们来学习标准库中如何通过&lt;code&gt;errorString&lt;/code&gt;结构来创建&lt;code&gt;error&lt;/code&gt;类型的接口。&lt;/p&gt;

&lt;h3 id=&#34;创建error值&#34;&gt;创建Error值&lt;/h3&gt;

&lt;p&gt;标准库中，提供了两种方式来创建&lt;code&gt;errorString&lt;/code&gt;类型的指针，以作为&lt;code&gt;error&lt;/code&gt;类型的接口使用。当你定义的error是一个string类型，且不需要具体的格式化参数，那么可以通过&lt;code&gt;errors&lt;/code&gt;包的&lt;code&gt;New&lt;/code&gt;函数定义。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.6&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var ErrInvalidParam = errors.New(&amp;quot;mypackage: invalid parameter&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.6中, 显示了&lt;code&gt;errors&lt;/code&gt;包的&lt;code&gt;New&lt;/code&gt;函数的调用。在这个示例中，我们声明了一个&lt;code&gt;error&lt;/code&gt;类型的接口变量，然后通过调用&lt;code&gt;New&lt;/code&gt;函数初始化该变量。下面为&lt;code&gt;New&lt;/code&gt;的实现：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.7&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// New returns an error that formats as the given text.
func New(text string) error {
    return &amp;amp;errorString{text}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.7中, 我们看到函数以&lt;code&gt;string&lt;/code&gt;类型作为参数传入，返回了&lt;code&gt;error&lt;/code&gt;类型的接口。在该函数的实现中，创建了一个&lt;code&gt;errorString&lt;/code&gt;类型的指针。 在return语句中，编译器创建了&lt;code&gt;error&lt;/code&gt;类型的接口，然后结合指针，作为返回。 &lt;code&gt;errorString&lt;/code&gt;指针作为隐含的数据，当做&lt;code&gt;error&lt;/code&gt;接口的值返回了。&lt;/p&gt;

&lt;p&gt;那么问题来了，如果我们的错误消息需要格式化呢？ 不着急，下面的 &lt;code&gt;fmt&lt;/code&gt;包中的&lt;code&gt;Errorf&lt;/code&gt;函数能够做到。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.8&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var ErrInvalidParam = fmt.Errorf(&amp;quot;invalid parameter [%s]&amp;quot;, param)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.8中, 我们可以看到&lt;code&gt;Errorf&lt;/code&gt;函数被调用了。如果你对&lt;code&gt;fmt&lt;/code&gt;包中的其他函数熟悉，你就知道这个函数跟其他函数是类似的了。这里，通过调用&lt;code&gt;Errorf&lt;/code&gt;函数， 我们再次创建并初始化了一个&lt;code&gt;error&lt;/code&gt;类型的接口变量。&lt;/p&gt;

&lt;p&gt;下面我们揭开&lt;code&gt;Errorf&lt;/code&gt;函数的神秘面纱&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.9&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/pkg/fmt/print.go

// Errorf formats according to a format specifier and returns the string
// as a value that satisfies error.
func Errorf(format string, a …interface{}) error {
    return errors.New(Sprintf(format, a…))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.9中, 我们看到依然是通过&lt;code&gt;error&lt;/code&gt;接口作为返回值类型的。 在该函数的实现中，调用了&lt;code&gt;errors&lt;/code&gt;包的&lt;code&gt;New&lt;/code&gt;函数，其中参数为格式化好的字符串。所以不管你使用&lt;code&gt;errors&lt;/code&gt;包或者&lt;code&gt;fmt&lt;/code&gt;包来创建&lt;code&gt;error&lt;/code&gt;类型的接口，&lt;strong&gt;&lt;em&gt;底层都是为&lt;code&gt;errorString&lt;/code&gt;类型的指针&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;现在我们有两种不同的方式，都能通过&lt;code&gt;errorString&lt;/code&gt;的指针实现&lt;code&gt;error&lt;/code&gt;类型的接口。下面我们来学习在标准库中，如何在API调用中返回特有的&lt;code&gt;errors&lt;/code&gt;信息。&lt;/p&gt;

&lt;h3 id=&#34;比较errors值&#34;&gt;比较Errors值&lt;/h3&gt;

&lt;p&gt;在&lt;code&gt;bufio&lt;/code&gt;包中（标准库中其他包也是一样的），通过&lt;code&gt;errors&lt;/code&gt;包中的&lt;code&gt;New&lt;/code&gt;函数来创建不同error变量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.10&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/pkg/bufio/bufio.go

var (
    ErrInvalidUnreadByte = errors.New(&amp;quot;bufio: invalid use of UnreadByte&amp;quot;)
    ErrInvalidUnreadRune = errors.New(&amp;quot;bufio: invalid use of UnreadRune&amp;quot;)
    ErrBufferFull        = errors.New(&amp;quot;bufio: buffer full&amp;quot;)
    ErrNegativeCount     = errors.New(&amp;quot;bufio: negative count&amp;quot;)
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.10 展示了四个不同的error变量，它们都在&lt;code&gt;bufio&lt;/code&gt;包中声明、初始化。注意到这些变量都是通过&lt;code&gt;Err&lt;/code&gt;作为前缀的，在Go中这是一种约定俗成的书写方式。因为这些变量都被声明为&lt;code&gt;error&lt;/code&gt;类型接口，我们能够区分指定的错误，这些错误可以是由&lt;code&gt;bufio&lt;/code&gt;包中不同的API返回的：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.11&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data, err := b.Peek(1)
if err != nil {
    switch err {
    case bufio.ErrNegativeCount:
        // Do something specific.
        return
    case bufio.ErrBufferFull:
        // Do something specific.
        return
    default:
        // Do something generic.
        return
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 listing 1.11 中，示例代码调用了&lt;code&gt;bufio.Reader&lt;/code&gt;类型指针值的&lt;code&gt;Peek&lt;/code&gt;方法。&lt;code&gt;Peek&lt;/code&gt;方法返回的值可能是&lt;code&gt;ErrNegativeCount&lt;/code&gt;或是 &lt;code&gt;ErrBufferFull&lt;/code&gt;变量。 因为这些变量已经对外暴露了，所以我们能够利用这些变量来区分具体是哪个错误。区分这些变量也是标准库中错误处理的一部分。&lt;/p&gt;

&lt;p&gt;设想如果我们没有声明这些&lt;code&gt;error&lt;/code&gt;变量，那么我们不得不通过比较具体的错误信息来判断我们获得的是那些错误：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.12&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data, err := b.Peek(1)
if err != nil {
    switch err.Error() {
    case &amp;quot;bufio: negative count&amp;quot;:
        // Do something specific.
        return
    case &amp;quot;bufio: buffer full&amp;quot;:
        // Do something specific.
        return
    default:
        // Do something specific.
        return
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在listing 1.12的例子中，有两个问题：首先，&lt;code&gt;Error()&lt;/code&gt;函数的调用会产生一份错误消息的拷贝；其次，如果包的开发者改变了这些消息内容，那么这段代码就有问题了。&lt;/p&gt;

&lt;p&gt;下面的&lt;code&gt;io&lt;/code&gt;包是另外一个例子，声明了&lt;code&gt;error&lt;/code&gt;类型的变量，并且都能够作为错误返回：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.13&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var ErrShortWrite    = errors.New(&amp;quot;short write&amp;quot;)
var ErrShortBuffer   = errors.New(&amp;quot;short buffer&amp;quot;)
var EOF              = errors.New(&amp;quot;EOF&amp;quot;)
var ErrUnexpectedEOF = errors.New(&amp;quot;unexpected EOF&amp;quot;)
var ErrNoProgress    = errors.New(&amp;quot;multiple Read calls return no data or error&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.13显示了在&lt;code&gt;io&lt;/code&gt;包中的六个&lt;code&gt;error&lt;/code&gt;变量。其中第三个变量是&lt;code&gt;EOF&lt;/code&gt;错误变量的声明，表示没有多余的输入变量了。通常会在这个包中比较将函数返回的错误值与该值进行比较。&lt;/p&gt;

&lt;p&gt;下面是&lt;code&gt;io&lt;/code&gt;包中的&lt;code&gt;ReadAtLeast&lt;/code&gt;函数的实现：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.14&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func ReadAtLeast(r Reader, buf []byte, min int) (n int, err error) {
    if len(buf) &amp;lt; min {
        return 0, ErrShortBuffer
    }
    for n &amp;lt; min &amp;amp;&amp;amp; err == nil {
        var nn int
        nn, err = r.Read(buf[n:])
        n += nn
    }
    if n &amp;gt;= min {
        err = nil
    } else if n &amp;gt; 0 &amp;amp;&amp;amp; err == EOF {
        err = ErrUnexpectedEOF 
    }
    return
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在listing 1.14中，&lt;code&gt;ReadAtLeast&lt;/code&gt;函数显示了如何使用这些错误变量。这里要注意到 &lt;code&gt;ErrShortBuffer&lt;/code&gt; 和 &lt;code&gt;ErrUnexpectedEOF&lt;/code&gt;是如何作为返回值的。 同样需要注意到函数如何比较&lt;code&gt;err&lt;/code&gt;变量与&lt;code&gt;EOF&lt;/code&gt;变量的。&lt;/p&gt;

&lt;p&gt;在你自己写的API中，创建错误类型变量，需要考虑是否有必要自己是实现，这也能使你提升错误处理的能力。&lt;/p&gt;

&lt;h3 id=&#34;为何不是值类型&#34;&gt;为何不是值类型&lt;/h3&gt;

&lt;p&gt;这里，也许会想到一个问题，为啥Go语言的设计者不直接设计一个&lt;code&gt;errString&lt;/code&gt;的值类型，而是使用结构类型？&lt;/p&gt;

&lt;p&gt;值类型可以定义为如下方式：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type errorString string
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结构类型定位为如下方式：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type errorString struct {
 s string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面给出命名类型的具体实现例子：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.15&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;01 package main
02 
03 import (
04     &amp;quot;errors&amp;quot;
05     &amp;quot;fmt&amp;quot;
06 )
07
08 // Create a named type for our new error type.
09 type errorString string
10
11 // Implement the error interface.
12 func (e errorString) Error() string {
13     return string(e)
14 }
15
16 // New creates interface values of type error.
17 func New(text string) error {
18     return errorString(text)
19 }
20
21 var ErrNamedType = New(&amp;quot;EOF&amp;quot;)
22 var ErrStructType = errors.New(&amp;quot;EOF&amp;quot;)
23
24 func main() {
25     if ErrNamedType == New(&amp;quot;EOF&amp;quot;) {
26         fmt.Println(&amp;quot;Named Type Error&amp;quot;)
27     }
28
29     if ErrStructType == errors.New(&amp;quot;EOF&amp;quot;) {
30         fmt.Println(&amp;quot;Struct Type Error&amp;quot;)
31     }
32 } 

Output:
Named Type Error
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1.15 提供了简单的示例，显示了&lt;code&gt;errorString&lt;/code&gt;作为值类型的错误使用。在09行声明了一个&lt;code&gt;string&lt;/code&gt;的值类型，在12行，&lt;code&gt;error&lt;/code&gt;接口通过命名类型是吸纳。在17行实行了&lt;code&gt;New&lt;/code&gt;函数定义。&lt;/p&gt;

&lt;p&gt;在21和22行，定义、初始化了两种不同类型的变量。分别通过&lt;code&gt;New&lt;/code&gt;函数和 &lt;code&gt;errors.New&lt;/code&gt;函数进行初始化。最后，在&lt;code&gt;main()&lt;/code&gt;函数中，与相同的方式创建的变量进行了比较。&lt;/p&gt;

&lt;p&gt;当你运行这段代码时，得到了上述有趣的结果。25行&lt;code&gt;if&lt;/code&gt;条件成立，而29行&lt;code&gt;if&lt;/code&gt;条件不成立。通过使用命名类型，我们能够创建&lt;code&gt;error&lt;/code&gt;类型值得接口，而且如果错误信息相同，那么就会匹配。这导致的问题其实和1.12l类似，因为我们能够创建自己的&lt;code&gt;error&lt;/code&gt;值，并且使用它们。如果是通过值类型创建的&lt;code&gt;error&lt;/code&gt;，那么包的作者改变错误消息的话，我们的代码判断就出问题了。&lt;/p&gt;

&lt;p&gt;同样我们也能通过&lt;code&gt;errorString&lt;/code&gt;的结构体类型复现上面的问题，只要接受者为值(T, 而不是 *T), 实现&lt;code&gt;error&lt;/code&gt;接口如下：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1.16&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;01 package main
02
03 import (
04    &amp;quot;fmt&amp;quot;
05 )
06
07 type errorString struct {
08    s string
09 }
10
11 func (e errorString) Error() string {
12    return e.s
13 }
14
15 func NewError(text string) error {
16    return errorString{text}
17 }
18
19 var ErrType = NewError(&amp;quot;EOF&amp;quot;)
20
21 func main() {
22    if ErrType == NewError(&amp;quot;EOF&amp;quot;) {
23        fmt.Println(&amp;quot;Error:&amp;quot;, ErrType)
24    }
25 } 

Output:
Error: EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在listing 1.16中，我们实现了&lt;code&gt;errorString&lt;/code&gt;的结构体类型，该类型对于&lt;code&gt;error&lt;/code&gt;接口的实现用的接受者是 &lt;code&gt;errorString&lt;/code&gt;, 而非&lt;code&gt;* errorString&lt;/code&gt;. 这一次得到的结果正如 listing 1.15 一样，&lt;strong&gt;&lt;em&gt;他们真正比较的其实是具体类型中的值&lt;/em&gt;&lt;/strong&gt;。11-13行代码 可以与 listing 1.9 进行比较，值得回味哈。&lt;/p&gt;

&lt;p&gt;在标准库中，** 使用&lt;code&gt;* errorString&lt;/code&gt;作为&lt;code&gt;error&lt;/code&gt;接口的实现的接受者 ** ，&lt;code&gt;errors.New&lt;/code&gt;函数强制返回了指针值， 这个指针就是绑定接口的值，并且每次调用都是指向同一个对象。这种情况下比较的其实是指针的值，而不是真正的错误消息。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;该篇文章中，我们初步理解了&lt;code&gt;error&lt;/code&gt;接口是什么，如何与&lt;code&gt;errorString&lt;/code&gt;结构相结合的。 通过&lt;code&gt;errors.New&lt;/code&gt;和&lt;code&gt;fmt.Errorf&lt;/code&gt;函数来创建&lt;code&gt;error&lt;/code&gt;类型的接口值，这种方式是非常普遍并且也是强烈推荐的。&lt;/p&gt;

&lt;p&gt;我们也可以暴露（对外能否访问）我们定义的&lt;code&gt;error&lt;/code&gt;类型的接口值（通常是标准库定义的），它能够通过API调用返回，帮助我们识别不同的错误信息。很多标准库的包中创建了这些对外可以访问的&lt;code&gt;error&lt;/code&gt;变量，这些通常已经提供了足够的识粒度来区分不同的错误信息。&lt;/p&gt;

&lt;p&gt;有时我们需要自己创建合理的&lt;code&gt;error&lt;/code&gt;类， 这些将会在第二部分中讲述。现在，请使用标准库提供的支持来处理错误吧！&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>golang参数传递</title>
          <link>https://maodanp.github.io/2016/03/15/using-pointers-in-go/</link>
          <pubDate>Tue, 15 Mar 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/03/15/using-pointers-in-go/</guid>
          <description>&lt;p&gt;以前在C/C++中，都知道传参时何时传值、指针、引用。那在Golang中的规则又是怎样的呢？对于参数传递是否有统一的规范呢？本文翻译自&lt;a href=&#34;https://www.goinggo.net/2014/12/using-pointers-in-go.html&#34;&gt;Using Pointers In *Go&lt;/a&gt;，作者总结出的方法一定让你受益匪浅。&lt;/p&gt;

&lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;

&lt;p&gt;在Go语言编程中，经常会遇到何时使用、何时不适用指针的问题。 绝大多数人都是基于他们的一个想法：权衡是否能够通过指针提高程序的性能。因此&lt;strong&gt;大家都朝着性能方面去考虑代码中是否使用指针，并不是从代码的习惯用法、简洁性、可读性以及合理性去考虑的&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;我对于指针的使用原则，基于的是标准库中指针的使用。当然下面说的这些规则也有例外的情况，但是这篇文章需要展示的是普遍的规则。本文通过区分传递的值类型说起，这些类型包括Go内置类型，结构体以及引用类型。让我们开始逐个说明吧。&lt;/p&gt;

&lt;h3 id=&#34;内置类型&#34;&gt;内置类型&lt;/h3&gt;

&lt;p&gt;Go的&lt;a href=&#34;https://golang.org/ref/spec#Types&#34;&gt;内置类型&lt;/a&gt;代表的是原生的数据，他们也是代码编写的基石。这些内置类型主要包括：布尔类型、数字类型以及字符串类型。当我们声明函数或者方法时，一般传递的是这些类型的值，标准库中很少通过指针传递它们。&lt;/p&gt;

&lt;p&gt;让我们看下&lt;code&gt;env&lt;/code&gt;包中的&lt;code&gt;isShellSpecialVar&lt;/code&gt;函数：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 1&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/os/env.go

38 func isShellSpecialVar(c uint8) bool {
39     switch c {
40     case ‘*’, ‘#’, ‘$’, ‘@’, ‘!’, ‘?’, ‘0’, ‘1’, ‘2’, ‘3’, ‘4’, ‘5’, ‘6’, ‘7’, ‘8’, ‘9’:
41         return true
42     }
43     return false
44 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 1中，&lt;code&gt;isShellSpecialVar&lt;/code&gt;函数接受一个&lt;code&gt;uint8&lt;/code&gt;类型的值，返回一个&lt;code&gt;bool&lt;/code&gt;类型的值。对于调用者而言，他们必须给这个函数传递一个&lt;code&gt;uint8&lt;/code&gt;类型的值，同样返回的也是一个&lt;code&gt;bool&lt;/code&gt;类型的值。&lt;/p&gt;

&lt;p&gt;下面，我们看下&lt;code&gt;env&lt;/code&gt;包中的&lt;code&gt;getShellName&lt;/code&gt;函数：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 2&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/os/env.go

54 func getShellName(s string) (string, int) {
55     switch {
56     case s[0] == ‘{’:
           …
66         return &amp;quot;&amp;quot;, 1 // Bad syntax; just eat the brace.
67     case isShellSpecialVar(s[0]):
68         return s[0:1], 1
69     }
       …
74     return s[:i], i
75 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 2中，&lt;code&gt;getShellName&lt;/code&gt;函数接受一个&lt;code&gt;string&lt;/code&gt;类型的值，同时返回了两个值：一个是&lt;code&gt;string&lt;/code&gt;类型；另一个是&lt;code&gt;int&lt;/code&gt;类型。&lt;code&gt;string&lt;/code&gt;类型的值是一个内置的类型，它代表了一部分固定不变的字节数。因为这部分是不可增长的，值得容量与切片头(&lt;a href=&#34;https://www.goinggo.net/2013/08/understanding-slices-in-go-programming.html&#34;&gt;slice header&lt;/a&gt;)不存在关联。&lt;/p&gt;

&lt;p&gt;当调用者调用&lt;code&gt;getShellName&lt;/code&gt;函数时，需要传递一份&lt;code&gt;string&lt;/code&gt;类型值的拷贝，然后函数会产生一份新的string值返回给调用者。所有的所要传递的输入输出的值都是需要进行拷贝的。&lt;/p&gt;

&lt;p&gt;这种&lt;code&gt;string&lt;/code&gt;类型值得拷贝在&lt;code&gt;strings&lt;/code&gt;包中是很常见的：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 3&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/strings/strings.go

620 func Trim(s string, cutset string) string {
621     if s == &amp;quot;&amp;quot; || cutset == &amp;quot;&amp;quot; {
622         return s
623     }
624     return TrimFunc(s, makeCutsetFunc(cutset))
625 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;strings&lt;/code&gt;包中很多函数，都会接受一份调用者的string值的拷贝，然后返回函数内部常见的string值得拷贝给调用者。Listing 3中展示了&lt;code&gt;Trim&lt;/code&gt;函数的实现， 该函数接受了两个string值得拷贝，然后返回一个拷贝（这个拷贝可能是第一个形参，可能是截取后的新的string)。&lt;/p&gt;

&lt;p&gt;如果你查看标准库中的代码，会发现这些内置类型的值很少会传指针，基本都是直接传递值得拷贝。如果一个函数或方法需要改变内置类型的值，那么改变后的新的值通常回座位返回值返回给调用者。&lt;/p&gt;

&lt;p&gt;总之，不要通过指针来传递内置类的值。&lt;/p&gt;

&lt;h3 id=&#34;结构体类型&#34;&gt;结构体类型&lt;/h3&gt;

&lt;p&gt;结构体能够通过组合不同的类型，创建出复杂的数据类型。通过组合一系列的字段，每个字段都有一个名称和类型。当然，结构体也支持匿名组合方式，嵌入结构体类型。&lt;/p&gt;

&lt;p&gt;结构体类型能够实现类似内置类型的功能。我们可以通过标准库的&lt;code&gt;time&lt;/code&gt;包，看到结构体扮演的原生数据值（primitive data value）:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 4&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/time/time.go

39 type Time struct {
40     // sec gives the number of seconds elapsed since
41     // January 1, year 1 00:00:00 UTC.
42     sec int64
43
44     // nsec specifies a non-negative nanosecond
45     // offset within the second named by Seconds.
46     // It must be in the range [0, 999999999].
47     nsec int32
48
49     // loc specifies the Location that should be used to
50     // determine the minute, hour, month, day, and year
51     // that correspond to this Time.
52     // Only the zero Time has a nil Location.
53     // In that case it is interpreted to mean UTC.
54     loc *Location
55 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 4 shows the Time struct type. This type represents time and has been implemented to behave as a primitive data value. If you look at the factory function Now, you will see it returns a value of type Time, not a pointer:&lt;/p&gt;

&lt;p&gt;Listing 4展示了&lt;code&gt;Time&lt;/code&gt;结构类型。这个类型代表了时间，作为原生数据值实现的。下面的&lt;code&gt;Now&lt;/code&gt;函数，返回了&lt;code&gt;Time&lt;/code&gt;类型的值，而非指针：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 5&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/time/time.go

781 func Now() Time {
782     sec, nsec := now()
783     return Time{sec + unixToInternal, nsec, Local}
784 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 5 shows how the Now function returns a value of type Time. This is an indication that values of type Time are safe to copy and is the preferred way to share them. Next, let’s look at a method that is used to change the value of a Time value:&lt;/p&gt;

&lt;p&gt;Listing 5 展示了返回&lt;code&gt;Time&lt;/code&gt;类型的&lt;code&gt;Now&lt;/code&gt;函数。这个函数说明了&lt;code&gt;Time&lt;/code&gt;类型的值返回时安全的，也是首选的方式。接下来，让我们看下我们如何通过&lt;code&gt;Time&lt;/code&gt;的方法来改变内部值的：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 6&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/time/time.go

610 func (t Time) Add(d Duration) Time {
611     t.sec += int64(d / 1e9)
612     nsec := int32(t.nsec) + int32(d%1e9)
613     if nsec &amp;gt;= 1e9 {
614         t.sec++
615         nsec -= 1e9
616     } else if nsec &amp;lt; 0 {
617         t.sec–
618         nsec += 1e9
619     }
620     t.nsec = nsec
621     return t
622 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正如我们知道的，内置类型是通过值传递并作为返回的。Listing 6展示了如何通过调用&lt;code&gt;Add&lt;/code&gt;方法，来解决&lt;code&gt;Time&lt;/code&gt;的值拷贝问题的。这个方法改变了接受者为值类型的局部变量，然后&lt;strong&gt;返回给调用者这个改变后值的拷贝&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 7&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/time/time.go

1118 func div(t Time, d Duration) (qmod2 int, r Duration) {

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 7声明了&lt;code&gt;div&lt;/code&gt;函数，它接收&lt;code&gt;Time&lt;/code&gt;和&lt;code&gt;Duration&lt;/code&gt;类型的值。这里再次说明下，&lt;code&gt;Time&lt;/code&gt;类型的值当做了原生数据类型，通过值来传递。&lt;/p&gt;

&lt;p&gt;但是大部分时候，结构体类型就不能当做原生数据类型了，在这些情况下，通过传值得指针会是更佳的选择。让我们看下&lt;code&gt;os&lt;/code&gt;包中的示例：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 8&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/os/file.go

238 func Open(name string) (file *File, err error) {
239     return OpenFile(name, O_RDONLY, 0)
240 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 8中，我们能够看到&lt;code&gt;os&lt;/code&gt;包中的&lt;code&gt;Open&lt;/code&gt;函数， 它打开了可读的文件，然后返回了&lt;code&gt;File&lt;/code&gt;类型值的指针。下面，我们看看这个&lt;code&gt;File&lt;/code&gt;结构在UNIX平台下的类型声明：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 9&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/os/file_unix.go

15 // File represents an open file descriptor.
16 type File struct {
17     *file
18 }
19
20 // file is the real representation of *File.
21 // The extra level of indirection ensures that no clients of os
22 // can overwrite this data, which could cause the finalizer
23 // to close the wrong file descriptor.
24 type file struct {
25     fd int
26     name string
27     dirinfo *dirInfo // nil unless directory being read
28     nepipe int32 // number of consecutive EPIPE in Write
29 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面关于&lt;code&gt;File&lt;/code&gt;的注释很好的说明了一点。当你有个像&lt;code&gt;Open&lt;/code&gt;那样的的工厂函数（factory function），它提供给你一个指针，它在提示你不能够创建这个返回值得拷贝。&lt;code&gt;Open&lt;/code&gt;返回一个指针，因为如果将涉及的&lt;code&gt;File&lt;/code&gt;值的拷贝返回，那将是不安全的。这个&lt;code&gt;File&lt;/code&gt;值应该通过指针拷贝及使用。&lt;/p&gt;

&lt;p&gt;Even if a function or method is not changing the state of a File struct type value, it still needs to be shared with a pointer. Let’s look at the epipecheck function from the os package for the UNIX platform:&lt;/p&gt;

&lt;p&gt;即使有函数或方法没有改变&lt;code&gt;File&lt;/code&gt;结构类型值，它仍然需要通过指针方式使用。下面我们看下&lt;code&gt;os&lt;/code&gt;包，UNIX平台下的&lt;code&gt;epipecheck&lt;/code&gt;函数的定义：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 10&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/os/file_unix.go

58 func epipecheck(file *File, e error) {
59     if e == syscall.EPIPE {
60         if atomic.AddInt32(&amp;amp;file.nepipe, 1) &amp;gt;= 10 {
61             sigpipe()
62         }
63     } else {
64         atomic.StoreInt32(&amp;amp;file.nepipe, 0)
65     }
66 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在Listing 10中，&lt;code&gt;epipecheck&lt;/code&gt;函数接受了一个&lt;code&gt;File&lt;/code&gt;类型的指针。调用者因此能够通过指针共享&lt;code&gt;File&lt;/code&gt;类型的值。注意到&lt;code&gt;epipecheck&lt;/code&gt;函数并不能改变&lt;code&gt;File&lt;/code&gt;值得状态，但是能够通过它执行操作。&lt;/p&gt;

&lt;p&gt;这种应用方式在&lt;code&gt;File&lt;/code&gt;类型的其他函数声明中也能够看到：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 11&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/os/file.go

224 func (f *File) Chdir() error {
225     if f == nil {
226         return ErrInvalid
227     }
228     if e := syscall.Fchdir(f.fd); e != nil {
229         return &amp;amp;PathError{&amp;quot;chdir&amp;quot;, f.name, e}
230     }
231     return nil
232 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 11的&lt;code&gt;Chdir&lt;/code&gt;方法中，通过接受者为指针来是实现了&lt;code&gt;Chdir&lt;/code&gt;方法，但是并没有改变接受者值的状态。以上所有示例中，都是传递&lt;code&gt;File&lt;/code&gt;类型的指针来实现共享的。一个&lt;code&gt;File&lt;/code&gt;类型值并不是一个原生数据类型。&lt;/p&gt;

&lt;p&gt;如果你阅读标准库中更多的代码，你将会看到如何传递结构类型的，可以像内置类型一样当原生类型使用，也可以通过指针实现共享。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;总之，对于结构类型值通过指针传递，除非结构类型的行为类似原生数据类型&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果你还不确定，这里提供另一种思考方式。可以将每个结构看做一个自然。如果结构体本质上不能够改变，像时间、颜色或者坐标，那么就把结构体当做原生数据类型。如果结构体本质山是可以改变的东西，即使它在你的代码中从来没变化过，它就不能当做原生数据类型，而应该通过指针传递，我们不能够创建具有二义性的结构体。&lt;/p&gt;

&lt;h3 id=&#34;引用类型&#34;&gt;引用类型&lt;/h3&gt;

&lt;p&gt;引用类型包括切片、映射、管道、接口以及函数等。这些值包含头节点，头节点会通过指针指向潜在的数据结构以及其他的元数据。我们很少传递引用类型的指针，因为这些头节点本来就是设计成允许拷贝的。我们来看下&lt;code&gt;net&lt;/code&gt;包中的示例：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 12&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/net/ip.go

type IP []byte
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 12中，我们能够看到一个成为&lt;code&gt;IP&lt;/code&gt;的命名类型，它实际的类型是一个字节类型的切片。当你需要声明一个内置内省或者引用类型，一般都使用它们的值传递。让我们看下&lt;code&gt;IP&lt;/code&gt;命名类型下的&lt;code&gt;MarshalText&lt;/code&gt;方法：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 13&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/net/ip.go

329 func (ip IP) MarshalText() ([]byte, error) {
330     if len(ip) == 0 {
331         return []byte(&amp;quot;&amp;quot;), nil
332     }
333     if len(ip) != IPv4len &amp;amp;&amp;amp; len(ip) != IPv6len {
334         return nil, errors.New(&amp;quot;invalid IP address&amp;quot;)
335     }
336     return []byte(ip.String()), nil
337 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 13中，我们能够看到&lt;code&gt;MarshalText&lt;/code&gt;方法如何使用值类型的接受者的，这里并没有使用引用类型的指针作为接受者。我们能够给函数或方法传引用类型的值：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 14&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/net/ip.go

318 // ipEmptyString is like ip.String except that it returns
319 // an empty string when ip is unset.
320 func ipEmptyString(ip IP) string {
321     if len(ip) == 0 {
322         return &amp;quot;&amp;quot;
323     }
324     return ip.String()
325 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 14中，&lt;code&gt;ipEmptyString&lt;/code&gt;函数接受了&lt;code&gt;IP&lt;/code&gt;命名类型的值。因为&lt;code&gt;IP&lt;/code&gt;的基本类型是字节数切片，是一个引用类型，因此我们不需要通过指针来共享。&lt;/p&gt;

&lt;p&gt;但是对于&lt;strong&gt;不要通过引用类型的指针来共享&lt;/strong&gt;这条规则，有个例外：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 15&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://golang.org/src/net/ip.go

341 func (ip *IP) UnmarshalText(text []byte) error {
342     if len(text) == 0 {
343         *ip = nil
344         return nil
345     }
346     s := string(text)
347     x := ParseIP(s)
348     if x == nil {
349         return &amp;amp;ParseError{&amp;quot;IP address&amp;quot;, s}
350     }
351     *ip = x
352     return nil
353 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;任何时候，当你要将数据解码成引用类型时，你需要通过引用类型的&lt;strong&gt;指针共享&lt;/strong&gt;，而不能通过&lt;strong&gt;值共享&lt;/strong&gt;。Listing15显示了&lt;code&gt;UnmarshalText&lt;/code&gt;方法的实现，它的接受者为指针类型，以实现解码操作。&lt;/p&gt;

&lt;p&gt;当你阅读更多的标准库代码时，你将会看到引用类型的值在大多数情况下都是值共享的。因为引用类型包括头结点，能够共享头结点指向的数据结构。这个思想有点类似C/C++中指针的传递，我们在对指针指向对象初始化时，需要传递二级指针，其他情况下我们一般只要传递指针就行了。&lt;/p&gt;

&lt;p&gt;总之，不要通过引用类型的指针来共享，除非你需要实现解码类型的功能。&lt;/p&gt;

&lt;h3 id=&#34;值的切片&#34;&gt;值的切片&lt;/h3&gt;

&lt;p&gt;有一件事需要说明，当我(作者)在从数据库、网络或者文件中获取数据时，将这些数据存储在了切片中：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Listing 16&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10 func FindRegion(s *Service, region string) ([]BuoyStation, error) {
11     var bs []BuoyStation
12     f := func(c *mgo.Collection) error {
13         queryMap := bson.M{&amp;quot;region&amp;quot;: region}
14         return c.Find(queryMap).All(&amp;amp;bs)
15     }
16
17     if err := s.DBAction(cfg.Database, &amp;quot;buoy_stations&amp;quot;, f); err != nil {
18         return nil, err
19     }
20
21     return bs, nil
22 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing 16中，通过&lt;code&gt;mgo&lt;/code&gt;包去访问MongoDB数据库。在14行，传递给&lt;code&gt;All&lt;/code&gt;方法的是&lt;code&gt;bs&lt;/code&gt;切片的指针地址。&lt;code&gt;All&lt;/code&gt;方法实际执行的是解码方法，来创建切片的值。当使用切片的值时，能够允许程序中的数据以连续的块存储在内存中。这意味着更多的核心数据能够被CPU缓存存储，能够在缓存中保存较长的时间。而如果创建的是群拍你的指针，却不能保证这些核心数据在内存中能够连续存储，而是指向这些数据的&lt;strong&gt;指针&lt;/strong&gt;能够连续存储。&lt;/p&gt;

&lt;p&gt;总之，当你编写自己的代码时，尽可能传递引用类型的值而非指针。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;基于值类型来共享/传递这种思想，在标准库中是相当一致的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不要使用内置数据类型的指针除非你有其他需求&lt;/li&gt;
&lt;li&gt;结构体具有二义性，如果结构体类型作为原生数据类型使用，就不需要使用指针；如果不是就使用指针&lt;/li&gt;
&lt;li&gt;引用类型不应该通过指针传递，极少情况是需要用指针的（解码）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在结束本篇文章之前，再重申三点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;在写代码时，要考虑习惯用法、简洁性、可读性以及合理性&lt;/li&gt;
&lt;li&gt;这无关乎对错，要多考虑代码背后的合理性&lt;/li&gt;
&lt;li&gt;将每种情况看做个例看待，并不只是一种解决方案&lt;/li&gt;
&lt;/ol&gt;</description>
        </item>
      
    
      
        <item>
          <title>程序猿的自我修养 — 直面问题</title>
          <link>https://maodanp.github.io/2016/03/10/face-problem/</link>
          <pubDate>Thu, 10 Mar 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/03/10/face-problem/</guid>
          <description>&lt;p&gt;程序员是与机器打交道的，机器识别的是二进制，不知道变通。所以，业务上任何逻辑、语法、性能等等问题都是家常便饭。问题可大可小，轻者内心嘀咕几句，自己debug；重者猛砸键盘鼠标，口爆粗语。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-03-10-face-problem.jpg&#34; alt=&#34;标题图片&#34; /&gt;&lt;/p&gt;

&lt;p&gt;生活在程序员的环境中，经常能听到 “这不知是问题”，“你看我的打印都正常的”，“见鬼了，之前没出现过这个问题的” 。。。。。。&lt;/p&gt;

&lt;h3 id=&#34;逃避-or-迎接困难&#34;&gt;逃避 or 迎接困难&lt;/h3&gt;

&lt;p&gt;各人遇到问题时的反应都不一样, 但大致两种，直面困难者与逃避困难者。其实困难恰恰是我们技术是否进步的风水岭。&lt;/p&gt;

&lt;p&gt;为问题而付出努力者，内心有对技术的强烈苛求，会释放内心巨大的潜力，尽可能将问题解决。此类性格会初始程序猿不断成长，从初级到高级、资深、骨灰级。但是人性的弱点决定大多数人都是有惰性的，害怕问题的。潜意识中是畏惧的，这是人原始的想法，但是心理成熟的人、经验丰富的人却很快能调整心态，去定位、解决问题。&lt;/p&gt;

&lt;p&gt;Benjamin Franklin说过:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;“唯有痛苦才会带来教益”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;但大多数似乎都害怕承受，遇到稍微棘手的bug会赶到自己无能为力，会怀疑自己。面对困难，有些是尽量推脱，将问题推给他人解决；有些则是置之不理，不在乎它们的存在（如果领导不催促的话, 否则自行想象后果）。这种心态、处理问题的态度是不利于自身成长的，特别是在技术更新日新月异的今天。&lt;/p&gt;

&lt;p&gt;美国一位作家曾经说过: &lt;code&gt;你不能解决问题，你就会成为问题&lt;/code&gt;。 对于职场而言则更是如此。如果属于你的问题却解决不了，或者逃避解决，反复多次，就会面临被解雇的风险(体制内的除外)。&lt;/p&gt;

&lt;p&gt;解决办法唯有以积极而主动的态度去迎接困难，Just do it！&lt;/p&gt;

&lt;h3 id=&#34;承担责任&#34;&gt;承担责任&lt;/h3&gt;

&lt;p&gt;如果对待问题避之唯恐不及，那么难题依然如山一样横亘在我们面前；请教别人解决，一两次还行，次数多了就会让人生厌了，唯有承担得起这份责任, 才能得到老板的认（jia）可(xin)。不畏困难，将难题先消灭，不拖沓，不逃避。&lt;/p&gt;

&lt;p&gt;不承担自身应付的责任，也就意味着将提升自我技术能力的机会让给了别人。对自身而言，即失去了进步的机会，也增加了团队对你的一份能力怀疑。要为程序员自己代言，不放弃任何机会，不逃避任何问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;要相信办法总比问题多，而且多得多。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;心态平衡&#34;&gt;心态平衡&lt;/h3&gt;

&lt;p&gt;我们需要保持好心态的平衡。遇到问题不急躁，有病乱投医不是好的解决方式。需要冷静分析，缩小问题的定位范围，而不是忙不的如无头苍蝇乱撞。&lt;/p&gt;

&lt;p&gt;《少有人走的路》中有这么一段话：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;作为成年人，整个一生都充满着选择和决定的机会。他们接受这一事实，就会变成自由的人；无法接受这种事实，永远都会感到自己是个牺牲品。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;希望上述大家能够共勉，无论是否何种行业，何种处境，积极应对困难，才是积极的人生态度。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>理解golang中的切片</title>
          <link>https://maodanp.github.io/2016/03/01/understanding-slices-in-go-programming/</link>
          <pubDate>Tue, 01 Mar 2016 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2016/03/01/understanding-slices-in-go-programming/</guid>
          <description>&lt;p&gt;Golang的初学者有时会被slice所困扰，不理解其内部原理，使用起来总是担心是否有复制的开销。 本文翻译自&lt;a href=&#34;https://www.goinggo.net/2013/08/understanding-slices-in-go-programming.html&#34;&gt;Understanding Slices in Go Programming&lt;/a&gt;，作者对其内部原理作了深入分析。相信读完将会有不一样的感受。&lt;/p&gt;

&lt;p&gt;因为我常常被Go语言中Slices(切片)的概念和使用所困扰，它像数组，但又不仅仅是数组。我阅读了很多有关Slices的文章，现在我认为是时候谈谈我对Slices的理解了。&lt;/p&gt;

&lt;p&gt;这里有一篇Andrew Gerrand所写的关于切片的&lt;a href=&#34;http://blog.golang.org/go-slices-usage-and-internals&#34;&gt;文章&lt;/a&gt;。因为这里没必要重复Andrew所讲过的内容，所以阅读下面的文章之前，请先阅读下他的文章。&lt;/p&gt;

&lt;p&gt;下面让我们直接看看切片的内部结构吧：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-03-01-understanding-slices-in-go-programming-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上面的图片展示了一个slice的内部结构。&lt;strong&gt;当你创建一个切片时，那么该切片的数据以及所隐含的数组也同样被创建了&lt;/strong&gt;。你创建的切片变量的值将会是这个数据结构，且当你将切片传递给一个函数时，将会在函数栈中创建这个数据结构的拷贝。&lt;/p&gt;

&lt;p&gt;我们有两种方式来创建一个切片：&lt;/p&gt;

&lt;p&gt;这里我们通过&lt;code&gt;make&lt;/code&gt;关键字创建了一个切片，并且将切片中存储的数据类型、切片初始化的长度、隐含数组的容量都当做参数传递给了&lt;code&gt;make&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mySlice := make([]string, 5, 8)
mySlice[0] = &amp;quot;Apple&amp;quot;
mySlice[1] = &amp;quot;Orange&amp;quot;
mySlice[2] = &amp;quot;Banana&amp;quot;
mySlice[3] = &amp;quot;Grape&amp;quot;
mySlice[4] = &amp;quot;Plum&amp;quot; 

// You don’t need to include the capacity. Length and Capacity will be the same
mySlice := make([]string, 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们也能够通过逐个元素来创建切片。这种情况下，切片的长度和容量是相同的。需要注意这里在&lt;code&gt;[]&lt;/code&gt;中没有具体的数。如果你添加了，那将会变成数组了。不添加，则创建的是切片：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mySlice := []string{&amp;quot;Apple&amp;quot;, &amp;quot;Orange&amp;quot;, &amp;quot;Banana&amp;quot;, &amp;quot;Grape&amp;quot;, &amp;quot;Plum&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一旦切片创建了，我们就不能扩展它的容量了。唯一改变切片容量的方式是创建一个新的切片，然后执行拷贝操作。&lt;code&gt;Andrew&lt;/code&gt;在文章中提到了一个简单函数来检测切片的剩余容量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;切片的长度&lt;/strong&gt;表示的是隐含数组中，从起始索引开始的实际元素的个数； &lt;strong&gt;切片的容量&lt;/strong&gt;表示我们能够利用的元素个数。&lt;/p&gt;

&lt;p&gt;我们能够从原始切片中创建一个新的切片：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;newSlice := mySlice[2:4]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-03-01-understanding-slices-in-go-programming-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://play.golang.org/p/OGFZgT4Y_n&#34;&gt;新切片&lt;/a&gt;指针变量的值关联了原来隐含数组的索引位置2和3。对于新的切片而言，我们现在有包含3个元素的隐含数组，我们仅仅用了其中的两个。这里新切片对隐含数组中的前两个位置的元素是不知道的，并且永远也不会用到。&lt;/p&gt;

&lt;p&gt;当执行切片操作时，第一个元素指定了从切片指针变量位置开始的索引。在上面的例子中，我们说从第二个索引（对应隐含数组中的第3个元素）开始取切片元素。第二个参数是最后索引位置+1的值，我们说新的切片结束位置索引号为3。&lt;/p&gt;

&lt;p&gt;当然，我们在执行切片操作是，不需要经常指定起始或者结束位置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;newSlice2 = newSlice[:cap(newSlice)]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-03-01-understanding-slices-in-go-programming-3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在这个示例中，我们利用&lt;code&gt;newSlice&lt;/code&gt;创建了第三个新的切片。我们没有指定起始的索引，但是指定了结束索引的位置。&lt;code&gt;newSlice2&lt;/code&gt;与&lt;code&gt;newSlice&lt;/code&gt;比较，有相同的起始位置，以及容量，但是长度却发生了变化。通过将&lt;code&gt;newSlice&lt;/code&gt;的容量大小作为&lt;code&gt;newSlice2&lt;/code&gt;的结束索引，那么&lt;code&gt;newSlice2&lt;/code&gt;将使用隐含数组的所有剩余的元素。&lt;/p&gt;

&lt;p&gt;下面我们来运行一段&lt;a href=&#34;https://play.golang.org/p/XPRU0D0H1N&#34;&gt;程序&lt;/a&gt;，来证明这种数据结构的确是存在的，并且切片也是按照我们所预想的运行的。下面的程序通过观测内存地址，来观测切片：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func InspectSlice(slice []string) {
    // Capture the address to the slice structure
    address := unsafe.Pointer(&amp;amp;slice)

    // Capture the address where the length and cap size is stored
    lenAddr := uintptr(address) + uintptr(8)
    capAddr := uintptr(address) + uintptr(16)

    // Create pointers to the length and cap size
    lenPtr := (*int)(unsafe.Pointer(lenAddr))
    capPtr := (*int)(unsafe.Pointer(capAddr))

    // Create a pointer to the underlying array
    addPtr := (*[8]string)(unsafe.Pointer(*(*uintptr)(address)))

    fmt.Printf(&amp;quot;Slice Addr[%p] Len Addr[0x%x] Cap Addr[0x%x]\n&amp;quot;,
        address,
        lenAddr,
        capAddr)

    fmt.Printf(&amp;quot;Slice Length[%d] Cap[%d]\n&amp;quot;,
        *lenPtr,
        *capPtr)

    for index := 0; index &amp;lt; *lenPtr; index++ {
        fmt.Printf(&amp;quot;[%d] %p %s\n&amp;quot;,
            index,
            &amp;amp;(*addPtr)[index],
            (*addPtr)[index])
    }

    fmt.Printf(&amp;quot;\n\n&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;函数&lt;code&gt;InspectSlice&lt;/code&gt;进行了一系列的指针操作，以便我们能够看到切片的*数据结构*和*隐含数组*的内存和值的信息。&lt;/p&gt;

&lt;p&gt;后续我们将会一一拆分讲解，第一步，我们先来创建一个切片，然后通过&lt;code&gt;InspectSlice&lt;/code&gt;函数运行它：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;unsafe&amp;quot;
)

func main() {
    orgSlice := make([]string, 5, 8)
    orgSlice[0] = &amp;quot;Apple&amp;quot;
    orgSlice[1] = &amp;quot;Orange&amp;quot;
    orgSlice[2] = &amp;quot;Banana&amp;quot;
    orgSlice[3] = &amp;quot;Grape&amp;quot;
    orgSlice[4] = &amp;quot;Plum&amp;quot;

    InspectSlice(orgSlice)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面是程序的输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Slice Addr[0x2101be000] Len Addr[0x2101be008] Cap Addr[0x2101be010]
Slice Length[5] Cap[8]
[0] 0x2101bd000 Apple
[1] 0x2101bd010 Orange
[2] 0x2101bd020 Banana
[3] 0x2101bd030 Grape
[4] 0x2101bd040 Plum
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;InspectSlice&lt;/code&gt;函数，首先打印了前篇数据结构的地址，以及长度值、容量值所在的地址。然后通过根据这些地址创建的&lt;code&gt;int&lt;/code&gt;类型指针，打印出长度和容量的值。最后我们创建了一个指向隐含数组的指针。通过这个指针，我们遍历这个隐含数组，打印出索引值、每个元素的起始地址、以及每个元素的值。&lt;/p&gt;

&lt;p&gt;让我们将&lt;code&gt;InspectSlice&lt;/code&gt;函数拆分，逐个讲解它是如何工作的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Capture the address to the slice structure
address := unsafe.Pointer(&amp;amp;slice)

// Capture the address where the length and cap size is stored
lenAddr := uintptr(address) + uintptr(8)
capAddr := uintptr(address) + uintptr(16)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;unsafe.Pointer&lt;/code&gt;是一个特殊的类型，它能够映射到&lt;code&gt;uintptr&lt;/code&gt;类型。因为我们需要执行指针运算，我们需要得到真实的指针。代码段第一行将切片数据结构的地址强制转换成了&lt;code&gt;unsafe.Pointer&lt;/code&gt;，然后我们创建了两个普通指针，它们对数据结构地址分别进行了加8和加16的操作(&lt;strong&gt;注意：这里具体跟操作系统版本有关，32位系统分别加4加8&lt;/strong&gt;)。&lt;/p&gt;

&lt;p&gt;下面的图展示了每个指针变量，指针指向地址的值：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2016/2016-03-01-understanding-slices-in-go-programming-4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我们通过这些指针，能够转换成指定类型的指针，就能够显示指向的值了。这里我们创建了两个整型指针，以便于显示切片数据结构中的长度和容量的值。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Create pointers to the length and cap size
lenPtr := (*int)(unsafe.Pointer(lenAddr))
capPtr := (*int)(unsafe.Pointer(capAddr))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now need a pointer of type [8]string, which is the type of underlying array.&lt;/p&gt;

&lt;p&gt;现在我们需要获取&lt;code&gt;[8]string&lt;/code&gt;类型的指针，这也是隐含数组的类型：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Create a pointer to the underlying array
addPtr := (*[8]string)(unsafe.Pointer(*(*uintptr)(address)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这条语句中有很多的细节，我们拆分开来解析：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(*uintptr)(address) : 0x2101be000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这条语句表示获取切片数据结构的起始地址，然后强转成普通的指针。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* (*uintptr)(address) : 0x2101bd000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们就能够通过普通的指针获取到其中的值，这个值也就是指向隐含数组的起始地址值&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;unsafe.Pointer(*(*uintptr)(address))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们将隐含数组起始地址的值转换成&lt;code&gt;unsafe.Pointer&lt;/code&gt;类型，因为我们需要&lt;code&gt;unsafe.Pointer&lt;/code&gt;类型指针做最终的转换。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(*[8]string)(unsafe.Pointer(*(*uintptr)(address)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终，我们将&lt;code&gt;unsafe.Pointer&lt;/code&gt;类型转换成合适的指针类型(&lt;code&gt;[8]string&lt;/code&gt;类型)&lt;/p&gt;

&lt;p&gt;剩下的代码片段，通过合适的指针来显示数组中的值：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Printf(&amp;quot;Slice Addr[%p] Len Addr[0x%x] Cap Addr[0x%x]\n&amp;quot;,
    address,
    lenAddr,
    capAddr)

fmt.Printf(&amp;quot;Slice Length[%d] Cap[%d]\n&amp;quot;,
    *lenPtr,
    *capPtr)

for index := 0; index &amp;lt; *lenPtr; index++ {
    fmt.Printf(&amp;quot;[%d] %p %s\n&amp;quot;,
        index,
        &amp;amp;(*addPtr)[index],
        (*addPtr)[index])
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面，让我们将整个&lt;a href=&#34;https://play.golang.org/p/kXtJAQh7gw&#34;&gt;程序&lt;/a&gt;放在一起，创建很多个切片。我们将观察创建的每个切片以确保我们所知道的这些知识是正确的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;fmt&amp;quot;
    &amp;quot;unsafe&amp;quot;
)

func main() {
    orgSlice := make([]string, 5, 8)
    orgSlice[0] = &amp;quot;Apple&amp;quot;
    orgSlice[1] = &amp;quot;Orange&amp;quot;
    orgSlice[2] = &amp;quot;Banana&amp;quot;
    orgSlice[3] = &amp;quot;Grape&amp;quot;
    orgSlice[4] = &amp;quot;Plum&amp;quot;

    InspectSlice(orgSlice)

    slice2 := orgSlice[2:4]
    InspectSlice(slice2)

    slice3 := slice2[1:cap(slice2)]
    InspectSlice(slice3)

    slice3[0] = &amp;quot;CHANGED&amp;quot;
    InspectSlice(slice3)
    InspectSlice(slice2)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面是每个切片的输出结果，这里我们创建了一个长度为5、容量为8的切片：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Code:
orgSlice := make([]string, 5, 8)
orgSlice[0] = &amp;quot;Apple&amp;quot;
orgSlice[1] = &amp;quot;Orange&amp;quot;
orgSlice[2] = &amp;quot;Banana&amp;quot;
orgSlice[3] = &amp;quot;Grape&amp;quot;
orgSlice[4] = &amp;quot;Plum&amp;quot;

Output:
Slice Addr[0x2101be000] Len Addr[0x2101be008] Cap Addr[0x2101be010]
Slice Length[5] Cap[8]
[0] 0x2101bd000 Apple
[1] 0x2101bd010 Orange
[2] 0x2101bd020 Banana
[3] 0x2101bd030 Grape
[4] 0x2101bd040 Plum
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出结果正如我们所预期的那样。然后我们创建了变量&lt;code&gt;slice2&lt;/code&gt;，它包含两个元素，索引分别为2和3：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Code:
slice2 := orgSlice[2:4]
InspectSlice(slice2)

Output:
Slice Addr[0x2101be060] Len Addr[0x2101be068] Cap Addr[0x2101be070]
Slice Length[2] Cap[6]
[0] 0x2101bd020 Banana
[1] 0x2101bd030 Grape
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从对&lt;code&gt;slice2&lt;/code&gt;的输出中，我们看到它的长度和容量分别是2和6.因为该切片的起始位置对应，是&lt;code&gt;orgSlice&lt;/code&gt;的隐含数组中的第三个元素，索引只能够容纳下6个元素。&lt;code&gt;slice2&lt;/code&gt;的索引0对应&lt;code&gt;orgSlice&lt;/code&gt;的索引2.&lt;/p&gt;

&lt;p&gt;下面我们新建一个切片，起始位置为1，结束位置为&lt;code&gt;slice2&lt;/code&gt;的最后一个元素位置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Code:
slice3 := slice2[1:cap(slice2)]
InspectSlice(slice3)

Output:
Slice Addr[0x2101be0a0] Len Addr[0x2101be0a8] Cap Addr[0x2101be0b0]
Slice Length[5] Cap[5]
[0] 0x2101bd030 Grape
[1] 0x2101bd040 Plum
[2] 0x2101bd050
[3] 0x2101bd060
[4] 0x2101bd070
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正如我们所期望的，&lt;code&gt;slice3&lt;/code&gt;的长度和容量斗是。当你打印这个切片的所有值，你会发现最后三个元素没有值。因为当隐含数组被创建时，已经初始化了其中的所有值。你会看到&lt;code&gt;slice3&lt;/code&gt;的索引0对应&lt;code&gt;slice2&lt;/code&gt;的索引1，对应&lt;code&gt;orgSlice&lt;/code&gt;的索引3，他们的指针都是&lt;strong&gt;0x2101bd030&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;最后一段代码改变了&lt;code&gt;slice3&lt;/code&gt;中的第一个元素，即索引为0的值。然后我们看改变后&lt;code&gt;slice3&lt;/code&gt;和&lt;code&gt;slice2&lt;/code&gt;值的变化：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;slice3[0] = &amp;quot;CHANGED&amp;quot;
InspectSlice(slice3)
InspectSlice(slice2)

Slice Addr[0x2101be0e0] Len Addr[0x2101be0e8] Cap Addr[0x2101be0f0]
Slice Length[5] Cap[5]
[0] 0x2101bd030 CHANGED
[1] 0x2101bd040 Plum
[2] 0x2101bd050 
[3] 0x2101bd060 
[4] 0x2101bd070 


Slice Addr[0x2101be120] Len Addr[0x2101be128] Cap Addr[0x2101be130]
Slice Length[2] Cap[6]
[0] 0x2101bd020 Banana
[1] 0x2101bd030 CHANGED
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们看到两个切片在它们各种的索引上的值都发生了变化。这证明了所有切片都使用相同的隐含数组。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;InspectSlice&lt;/code&gt;函数证明了：每个切片都包含它们各自的数据结构（包含指向隐含数组的指针，切片的长度值，容量值）。花些时间创建更多的切片，然后利用&lt;code&gt;InspectSlice&lt;/code&gt;函数来证明你的假设吧！&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Linux防火墙</title>
          <link>https://maodanp.github.io/2015/07/07/linux-iptables/</link>
          <pubDate>Tue, 07 Jul 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2015/07/07/linux-iptables/</guid>
          <description>&lt;p&gt;在工作中常常涉及到防火墙的概念，基本网络不通或者服务无法连接首先就会想到是否是防火墙的原因。当然这里所说的防火墙是Linux系统内核继承的IP信息包过滤系统Netfiter/iptables。&lt;/p&gt;

&lt;h3 id=&#34;snat-dnat-masquerade&#34;&gt;SNAT、DNAT、MASQUERADE&lt;/h3&gt;

&lt;p&gt;了解Linux防火墙之前，需要对有些网络基础的概念有所了解。iptables能够灵活的做各种地址转换(NAT)，NAT主要又分为SNAT、DNAT。&lt;/p&gt;

&lt;p&gt;SNAT (source network address translation)，即源地址目标转换。内部地址要访问公网上的服务时（如web访问），内部地址会主动发起连接，由路由器或者防火墙上的网关对内部地址做个地址转换，将内部地址的私有IP转换为公网的公有IP，网关的这个地址转换称为SNAT，主要用于内部共享IP访问外部。&lt;/p&gt;

&lt;p&gt;DNAT (destination network address translation），即目标网络地址转换。当内部需要提供对外服务时（如对外发布web网站），外部地址发起主动连接，由路由器或者防火墙上的网关接收这个连接，然后将连接转换到内部，此过程是由带有公网IP的网关替代内部服务来接收外部的连接，然后在内部做地址转换，此转换称为DNAT，主要用于内部服务对外发布。&lt;/p&gt;

&lt;p&gt;MASQUERADE，地址伪装，在iptables中有着和SNAT相近的效果，但也有一些区别。使用SNAT的时候，出口ip的地址范围可以是一个，也可以是多个。MASQUERADE作用是，从服务器的网卡上，自动获取当前ip地址来做NAT，就不用手动指定转换的目的IP了，实现了动态的SNAT。&lt;/p&gt;

&lt;h3 id=&#34;linux防火墙的应用&#34;&gt;Linux防火墙的应用&lt;/h3&gt;

&lt;p&gt;Linux防火墙iptables的用途主要包括NAT路由、安全防护、透明代理等。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;企业或者网吧能够利用iptables作为企业的NAT路由器，代替传统的路由器供企业内部员工上网，节约成本并能有效控制&lt;/li&gt;
&lt;li&gt;提供外网到内网的IP映射，能够使得内部Web服务器对外提供服务，即DNAT&lt;/li&gt;
&lt;li&gt;iptables可以防止轻量级的DDOS攻击，如ping攻击以及SYN洪水攻击&lt;/li&gt;
&lt;li&gt;iptables可以结合squid作为内部上网的透明代理，不需要再浏览器里配置代理服务器信息，iptables+squid的透明代理可以将客户端的请求重定向到代理服务器的端口。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;netfilter-与-iptables&#34;&gt;Netfilter 与 iptables&lt;/h3&gt;

&lt;p&gt;Netfiter/iptables是IP信息包过滤系统的一个整体的两个模块。 Netfiter是内核的模块实现， iptables是上层的操作工具。&lt;/p&gt;

&lt;p&gt;Netfiter是Linux核心中的一个通用结构，它要么被直接编译进内核，要么被包含在模块中，运行在内核空间。&lt;/p&gt;

&lt;p&gt;iptables提供一些列的表，每个表由若干条链组成，每条链中可以由一条或薯条规则组成。 iptables是一个管理内核包过滤的工具，可以加入、插入或者删除核心包过滤表中的规则。它运行在用户控件，真正执行这些过滤规则的是Netfilter。&lt;/p&gt;

&lt;h3 id=&#34;网络数据的流向&#34;&gt;网络数据的流向&lt;/h3&gt;

&lt;p&gt;我们知道TCP/IP四层网络模型自下而上包括：链路层、网络层、传输层、应用层。在数据的发送过程中，从上至下依次是&lt;strong&gt;加头&lt;/strong&gt;的过程，每到达一层数据就被会加上该层的头部；与此同时，接受数据方就是个&lt;strong&gt;剥头&lt;/strong&gt;的过程，从网卡收上包来之后，在往协议栈的上层传递过程中依次剥去每层的头部，最终到达用户那儿的就是裸数据了。&lt;/p&gt;

&lt;p&gt;数据在网络协议栈中的基本流程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2015/2015-07-07-linux-iptables-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;对于收到的每个数据包，都从“A”点进来，经过路由判决，如果是发送给本机的就经过“B”点，然后往协议栈的上层继续传递；否则，如果该数据包的目的地是不本机，那么就经过“C”点，然后顺着“E”点将该包转发出去。&lt;/p&gt;

&lt;p&gt;对于发送的每个数据包，首先也有一个路由判决，以确定该包是从哪个接口出去，然后经过“D”点，最后也是顺着“E”点将该包发送出去。&lt;/p&gt;

&lt;p&gt;Netfilter是Linux 2.4.x引入的一个子系统，它作为一个通用的、抽象的框架，提供一整套的hook函数的管理机制，使得诸如数据包过滤、网络地址转换(NAT)和基于协议类型的连接跟踪成为了可能。Netfilter在内核中位置如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2015/2015-07-07-linux-iptables-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上图很直观的反应了用户空间的iptables和内核空间的基于Netfilter的iptables模块之间的关系和其通讯方式，以及Netfilter在这其中所扮演的角色。&lt;/p&gt;

&lt;p&gt;Netfilter在netfilter_ipv4.h中将这个五个点重新命了个名，如下图所示:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../../../pic/2015/2015-07-07-linux-iptables-3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;即对于数据包而言的几个流向分别为：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;PREROUTING &amp;ndash;&amp;gt; FORWARD &amp;ndash;&amp;gt; POSTROUTING&lt;/li&gt;
&lt;li&gt;PREROUTING &amp;ndash;&amp;gt; INPUT &amp;ndash;&amp;gt; OUTPUT &amp;ndash;&amp;gt; POSTROUTING&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上述两种主要流向就是iptables的两种工作模式：NAT路由、主机防火墙。&lt;/p&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/sdytlm/article/details/6544913/&#34;&gt;iptables介绍&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.chinaunix.net/uid-23069658-id-3160506.html&#34;&gt;洞悉linux下的Netfilter&amp;amp;iptables：什么是Netfilter？ &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://my.oschina.net/hevakelcj/blog/313212&#34;&gt;Linux下防火墙iptables设置&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.chinaunix.net/uid-21516619-id-1824942.html&#34;&gt;IPtables中SNAT、DNAT和MASQUERADE的区别&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/JemBai/archive/2009/03/19/1416364.html&#34;&gt;linux下IPTABLES配置详解&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;《构建高可用Linux服务器》 Ch8 Linx防火墙及系统安全&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>简单分布式服务器框架</title>
          <link>https://maodanp.github.io/2015/06/18/distrubuted-server/</link>
          <pubDate>Thu, 18 Jun 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2015/06/18/distrubuted-server/</guid>
          <description>&lt;p&gt;最近工作中接触到分布式服务器，现针对学到的作简要概述, 分布式服务器之路刚起步。&lt;/p&gt;

&lt;h3 id=&#34;整体框架&#34;&gt;整体框架&lt;/h3&gt;

&lt;p&gt;下面结合Hadoop的框架思想与工作中接触到的分布式框架，给出简易分布式服务器框架的设计。整体设计框架如下图所示：
&lt;img src=&#34;../../../../pic/2015/2015-06-18-distrubuted-server-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如上图示，可以将整体模块分为5个结构层次，分别为： 客户端层、JobTracker层、TaskTracker层、DBC/CloudC层、以及最后的 DB/Cloud层。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;客户端层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;该层即为客户端的web访问层，通过http访问JobTracker层。 web与JobTracker的具体协议可以协定，或者RPC/HTTP协议都可以。
客户端的主要完成工作请求、暂停、删除作业；获得作业的运行状态信息等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;JobTracker层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;该层是整个分布式服务器的核心层。它是整个集群中唯一的全局“管理者”，涉及的功能包括作业管理、状态监控、任务调度等。 总体而言，JobTracker主要包括两个功能：作业的调度与TaskTracker资源的管理。下节将具体讲解简易集群JobTracker的实现原理。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TaskTracker层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;TaskTracker主要负责任务的执行和任务状态的上报，还有就是分析后结果的入库等等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;DBC/CloudC层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DBC为数据库控制模块，CloudC为云存储控制模块。这里通过这两个模块与下面的数据库、云存储交互。控制模块中可以通过缓存机制，连接池机制等减轻直接访问DB/Cloud的压力。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;DB/Cloud层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DB/Cloud分别为数据库、云存储（可以部署在一台服务器或不同的服务器上） 。为啥要分数据库和云存储呢？ 对于结构化的信息，存储在数据库中比较方便，能够插入、更新、修改（这里的数据库设计的是关系型数据库，而非HBase那种面向列的存储数据库）。云存储则存储的是大的文件信息，这样TaskTracker通过调用CloudC的API，获得资源所在云存储的URL，TaskTracker能够根据URL直接访问云存储。&lt;/p&gt;

&lt;h3 id=&#34;jobtracker实现细节&#34;&gt;JobTracker实现细节&lt;/h3&gt;

&lt;p&gt;JobTracker是整个系统的核心租价，是系统高效运转的关键。其实现框架如下图：
&lt;img src=&#34;../../../../pic/2015/2015-06-18-distrubuted-server-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这里，将JobTracker的内部框架分为四个模块，分别是 TaskScheduler（任务调度模块），TaskSelect（任务选择模块），ResourceSelect（资源选择模块，选择哪个TaskTracker执行任务）。私有DB模块（存放任务的数据库）。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TaskScheduler模块
该模块负责Job与Task之间的关系维护，负责Job与task的进度管理及更新等工作。这里可以仿照hadoop采用“二层多叉树”方式描述和跟踪每个作业的运行状态（Hadoop采用的“三层多叉树”，多了一层任务运行尝试）。
&lt;img src=&#34;../../../../pic/2015/2015-06-18-distrubuted-server-3.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中，JobTracker为每个作业创建一个JobInProcess对象以跟踪和监控其运行状态。该对象存在于作业的整个运行过程中。同时，采用分而治之的策略，JobInProcess将每个作业拆分成若干个任务，并为每个任务创建一个TaskInProcess对象以跟踪和监控其运行状态。&lt;/p&gt;

&lt;p&gt;该模块还负责task与resource对应关系的管理。即哪个task放到了哪个tasktracker节点执行的。这就涉及到了与TaskSelect、ResourceSelect模块的交互。&lt;/p&gt;

&lt;p&gt;从图中可以看到，有私有数据库，这里的目的是将作业的信息、作业运行的当前状态等信息入库，JobTracker单点故障，重启后能够从数据库中读取保存的信息，重新运行任务。Hadoop中采用的日志方式进行任务的恢复，关于adoop的日志恢复，有待研究。这里姑且用任务数据库仿照Hadoop的日志恢复。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TaskSelect模块&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;该模块负责任务切片的选择。 因为客户端的 job是带有优先级的，有些job需要先执行，有些可以延后。 所以这里job切分的task切片都需要存放到TaskSelect模块的队列中，然后该模块选择优先级较高的task返回给TaskScheduler，表示当前可以执行该任务了。&lt;/p&gt;

&lt;p&gt;该模块中的优先级可以通过client端用户设定，而且优先级会根据时间长短动态调整。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ResourceSelect模块&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;该模块负责资源的选择。TaskTracker会定时发送心跳包给JobTracker，而发送的心跳包中包括资源使用情况（该节点的cpu利用率，内存利用率等信息你）以及任务运行状态。这些信息都将被保存在ResourceSelect这个模块。&lt;/p&gt;

&lt;p&gt;为每个TaskTracker节点创建一个对象（TaskTrackerObj），然后通过心跳来更新TaskTrackerObj中的状态信息。&lt;/p&gt;

&lt;h3 id=&#34;tasktracker实现细节&#34;&gt;TaskTracker实现细节&lt;/h3&gt;

&lt;p&gt;TaskTracker是任务的执行者，主要负责任务的执行和任务状态的上报。该模块的框架图如下所示：
&lt;img src=&#34;../../../../pic/2015/2015-06-18-distrubuted-server-4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;该模块中也有个管理模块TaskManager。该模块的作用相当于任务执行者的管理者。它有权限控制下面的Task（可以拉起、暂停、杀死下面任意一个Task）。它还会收集自身的资源，各个任务的状态等信息上报给JobTracker。 也就是说它是与JobTracker直接交互的。&lt;/p&gt;

&lt;p&gt;这里，Task运行后的结果统一经过DBC保存到了DB中， 而Task需要的资源可以通过CloudC，获得资源的URL，然后直接下载到本地或者内存 。&lt;/p&gt;

&lt;h3 id=&#34;存在问题&#34;&gt;存在问题&lt;/h3&gt;

&lt;p&gt;与真正的Hadoop设计思想相比较，会发现笔者这里的简易集群确实简单，只是涉及了MapReduce的 master/slave架构，而对另外两个hadoop的精髓——HDFS、HBase则未涉及。只是实现简单的分布式计算，未实现分布式的存储。&lt;/p&gt;

&lt;p&gt;该设计也存在单点故障问题， 比如JobTracker的， DBC的，CloudC的单点故障等等。&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>setopt简介</title>
          <link>https://maodanp.github.io/2015/05/20/introduce-of-setopt/</link>
          <pubDate>Wed, 20 May 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2015/05/20/introduce-of-setopt/</guid>
          <description>&lt;p&gt;在阅读别人的代码时，网络部分经常会遇到&lt;code&gt;setopt&lt;/code&gt;函数，下面关于几个生疏的选项作简要总结。&lt;/p&gt;

&lt;p&gt;关于套接字选项的设置与获取的两个函数为：setsockopt、 getsockopt。涉及的套接字选项较多，以下结合笔者所认为较为重要的几个，做简要描述（内容摘录自《UNNIX网络编程》卷1 Ch7 套接字选项）。&lt;/p&gt;

&lt;h3 id=&#34;so-error套接字选项&#34;&gt;SO_ERROR套接字选项&lt;/h3&gt;

&lt;p&gt;当一个套接字上发生错误时，源自Berkeley的内核中的协议模块将该套接字名为so_error的变量设置为标准的Unix Exxx值中的一个，称之为该套接字的待处理错误（pending error）。内核能够以以下两种方式之一立即通知进程这个错误。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果进程阻塞在对该套接字的select调用上，那么无论是检查可读还是可写条件，select均返回并设置其中一个或所有两条条件。&lt;/li&gt;
&lt;li&gt;如果进程使用信号驱动式I/O模型，那就给进程或进程组产生一个SIGIO信号。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;进程然后可以通过访问SO_ERROR套接字选项获取so_error的值。so_error随后由内核复位为0（错误处理的例子可以参照 《非阻塞connect》）。
当进程调用read且没有数据返回时，如果so_error为非0值，那么read返回-1，且errno被置为so_error的值。so_error随后由内核复位为0。 如果该套接字上有数据在排队等待读取，那么read返回那些数据而不是返回错误条件。
如果在进程调用write时so_error为非零值，那么write返回一个-1且errno被设置为so_error的值。so_error随后由内核复位为0。&lt;/p&gt;

&lt;h3 id=&#34;so-keepalive套接字选项&#34;&gt;SO_KEEPALIVE套接字选项&lt;/h3&gt;

&lt;p&gt;给一个TCP套接字设置保持存活（keep-alive）选项后，如果2小时内在该套接字的任意方向上都没有数据的交互，TCP会自动给对端发送一个保持存活探测包（keep-alive probe）。这是一个对端必须响应的TCP包，它会导致以下三种情况之一：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;对端以期望的ACK响应。应用进程得不到通知(一切正常)，在又经过仍无动静的2小时后，TCP将发出另一个保持存活探测包。&lt;/li&gt;
&lt;li&gt;对端以RST响应，它告知本端TCP:对端已经崩溃且已经重启。该套接字的待处理错误被置为ECONNRESET，套接字本身则被关闭。&lt;/li&gt;
&lt;li&gt;对端对保持存活探测包没有任何响应。源自Berkeley的TCP将另外发送8个保持存活探测包，两两相隔75秒，试图得到一个回应，如果还没有回应，则放弃。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;so-linger套接字选项&#34;&gt;SO_LINGER套接字选项&lt;/h3&gt;

&lt;p&gt;本选项执行close函数对于面向连接的协议如何进行操作的。&lt;/p&gt;

&lt;h4 id=&#34;服务器tcp不同条件检测&#34;&gt;服务器TCP不同条件检测&lt;/h4&gt;

&lt;p&gt;情形1： 客户端TCP正主动发送数据&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;服务器进程崩溃: 服务器TCP发送一个FIN，客户端通过使用select判断可读条件立即能检测出来。如果客户端再发送另一个数据包，服务器TCP就以RST响应。如果在客户端TCP收到RST后应用进程仍然试图写套接字，则客户端的套接字就给该进程发送一个SIGPIPE信号。&lt;/li&gt;
&lt;li&gt;服务器主机崩溃: 客户端TCP将超时，且套接字的待处理错误被置为ETIMEDOUT。&lt;/li&gt;
&lt;li&gt;服务器主机不可达: 客户端TCP将超时，且套接字的待处理错误被置为EHOSTUNREACH。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;情形2： 客户端TCP正主动接收数据&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;服务器进程崩溃: 服务器TCP将发送一个FIN，我们将把它作为一个EOF读入（可能较早读入）。&lt;/li&gt;
&lt;li&gt;服务器主机崩溃: 客户端将停止数据接收。&lt;/li&gt;
&lt;li&gt;服务器主机不可达: 客户端将停止数据接收。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;情形3： 连接空闲，保持存活选项已设置&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;服务器进程崩溃: 服务器TCP发送一个FIN，客户端通过使用select判断可读条件立即能检测出来。&lt;/li&gt;
&lt;li&gt;服务器主机崩溃: 在毫无动静2小时后，发送9个保持存活探测数据包，然后套接字的待处理错误被设置为ETIMEDOUT。&lt;/li&gt;
&lt;li&gt;服务器主机不可达: 在毫无动静2小时后，发送9个保持存活探测数据包，然后套接字的待处理错误被设置为EHOSTUNREACH。
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;情形4： 连接空闲，保持存活选项未设置&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;服务器进程崩溃: 服务器TCP发送一个FIN，客户端通过使用select判断可读条件立即能检测出来。&lt;/li&gt;
&lt;li&gt;服务器主机崩溃: 无&lt;/li&gt;
&lt;li&gt;服务器主机不可达： 无&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;注：以上的客户端、服务器可互换，条件检测类似&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;so-linger选项介绍&#34;&gt;SO_LINGER选项介绍&lt;/h4&gt;

&lt;p&gt;SO_LINGER套接字选项使得我们可以改变close的默认设置。本选项要求在用户进程与内核间传递如下结构：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   struct linger
   {
       int l_onoff; /*0-关闭 1-打开*/
       int l_linger; /*停留时间（posix单位为秒）*/
   }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对setsockopt的调用将根据其中两个结构成员的值形成下列三种情形之一：
* 如果l_onoff为 0，那么关闭本选项。l_linger的值被忽略，TCP的默认设置生效，即close立即返回。
* 如果l_onoff为非0且l_linger为0，那么当close某个连接时TCP将中止该连接（TCP将丢弃保留在套接字发送缓冲区中的任何数据，并发送一个RST给对端，而没有通常的关闭时的四次握手，这样能够避免TCP的TIME_WAIT状态(这样有可能导致&amp;rdquo;已失效的报文段&amp;rdquo;被不正确的传到新的连接上)。
* 如果l_onoff为非0且l_linger为非0值 ，那么当套接字关闭时内核将拖延一段时间（如果在套接字发送缓冲区中仍然留有数据，那么进程将投入睡眠，直到所有数据都发送完成且均被对方确认或者延迟事件到），如果套接字设置为非阻塞，那么它将不等待close完成，即使延迟时间为非0值。
当使用SO_LINGER选项的这个特性时，应用进程检查close的返回值是非常重要的，因为如果在数据发送完并被确认前延迟时间到的话，close将返回EWOULDBLOCK错误，且套接字发送缓冲区中的任何残留数据都将被丢弃。&lt;/p&gt;

&lt;h4 id=&#34;shutdown函数&#34;&gt;shutdown函数&lt;/h4&gt;

&lt;p&gt;终止网络连接的通常方法是调用close函数。不过close有两个限制，却可以使用shutdown来避免。
* close把描述符的引用计数减1，仅在该计数变成0时才关闭套接字。 使用shutdown则可以不管应用计数就激发TCP的正常连接终止序列。
* close终止读和写两个方向的数据传送。既然TCP是全双工的，有时候我们需要告诉对端我们已经完成了数据传送。既使对端仍然有数据要发送给我们。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   int shutdown(int sockfd, int howto)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该函数的行为依赖于howto参数的值：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SHUT_RD: 关闭连接的读这一半——套接字中不再有数据可接收，而且套接字接收缓冲区中的现有数据将被全部丢弃。进程不再对这样的套接字调用任何读函数。对一个TCP套接字这样调用shutdown函数后，由该套接字接收的来自对端的任何数据都被确认，然后悄然丢弃。
SHUT_WR: 关闭连接的写这一半——对于TCP套接字，这称之为半关闭，当前留在套接字发送缓冲区中的数据将被发送掉，后跟TCP的正常终止序列。进程不再对这样的套接字调用任何写函数。&lt;/li&gt;
&lt;li&gt;SHUT_RDWR: 连接的读半部分和写半部分都关闭——这与调用shutdown两次等效；第一次调用指定SHUT_RD, 第二次调用指定SHUT_WR。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;不同情形的close返回&#34;&gt;不同情形的close返回&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;close默认操作&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;默认的操作是close后立即返回，但是如果有数据残留在套接字发送缓冲区中，系统将试着把这些数据发送给对端。
&lt;img src=&#34;../../../../pic/2015/2015-05-20-introduce-of-setopt-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;客户端的close可以在服务器读取套接字接收缓冲区中的剩余数据之前就返回。如果在服务器的应用进程读取这些剩余数据之前就崩溃，客户端进程就永远不会知道（客户端一直处于FINWAIT_1状态）。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SO_LINGER指定延时时间&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;客户端可以设置SO_LINGER套接字选项，指定一个正的延时时间。这种情况下客户端的close要到它的数据和FIN已被服务器主机的TCP确认后才返回（延时时间为一个较大的值）。&lt;/p&gt;

&lt;p&gt;然而，仍然会与close的默认操作存在同样的问题：在服务器应用进程读取剩余数据之前，服务器主机有可能崩溃，并且服务器应用进程永远不知道（如果SO_LINGER选项的值偏小，close仍然有可能在它的数据和FIN被服务器主机的TCP确认之前就返回，并且返回值为-1，errno为EWOULDBLOCK）。
&lt;img src=&#34;../../../../pic/2015/2015-05-20-introduce-of-setopt-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;基本原则：设置SO_LINGER套接字选项后，close的唱功返回只是告诉我们先前发送的数据和FIN已经由对端TCP确认，而不能告诉我们对端的一样进成功已经读取了数据。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;shutdown关闭方式
让客户知道服务器已经读取其数据的一个方法是改为shutdown（并设置它的第二个参数为SHUT_WR）而不是调用close，并等待服务器的close调用。
&lt;img src=&#34;../../../../pic/2015/2015-05-20-introduce-of-setopt-3.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;比较这几种方式，可以在一下3个不同时机返回:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;close立即返回，根本不等待。&lt;/li&gt;
&lt;li&gt;close一直拖延到接收了对于客户端FIN的ACK才返回。&lt;/li&gt;
&lt;li&gt;后跟一个read调用的shutdown一直等到接收了服务器端的FIN才返回。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;《UNNIX网络编程》卷1 Ch7 套接字选项&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>非阻塞connect</title>
          <link>https://maodanp.github.io/2015/06/18/network_connect/</link>
          <pubDate>Wed, 13 May 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2015/06/18/network_connect/</guid>
          <description>&lt;p&gt;本文总结了关于非阻塞connect的处理细节，实现细节，作简要总结。&lt;/p&gt;

&lt;h3 id=&#34;非阻塞connect的用途&#34;&gt;非阻塞connect的用途&lt;/h3&gt;

&lt;p&gt;非阻塞的TCP套接字上调用connect时，connect将立即返回一个EINPROCESS错误，不过已经发起的TCP三路握手继续进行。接着用select检测这个连接或成功或失败的已建立条件。非阻塞connect有三个用途：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;我们可以把三路握手的时间叠加到其他处理上。完成一个connect要花费一个RTT时间，该时间波动范围很大，从几毫秒到几秒。这段时间内也许我们可以执行其他我们想要执行的工作。&lt;/li&gt;
&lt;li&gt;可以使用这个技术同时建立多个连接，这个用途已经随着web浏览器变得流行起来。&lt;/li&gt;
&lt;li&gt;由于我们用select等待连接的完成，因此可以给select设置一个时间限制，从而缩短connect的超时时间。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;非阻塞connect的处理细节&#34;&gt;非阻塞connect的处理细节&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;即使套接字是非阻塞的，如果连接服务器在同一台主机上，在调用connect时连接通常会立刻建立，我们必须处理这种情况。&lt;/li&gt;
&lt;li&gt;源自Berkeley的实现有两条与select和非阻塞I/O相关的规则: 当连接成功建立时，描述字变成可写; 当连接成功出错时，描述字变成即可读又可写&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;套接字可读-可写的条件&#34;&gt;套接字可读/可写的条件&lt;/h3&gt;

&lt;p&gt;关于这里的套接字的可读可写，在《Unix网络编程（卷1）》第6章有这样的描述：&lt;/p&gt;

&lt;p&gt;对于select返回套接字&amp;rdquo;准备好 可读/可写&amp;rdquo; 的明确条件：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;下列四个条件中任何一个满足时，套接字准备好读：&lt;/p&gt;

&lt;p&gt;a.  套接字缓冲区中的数据字节数大于等于套接字接收缓冲区中低潮限度的当前值。（我们可以用套接字选项SO_RCVLOWAT来设置此低潮限度， TCP/UDP默认值为1）。&lt;/p&gt;

&lt;p&gt;b.  连接的读这一半关闭（也就是说接收了FIN端的TCP连接），对这样的套接字的读操作将不阻塞且返回0（即为文件结束符）。&lt;/p&gt;

&lt;p&gt;c.   套接字是一个侦听套接字，且已经完成的连接数大于0。这样的监听套接字在accept上一般不会阻塞。&lt;/p&gt;

&lt;p&gt;d.  有一个套接字错误待处理。对这样的套接字的读操作将不会阻塞且返回一个错误值（-1）。errno设置成明确的错误条件。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;下列四个条件中任何一个满足时，套接字准备好写：&lt;/p&gt;

&lt;p&gt;a.  套接字发送缓冲区中的可用空间字节数大于等于套接字发送缓冲区低潮限度的当前值（ TCP/UDP默认值为2048）。&lt;/p&gt;

&lt;p&gt;b.  该连接的写半部关闭，对这样的套接字的写操作将产生SIGPIPE信号（参见上篇《服务器关闭与TCP异常》）。&lt;/p&gt;

&lt;p&gt;c.  使用非阻塞connect的套接字已经建立连接，或者connect已经以失败告终。&lt;/p&gt;

&lt;p&gt;d.  其上有一个套接字错误待处理。对这样的套接字的写操作将不阻塞并返回-1，同时把errno设置为确切的错误条件。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;注意：当某个套接字上发生错误时，它将由select标记为既可读又可写。&lt;/p&gt;

&lt;h3 id=&#34;代码分析&#34;&gt;代码分析&lt;/h3&gt;

&lt;p&gt;以下为常用的非阻塞connect的实现模块（摘录自《Unix网络编程》 Unit16）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int connect_nonb(int sockfd, const SA *saptr, socklen_t salen, int nsec) {
　　int flags, n, error;
　　socklen_t len;
　　fd_set rset, wset;
　　struct timeval tval;
　　/* 获取当前socket的属性， 并设置 noblocking 属性 */
　　flags = fcntl(sockfd, F_GETFL, 0);
　　fcntl(sockfd, F_SETFL, flags | O_NOBLOCK);
　　errno = 0;
     /*=========================================
      期望获得的错误(EINPROGRESS):
           表示连接建立已经启动但尚未完成
      其他错误则返回给本函数的调用者
     =========================================*/
　　if ( (n = connect(sockfd, saptr, salen)) &amp;lt; 0)
　　if (errno != EINPROGRESS)  
　　return (-1);

　　/* 这里可以做任何其它的操作*/

　　if (n == 0)
　　goto done;       /* 服务器与客户端为同一个主机, 会返回 0*/
　　FD_ZERO(&amp;amp;rset);
　　FD_SET(sockfd, &amp;amp;rset);
　　wset = rset;  
        tval.tv_sec = nsec;
        tval.tv_usec = 0;
     /*=========================================
     如果nsec 为0，将使用缺省的超时时间，即其结构指针为 NULL
     如果select的返回值为0，则表示超时:
        关闭套接字
        返回ETIMEOUT错误给调用者
    =========================================*/
　　if ((n = select(sockfd+1, &amp;amp;rset, &amp;amp;west, NULL,nsec ?tval:NULL)) == 0)
    {
　　  close(sockfd);
　　  errno = ETIMEOUT;
　　  return (-1);
　  }
    /*====================================================
     检查描述符的可读、可写
     需要getsockopt检查套接字上是否存在待处理错误，判断连接建立是否成功了:
        因为套接字上发生错误时，它将由select标记为既可读又可写
     这里getsockopt存在移植性问题(以下代码兼容两种情况)：
        Berkeley实现, getsockopt返回0，error中返回待处理错误
        Solaris中getsockopt返回-1，error中返回待处理错误
    ====================================================*/
　　if(FD_ISSET(sockfd, &amp;amp;rset) || FD_ISSET(sockfd, &amp;amp;west))
        {

　　  len = sizeof(error);
　　  if (getsockopt(sockfd, SOL_SOCKET, SO_ERROR, &amp;amp;error, &amp;amp;len) &amp;lt; 0)
　　  return (-1);
　   }
　　else err_quit(“select error: sockfd not set”);
　　done:
　　fcntl(sockfd, F_SETFL, flags);  /* 恢复socket 属性*/
　　if (error)
  {
　　close(sockfd);
　　errno = error;
　　return (-1);
　}
　　Return (0);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;移植问题&#34;&gt;移植问题&lt;/h3&gt;

&lt;p&gt;首先，调用select之前，有可能连接已经建立并由来自对端的数据到达。该情况下，即使套接字上不发生错误，套接字也是既可读又可写，这和连接简历失败情况下套接字的读写条件一样。&lt;/p&gt;

&lt;p&gt;除了getsockopt调用，还有其他方式可以判断连接建立是否成功么？UNIX网络编程提供的集中方案：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;调用getpeername代替 getsockopt。如果getpeername以ENOTCONN错误失败返回，那么连接建立已经失败，我们必须接着以SO_ERROR调用getsockopt取得套接字上待处理的错误；&lt;/li&gt;
&lt;li&gt;调用read,读取长度为0字节的数据.如果read调用失败,则表示连接建立失败,而且read返回的errno指明了连接失败的原因.如果连接建立成功,read应该返回0；&lt;/li&gt;
&lt;li&gt;再调用一次connect.它应该失败,如果错误errno是EISCONN,就表示套接口已经建立,而且第一次连接是成功的;否则,连接就是失败的。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;参考文章&#34;&gt;参考文章&lt;/h3&gt;

&lt;p&gt;UNIX网络编程卷1： Unit16 非阻塞connect&lt;/p&gt;</description>
        </item>
      
    
      
        <item>
          <title>Markdown简介</title>
          <link>https://maodanp.github.io/2015/04/17/introduce-of-markdown/</link>
          <pubDate>Fri, 17 Apr 2015 00:00:00 UTC</pubDate>
          <author></author>
          <guid>https://maodanp.github.io/2015/04/17/introduce-of-markdown/</guid>
          <description>&lt;p&gt;这段时间才结束Markdown。
想想作为程序员，才接触Markdown，甚是晚哉。
学什么只要其实也没有早晚，只要用心，此理放之四海而皆准。
废话不多说，下面简单记录markdown。&lt;/p&gt;

&lt;p&gt;下面为markdown的官方文档说明：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Markdown is intended to be as easy-to-read and easy-to-write as is feasible.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Markdown内部支持HTML、自动转意特殊字符&lt;/li&gt;
&lt;li&gt;Markdown的语法相当简洁, 可以让作者专注于写作内容本身，而不是排版。&lt;/li&gt;
&lt;li&gt;纯文档的，可以用任意文本编辑器打开&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;markdown语法&#34;&gt;Markdown语法&lt;/h3&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;标题&#34;&gt;标题&lt;/h4&gt;

&lt;p&gt;Markdown 支持两种分割的标题，&lt;a href=&#34;http://docutils.sourceforge.net/mirror/setext.html&#34;&gt;Setex&lt;/a&gt;和&lt;a href=&#34;http://www.aaronsw.com/2002/atx/&#34;&gt;Atx&lt;/a&gt;风格。
一般常用Atx风格, 用#表示1-6级标题。&lt;/p&gt;

&lt;h4 id=&#34;块引用&#34;&gt;块引用&lt;/h4&gt;

&lt;p&gt;Markdown使用邮件风格的 &amp;gt; 作为块引用。&lt;/p&gt;

&lt;p&gt;当然，块引用中可以包含其他的块。&lt;/p&gt;

&lt;h4 id=&#34;列表&#34;&gt;列表&lt;/h4&gt;

&lt;p&gt;列表分为有序列表、无序列表。&lt;/p&gt;

&lt;p&gt;无序列表使用 *, + 和 - 作为列表生成器; 有序列表则使用数字标识。
&lt;img src=&#34;../../../../pic/2015/2015-04-17-introduce-of-markdown-list.png&#34; alt=&#34;标题图片&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;注：标题、块引用都可以和前面的符号连着写，但列表符号就需要空行了&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;链接-图片&#34;&gt;链接、图片&lt;/h4&gt;

&lt;p&gt;在 Markdown 中，插入链接不需要其他按钮，你只需要使用如下语法：
&lt;code&gt;显示文本(链接地址)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;插入图片的语法则是&lt;code&gt;![显示文本](链接地址)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;注：目前Markdown还不支持定义图片的宽高，如果需要，可以使用普通的 &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; 标签。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;markdown不同平台编辑&#34;&gt;Markdown不同平台编辑&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Mac平台下推荐Mou&lt;/li&gt;
&lt;li&gt;windows平台推荐MarkdownPad&lt;/li&gt;
&lt;li&gt;Chorme提供Markdown-here插件(chrome插件下载都是需要科学上网的，大家都懂)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.jianshu.com/p/q81RER&#34;&gt;献给写作者的 Markdown 新手指南&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.jianshu.com/p/PpDNMG&#34;&gt;Markdown写作浅析&lt;/a&gt;&lt;/p&gt;</description>
        </item>
      
    
      
    

  </channel>
</rss>
